{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words Classifier Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# Custom functions \n",
    "from utils import print_gridsearch_results, test_on_estimator, plot_cv_single_param\n",
    "\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "---------------\n",
      "x_train_df shape: (2400, 2) \n",
      "x_test_df shape: (600, 2) \n",
      "y_train_df shape: (2400, 1) \n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data_reviews'\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "# Where to output predictions on the test_set\n",
    "x_test_df = pd.read_csv(os.path.join(data_dir, 'x_test.csv'))\n",
    "output_dir = 'predictions'\n",
    "\n",
    "print(\"Shape of data\\n---------------\")\n",
    "print(f\"x_train_df shape: {x_train_df.shape} \")\n",
    "print(f\"x_test_df shape: {x_test_df.shape} \")\n",
    "print(f\"y_train_df shape: {y_train_df.shape} \")\n",
    "\n",
    "# Get the text as a list of strings\n",
    "x_train_text = x_train_df['text'].values\n",
    "x_test_text = x_test_df['text'].values\n",
    "y_train = y_train_df['is_positive_sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training samples = 2400\n",
      "Fraction positive training samples = 0.5\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = x_train_text.shape[0]\n",
    "num_positive_train_samples = np.count_nonzero(y_train == 1)\n",
    "fraction_positive_train = float(num_positive_train_samples) / float(num_train_samples)\n",
    "\n",
    "\n",
    "print(f\"Total number of training samples = {num_train_samples}\")\n",
    "print(f\"Fraction positive training samples = {fraction_positive_train}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a stable skf CV-splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = sklearn.model_selection.StratifiedKFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction of two vectorizers - counts and tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "# #  Parameters for grid search\n",
    "# count_parameters = {\n",
    "#     'count__min_df': np.arange(1, 3),\n",
    "#     'count__max_df': (0.05, 0.5),\n",
    "#     'count__ngram_range': [(1, 1), (1, 2)],\n",
    "# }\n",
    "\n",
    "# Static Parameters based on earlier grid_search \n",
    "count_vectorizer.set_params(min_df = 2, ngram_range = (1,2))\n",
    "\n",
    "\n",
    "# Set the tuple for the pipeline\n",
    "count_pipeline_tuple = (\"count\", count_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# #  Parameters for grid search\n",
    "# tf_parameters = { \n",
    "#     'tf__min_df': np.arange(1,3),\n",
    "#     'tf__max_df': (0.05, 0.5),\n",
    "#     'tf__ngram_range': [(1, 1), (1, 2)],\n",
    "# }\n",
    "\n",
    "# Static Parameters based on earlier grid_search \n",
    "tf_vectorizer.set_params(min_df = 2, ngram_range = (1,2))\n",
    "\n",
    "# Set the tuple for the pipeline\n",
    "tf_pipeline_tuple = (\"tf\", tf_vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Max Depth Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "# Random Forest hyperparameter grid\n",
    "rf_parameters = {\n",
    "    \"rf__max_depth\": np.linspace(1, 500, 50)\n",
    "#     \"rf__n_estimxators\": np.linspace(1,800,40).astype(int),\n",
    "}\n",
    "rf_pipeline_tuple = ('rf', rf_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on the tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(min_df=2,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('rf',\n",
       "                                        RandomForestClassifier(random_state=123))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'rf__max_depth': array([  1.        ,  11.18367347,  21.36734694,  31.55102041,\n",
       "        41.73469388,  51.91836735,  62.10204082,  72.2857...\n",
       "       245.40816327, 255.59183673, 265.7755102 , 275.95918367,\n",
       "       286.14285714, 296.32653061, 306.51020408, 316.69387755,\n",
       "       326.87755102, 337.06122449, 347.24489796, 357.42857143,\n",
       "       367.6122449 , 377.79591837, 387.97959184, 398.16326531,\n",
       "       408.34693878, 418.53061224, 428.71428571, 438.89795918,\n",
       "       449.08163265, 459.26530612, 469.44897959, 479.63265306,\n",
       "       489.81632653, 500.        ])},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rf_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    rf_pipeline_tuple,\n",
    " ])\n",
    "tf_rf_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **rf_parameters\n",
    "}\n",
    "\n",
    "\n",
    "tf_rf_grid_searcher = GridSearchCV(\n",
    "    tf_rf_pipeline, \n",
    "    tf_rf_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=4,  \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "tf_rf_grid_searcher.fit(x_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (50, 19)\n",
      "Number of trials used in grid search:  50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>275.959</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.762917</td>\n",
       "      <td>1.060780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>357.429</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.762917</td>\n",
       "      <td>1.183933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>367.612</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>1.035695</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>500</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>0.895489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>489.816</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.002636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>387.98</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.177283</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>398.163</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.210880</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>408.347</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.223290</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>377.796</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.099336</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>428.714</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.041371</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>438.898</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.057028</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>449.082</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.033104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>459.265</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.037722</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>469.449</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.034240</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>479.633</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.131189</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>418.531</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761667</td>\n",
       "      <td>1.062309</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>235.224</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.761250</td>\n",
       "      <td>0.941259</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>316.694</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.760833</td>\n",
       "      <td>1.204672</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>214.857</td>\n",
       "      <td>0.988611</td>\n",
       "      <td>0.760833</td>\n",
       "      <td>0.918056</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>337.061</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>1.137349</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>296.327</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.759583</td>\n",
       "      <td>1.335129</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>347.245</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.759167</td>\n",
       "      <td>1.225426</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>326.878</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>1.158340</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>286.143</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>1.054691</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>245.408</td>\n",
       "      <td>0.991389</td>\n",
       "      <td>0.758750</td>\n",
       "      <td>1.024655</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>184.306</td>\n",
       "      <td>0.979722</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.849778</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>225.041</td>\n",
       "      <td>0.990417</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.903781</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>306.51</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.757083</td>\n",
       "      <td>1.222640</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>194.49</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.755417</td>\n",
       "      <td>0.985044</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>265.776</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>1.110408</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>204.673</td>\n",
       "      <td>0.985972</td>\n",
       "      <td>0.754583</td>\n",
       "      <td>0.910940</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>143.571</td>\n",
       "      <td>0.955694</td>\n",
       "      <td>0.754583</td>\n",
       "      <td>0.780104</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>255.592</td>\n",
       "      <td>0.991528</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.978937</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>174.122</td>\n",
       "      <td>0.975972</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.851482</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>163.939</td>\n",
       "      <td>0.969861</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.911192</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>153.755</td>\n",
       "      <td>0.962778</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.752287</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>133.388</td>\n",
       "      <td>0.948056</td>\n",
       "      <td>0.750417</td>\n",
       "      <td>0.825066</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>123.204</td>\n",
       "      <td>0.940556</td>\n",
       "      <td>0.748750</td>\n",
       "      <td>0.755766</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>113.02</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>0.747083</td>\n",
       "      <td>0.780397</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>102.837</td>\n",
       "      <td>0.924861</td>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.682955</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.4694</td>\n",
       "      <td>0.908611</td>\n",
       "      <td>0.743333</td>\n",
       "      <td>0.675913</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92.6531</td>\n",
       "      <td>0.917222</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.693137</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>72.2857</td>\n",
       "      <td>0.900417</td>\n",
       "      <td>0.738750</td>\n",
       "      <td>0.602264</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>62.102</td>\n",
       "      <td>0.890556</td>\n",
       "      <td>0.738750</td>\n",
       "      <td>0.579954</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51.9184</td>\n",
       "      <td>0.877917</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.510477</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.7347</td>\n",
       "      <td>0.869306</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.488856</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.551</td>\n",
       "      <td>0.857361</td>\n",
       "      <td>0.730417</td>\n",
       "      <td>0.410650</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.1837</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.297810</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.3673</td>\n",
       "      <td>0.842917</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.332735</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.726389</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.295080</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_rf__max_depth  mean_train_score  mean_test_score  mean_fit_time  \\\n",
       "27             275.959          0.991528         0.762917       1.060780   \n",
       "35             357.429          0.991528         0.762917       1.183933   \n",
       "36             367.612          0.991528         0.762083       1.035695   \n",
       "49                 500          0.991528         0.761667       0.895489   \n",
       "48             489.816          0.991528         0.761667       1.002636   \n",
       "38              387.98          0.991528         0.761667       1.177283   \n",
       "39             398.163          0.991528         0.761667       1.210880   \n",
       "40             408.347          0.991528         0.761667       1.223290   \n",
       "37             377.796          0.991528         0.761667       1.099336   \n",
       "42             428.714          0.991528         0.761667       1.041371   \n",
       "43             438.898          0.991528         0.761667       1.057028   \n",
       "44             449.082          0.991528         0.761667       1.033104   \n",
       "45             459.265          0.991528         0.761667       1.037722   \n",
       "46             469.449          0.991528         0.761667       1.034240   \n",
       "47             479.633          0.991528         0.761667       1.131189   \n",
       "41             418.531          0.991528         0.761667       1.062309   \n",
       "23             235.224          0.991528         0.761250       0.941259   \n",
       "31             316.694          0.991528         0.760833       1.204672   \n",
       "21             214.857          0.988611         0.760833       0.918056   \n",
       "33             337.061          0.991528         0.760417       1.137349   \n",
       "29             296.327          0.991528         0.759583       1.335129   \n",
       "34             347.245          0.991528         0.759167       1.225426   \n",
       "32             326.878          0.991528         0.758750       1.158340   \n",
       "28             286.143          0.991528         0.758750       1.054691   \n",
       "24             245.408          0.991389         0.758750       1.024655   \n",
       "18             184.306          0.979722         0.757500       0.849778   \n",
       "22             225.041          0.990417         0.757500       0.903781   \n",
       "30              306.51          0.991528         0.757083       1.222640   \n",
       "19              194.49          0.983333         0.755417       0.985044   \n",
       "26             265.776          0.991528         0.755000       1.110408   \n",
       "20             204.673          0.985972         0.754583       0.910940   \n",
       "14             143.571          0.955694         0.754583       0.780104   \n",
       "25             255.592          0.991528         0.753750       0.978937   \n",
       "17             174.122          0.975972         0.752917       0.851482   \n",
       "16             163.939          0.969861         0.752500       0.911192   \n",
       "15             153.755          0.962778         0.751667       0.752287   \n",
       "13             133.388          0.948056         0.750417       0.825066   \n",
       "12             123.204          0.940556         0.748750       0.755766   \n",
       "11              113.02          0.932222         0.747083       0.780397   \n",
       "10             102.837          0.924861         0.744583       0.682955   \n",
       "8              82.4694          0.908611         0.743333       0.675913   \n",
       "9              92.6531          0.917222         0.739583       0.693137   \n",
       "7              72.2857          0.900417         0.738750       0.602264   \n",
       "6               62.102          0.890556         0.738750       0.579954   \n",
       "5              51.9184          0.877917         0.733333       0.510477   \n",
       "4              41.7347          0.869306         0.731667       0.488856   \n",
       "3               31.551          0.857361         0.730417       0.410650   \n",
       "1              11.1837          0.818333         0.716667       0.297810   \n",
       "2              21.3673          0.842917         0.715000       0.332735   \n",
       "0                    1          0.726389         0.668333       0.295080   \n",
       "\n",
       "    rank_test_score  \n",
       "27                1  \n",
       "35                1  \n",
       "36                3  \n",
       "49                4  \n",
       "48                4  \n",
       "38                4  \n",
       "39                4  \n",
       "40                4  \n",
       "37                4  \n",
       "42                4  \n",
       "43                4  \n",
       "44                4  \n",
       "45                4  \n",
       "46                4  \n",
       "47                4  \n",
       "41                4  \n",
       "23               17  \n",
       "31               18  \n",
       "21               18  \n",
       "33               20  \n",
       "29               21  \n",
       "34               22  \n",
       "32               23  \n",
       "28               23  \n",
       "24               23  \n",
       "18               26  \n",
       "22               26  \n",
       "30               28  \n",
       "19               29  \n",
       "26               30  \n",
       "20               31  \n",
       "14               32  \n",
       "25               33  \n",
       "17               34  \n",
       "16               35  \n",
       "15               36  \n",
       "13               37  \n",
       "12               38  \n",
       "11               39  \n",
       "10               40  \n",
       "8                41  \n",
       "9                42  \n",
       "7                43  \n",
       "6                43  \n",
       "5                45  \n",
       "4                46  \n",
       "3                47  \n",
       "1                48  \n",
       "2                49  \n",
       "0                50  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(tf_rf_grid_searcher, list(tf_rf_full_grid.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the CV results for a gridsearch over one feature\n",
    "\n",
    "cv_results = tf_rf_grid_searcher.cv_results_\n",
    "# Two plots: One comparing train and test performance; one comparing all of the fold scores against one another \n",
    "# Plot one\n",
    "param = list(rf_parameters.keys())[0]\n",
    "param_label = \"Number of trees in forest frequency\"\n",
    "\n",
    "def plot_cv_single_param(cv_results, param_name, param_label):\n",
    "    param_values = cv_results[f'param_{param_name}']\n",
    "    mean_test_score = cv_results['mean_test_score']\n",
    "    mean_train_score = cv_results['mean_train_score']\n",
    "\n",
    "    # Plot Grid search scores\n",
    "    _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    ax.plot(param_values.data.astype(np.float64), mean_test_score, '-o', label='test set')\n",
    "#     ax.plot(np.log10(param_values.data.astype(np.float64)), mean_train_score, '-o', label='train set')\n",
    "\n",
    "    ax.set_title(f\"{param_label} Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "    ax.set_xlabel(param_label, fontsize=16)\n",
    "    ax.set_ylabel('Balanced Accuracy', fontsize=16)\n",
    "    ax.legend(loc=\"best\", fontsize=15)\n",
    "    ax.grid('on')\n",
    "\n",
    "plot_cv_single_param(cv_results, param, param_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Failed attempt at blocking each line in the visualization by a second parameter\n",
    "\n",
    "# cv_results = tf_rf_grid_searcher.cv_results_\n",
    "# # Two plots: One comparing train and test performance; one comparing all of the fold scores against one another \n",
    "# # Plot one\n",
    "# param = list(rf_parameters.keys())[0]\n",
    "# param_label = \"Number of trees in forest frequency\"\n",
    "# param_values = cv_results[f'param_{param}']\n",
    "# param_range = rf_parameters[param]\n",
    "\n",
    "\n",
    "# second_param = list(rf_parameters.keys())[1]\n",
    "# second_p_label = \"Max depth of trees\"\n",
    "# second_p_values = cv_results[f'param_{second_param}']\n",
    "# second_p_range = rf_parameters[second_param]\n",
    "# print(second_p_values)\n",
    "# # print(type(second_p_values))\n",
    "# print(second_p_range)\n",
    "# # print(second_p_values == second_p_range[0])\n",
    "\n",
    "\n",
    "# mean_test_score = cv_results['mean_test_score'].reshape(len(param_range), len(second_p_range))\n",
    "# mean_train_score = cv_results['mean_train_score'].reshape(len(param_range), len(second_p_range))\n",
    "# print(mean_test_score)\n",
    "# print(mean_train_score)\n",
    "# _, ax = plt.subplots(1, 1)\n",
    "\n",
    "# for i, val in enumerate(second_p_range): \n",
    "#     ax.plot(param_range, mean_test_score[:, i], '-o', label=f'test set, {val}')\n",
    "# #     ax.plot(param_range, mean_train_score[:, i], '-o', label=f'train set, {val}')\n",
    "\n",
    "# ax.set_title(f\"{param_label} Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "# ax.set_xlabel(second_p_label, fontsize=16)\n",
    "# ax.set_ylabel('Balanced Accuracy', fontsize=16)\n",
    "# ax.legend(loc=\"best\", fontsize=15)\n",
    "# ax.grid('on')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 275.9591836734694}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_rf_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on CountVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count_rf_pipeline = Pipeline([\n",
    "    count_pipeline_tuple,\n",
    "    rf_pipeline_tuple,\n",
    " ])\n",
    "count_rf_full_grid = { \n",
    "#     **count_parameters,\n",
    "    **rf_parameters\n",
    "}\n",
    "\n",
    "\n",
    "count_rf_grid_searcher = GridSearchCV(\n",
    "    count_rf_pipeline, \n",
    "    count_rf_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    return_train_score=True,\n",
    "    scoring='balanced_accuracy'\n",
    ")\n",
    "count_rf_grid_searcher.fit(x_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (36, 28)\n",
      "Number of trials used in grid search:  36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_count__min_df</th>\n",
       "      <th>param_count__ngram_range</th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.876524</td>\n",
       "      <td>0.767143</td>\n",
       "      <td>0.837929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.873676</td>\n",
       "      <td>0.766728</td>\n",
       "      <td>0.576524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.873816</td>\n",
       "      <td>0.765467</td>\n",
       "      <td>0.318968</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857908</td>\n",
       "      <td>0.763862</td>\n",
       "      <td>0.676434</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.855199</td>\n",
       "      <td>0.763024</td>\n",
       "      <td>0.459837</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.851113</td>\n",
       "      <td>0.761684</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.836514</td>\n",
       "      <td>0.759296</td>\n",
       "      <td>0.605566</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.759190</td>\n",
       "      <td>0.809340</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.852292</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.567307</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833818</td>\n",
       "      <td>0.758376</td>\n",
       "      <td>0.640886</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.847630</td>\n",
       "      <td>0.757614</td>\n",
       "      <td>0.300496</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.831456</td>\n",
       "      <td>0.757138</td>\n",
       "      <td>0.437517</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.830692</td>\n",
       "      <td>0.756715</td>\n",
       "      <td>0.685503</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.827013</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>0.227561</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.828181</td>\n",
       "      <td>0.753463</td>\n",
       "      <td>0.410863</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.829650</td>\n",
       "      <td>0.753383</td>\n",
       "      <td>0.476467</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.818395</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.593801</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.825207</td>\n",
       "      <td>0.751695</td>\n",
       "      <td>0.263088</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.827152</td>\n",
       "      <td>0.751690</td>\n",
       "      <td>0.669137</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.751292</td>\n",
       "      <td>0.243596</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.826666</td>\n",
       "      <td>0.750867</td>\n",
       "      <td>0.462598</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.750469</td>\n",
       "      <td>0.603675</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.791803</td>\n",
       "      <td>0.750090</td>\n",
       "      <td>0.373315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.814364</td>\n",
       "      <td>0.749271</td>\n",
       "      <td>0.389634</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789996</td>\n",
       "      <td>0.748419</td>\n",
       "      <td>0.199876</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.795411</td>\n",
       "      <td>0.747996</td>\n",
       "      <td>0.565720</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.801595</td>\n",
       "      <td>0.747982</td>\n",
       "      <td>0.266157</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.804025</td>\n",
       "      <td>0.747545</td>\n",
       "      <td>0.417764</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>0.793123</td>\n",
       "      <td>0.746738</td>\n",
       "      <td>0.532631</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.791590</td>\n",
       "      <td>0.745922</td>\n",
       "      <td>0.387262</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.819922</td>\n",
       "      <td>0.744269</td>\n",
       "      <td>0.252930</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>0.804791</td>\n",
       "      <td>0.742981</td>\n",
       "      <td>0.598277</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.801737</td>\n",
       "      <td>0.742979</td>\n",
       "      <td>0.410557</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.788746</td>\n",
       "      <td>0.742185</td>\n",
       "      <td>0.217825</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.805134</td>\n",
       "      <td>0.742173</td>\n",
       "      <td>0.235794</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.798055</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.214769</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_count__min_df param_count__ngram_range param_rf__n_estimators  \\\n",
       "17                   1                   (1, 2)                    300   \n",
       "16                   1                   (1, 2)                    200   \n",
       "15                   1                   (1, 2)                    100   \n",
       "14                   1                   (1, 2)                    300   \n",
       "13                   1                   (1, 2)                    200   \n",
       "6                    1                   (1, 1)                    100   \n",
       "11                   1                   (1, 2)                    300   \n",
       "8                    1                   (1, 1)                    300   \n",
       "7                    1                   (1, 1)                    200   \n",
       "5                    1                   (1, 1)                    300   \n",
       "12                   1                   (1, 2)                    100   \n",
       "4                    1                   (1, 1)                    200   \n",
       "35                   2                   (1, 2)                    300   \n",
       "3                    1                   (1, 1)                    100   \n",
       "10                   1                   (1, 2)                    200   \n",
       "34                   2                   (1, 2)                    200   \n",
       "2                    1                   (1, 1)                    300   \n",
       "33                   2                   (1, 2)                    100   \n",
       "26                   2                   (1, 1)                    300   \n",
       "24                   2                   (1, 1)                    100   \n",
       "25                   2                   (1, 1)                    200   \n",
       "32                   2                   (1, 2)                    300   \n",
       "19                   2                   (1, 1)                    200   \n",
       "1                    1                   (1, 1)                    200   \n",
       "18                   2                   (1, 1)                    100   \n",
       "29                   2                   (1, 2)                    300   \n",
       "30                   2                   (1, 2)                    100   \n",
       "31                   2                   (1, 2)                    200   \n",
       "20                   2                   (1, 1)                    300   \n",
       "28                   2                   (1, 2)                    200   \n",
       "9                    1                   (1, 2)                    100   \n",
       "23                   2                   (1, 1)                    300   \n",
       "22                   2                   (1, 1)                    200   \n",
       "27                   2                   (1, 2)                    100   \n",
       "0                    1                   (1, 1)                    100   \n",
       "21                   2                   (1, 1)                    100   \n",
       "\n",
       "   param_rf__max_depth  mean_train_score  mean_test_score  mean_fit_time  \\\n",
       "17                  20          0.876524         0.767143       0.837929   \n",
       "16                  20          0.873676         0.766728       0.576524   \n",
       "15                  20          0.873816         0.765467       0.318968   \n",
       "14                  10          0.857908         0.763862       0.676434   \n",
       "13                  10          0.855199         0.763024       0.459837   \n",
       "6                   20          0.851113         0.761684       0.289146   \n",
       "11                   5          0.836514         0.759296       0.605566   \n",
       "8                   20          0.855556         0.759190       0.809340   \n",
       "7                   20          0.852292         0.758772       0.567307   \n",
       "5                   10          0.833818         0.758376       0.640886   \n",
       "12                  10          0.847630         0.757614       0.300496   \n",
       "4                   10          0.831456         0.757138       0.437517   \n",
       "35                  20          0.830692         0.756715       0.685503   \n",
       "3                   10          0.827013         0.755474       0.227561   \n",
       "10                   5          0.828181         0.753463       0.410863   \n",
       "34                  20          0.829650         0.753383       0.476467   \n",
       "2                    5          0.818395         0.752577       0.593801   \n",
       "33                  20          0.825207         0.751695       0.263088   \n",
       "26                  20          0.827152         0.751690       0.669137   \n",
       "24                  20          0.822917         0.751292       0.243596   \n",
       "25                  20          0.826666         0.750867       0.462598   \n",
       "32                  10          0.807565         0.750469       0.603675   \n",
       "19                   5          0.791803         0.750090       0.373315   \n",
       "1                    5          0.814364         0.749271       0.389634   \n",
       "18                   5          0.789996         0.748419       0.199876   \n",
       "29                   5          0.795411         0.747996       0.565720   \n",
       "30                  10          0.801595         0.747982       0.266157   \n",
       "31                  10          0.804025         0.747545       0.417764   \n",
       "20                   5          0.793123         0.746738       0.532631   \n",
       "28                   5          0.791590         0.745922       0.387262   \n",
       "9                    5          0.819922         0.744269       0.252930   \n",
       "23                  10          0.804791         0.742981       0.598277   \n",
       "22                  10          0.801737         0.742979       0.410557   \n",
       "27                   5          0.788746         0.742185       0.217825   \n",
       "0                    5          0.805134         0.742173       0.235794   \n",
       "21                  10          0.798055         0.739647       0.214769   \n",
       "\n",
       "    rank_test_score  \n",
       "17                1  \n",
       "16                2  \n",
       "15                3  \n",
       "14                4  \n",
       "13                5  \n",
       "6                 6  \n",
       "11                7  \n",
       "8                 8  \n",
       "7                 9  \n",
       "5                10  \n",
       "12               11  \n",
       "4                12  \n",
       "35               13  \n",
       "3                14  \n",
       "10               15  \n",
       "34               16  \n",
       "2                17  \n",
       "33               18  \n",
       "26               19  \n",
       "24               20  \n",
       "25               21  \n",
       "32               22  \n",
       "19               23  \n",
       "1                24  \n",
       "18               25  \n",
       "29               26  \n",
       "30               27  \n",
       "31               28  \n",
       "20               29  \n",
       "28               30  \n",
       "9                31  \n",
       "23               32  \n",
       "22               33  \n",
       "27               34  \n",
       "0                35  \n",
       "21               36  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(count_rf_grid_searcher, list(count_rf_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (72, 31)\n",
      "Number of trials used in grid search:  72\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_count__min_df</th>\n",
       "      <th>param_count__max_df</th>\n",
       "      <th>param_count__ngram_range</th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.853810</td>\n",
       "      <td>0.765833</td>\n",
       "      <td>0.290650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>0.876310</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.784306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.877679</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>0.533752</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>0.851012</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>0.684137</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.845714</td>\n",
       "      <td>0.760833</td>\n",
       "      <td>0.324446</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.792083</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>0.254434</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.802917</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>0.219317</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.773571</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>0.226318</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.781369</td>\n",
       "      <td>0.694583</td>\n",
       "      <td>0.235885</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.766726</td>\n",
       "      <td>0.692917</td>\n",
       "      <td>0.209150</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_count__min_df param_count__max_df param_count__ngram_range  \\\n",
       "42                   1                 0.5                   (1, 1)   \n",
       "52                   1                 0.5                   (1, 2)   \n",
       "51                   1                 0.5                   (1, 2)   \n",
       "49                   1                 0.5                   (1, 2)   \n",
       "48                   1                 0.5                   (1, 2)   \n",
       "..                 ...                 ...                      ...   \n",
       "9                    1                0.05                   (1, 2)   \n",
       "21                   2                0.05                   (1, 1)   \n",
       "27                   2                0.05                   (1, 2)   \n",
       "0                    1                0.05                   (1, 1)   \n",
       "18                   2                0.05                   (1, 1)   \n",
       "\n",
       "   param_rf__n_estimators param_rf__max_depth  mean_train_score  \\\n",
       "42                    100                  20          0.853810   \n",
       "52                    200                  20          0.876310   \n",
       "51                    100                  20          0.877679   \n",
       "49                    200                  10          0.851012   \n",
       "48                    100                  10          0.845714   \n",
       "..                    ...                 ...               ...   \n",
       "9                     100                   5          0.792083   \n",
       "21                    100                  10          0.802917   \n",
       "27                    100                   5          0.773571   \n",
       "0                     100                   5          0.781369   \n",
       "18                    100                   5          0.766726   \n",
       "\n",
       "    mean_test_score  mean_fit_time  rank_test_score  \n",
       "42         0.765833       0.290650                1  \n",
       "52         0.764583       0.784306                2  \n",
       "51         0.762083       0.533752                3  \n",
       "49         0.762083       0.684137                4  \n",
       "48         0.760833       0.324446                5  \n",
       "..              ...            ...              ...  \n",
       "9          0.707500       0.254434               68  \n",
       "21         0.705833       0.219317               69  \n",
       "27         0.702500       0.226318               70  \n",
       "0          0.694583       0.235885               71  \n",
       "18         0.692917       0.209150               72  \n",
       "\n",
       "[72 rows x 9 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(count_rf_grid_searcher, list(count_rf_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count__min_df': 1,\n",
       " 'count__ngram_range': (1, 2),\n",
       " 'rf__max_depth': 20,\n",
       " 'rf__n_estimators': 300}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_rf_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions using best Random Forest and Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rf_filename = os.path.join(output_dir, 'bow_count_rf_yproba1_test.txt')\n",
    "test_on_estimator(count_rf_grid_searcher.best_estimator_, x_test_text, count_rf_filename)\n",
    "tf_rf_filename = os.path.join(output_dir, 'bow_tf_rf_yproba1_test.txt')\n",
    "test_on_estimator(tf_rf_grid_searcher.best_estimator_, x_test_text, tf_rf_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree: Hyperparameter search\n",
    "\n",
    "**NOTE** Only re-run when necessary. The total run-time for rebuilding these classifiers is roughly 15-30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=5, min_samples_leaf=1, random_state=RANDOM_STATE)\n",
    "# GradientBoosting-Tree hyperparameter grid\n",
    "gbtree_parameters = {\n",
    "    \"gbtree__n_estimators\": [100, 200, 300],\n",
    "    \"gbtree__max_depth\": [5, 10, 20],\n",
    "    \"gbtree__min_samples_leaf\": [1, 3, 5],\n",
    "}\n",
    "gbtree_pipeline_tuple = ('gbtree', gbtree_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on the tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=3)]: Done 506 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=3)]: Done 794 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=3)]: Done 1080 out of 1080 | elapsed: 20.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('gbtree',\n",
       "                                        GradientBoostingClassifier(max_depth=5,\n",
       "                                                                   random_state=123))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'gbtree__max_depth': [5, 10, 20],\n",
       "                         'gbtree__min_samples_leaf': [1, 3, 5],\n",
       "                         'gbtree__n_estimators': [100, 200, 300],\n",
       "                         'tf__max_df': (0.05, 0.5), 'tf__min_df': array([1, 2]),\n",
       "                         'tf__ngram_range': [(1, 1), (1, 2)]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_gbtree_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    gbtree_pipeline_tuple,\n",
    " ])\n",
    "tf_gbtree_full_grid = { \n",
    "    **tf_parameters,\n",
    "    **gbtree_parameters\n",
    "}\n",
    "\n",
    "\n",
    "tf_gbtree_grid_searcher = GridSearchCV(\n",
    "    tf_gbtree_pipeline, \n",
    "    tf_gbtree_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "tf_gbtree_grid_searcher.fit(x_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (216, 26)\n",
      "Number of trials used in grid search:  216\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tf__min_df</th>\n",
       "      <th>param_tf__max_df</th>\n",
       "      <th>param_tf__ngram_range</th>\n",
       "      <th>param_gbtree__n_estimators</th>\n",
       "      <th>param_gbtree__max_depth</th>\n",
       "      <th>param_gbtree__min_samples_leaf</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941979</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>2.447076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.771667</td>\n",
       "      <td>1.560614</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996146</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>4.124050</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.947604</td>\n",
       "      <td>0.769583</td>\n",
       "      <td>1.807707</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.769583</td>\n",
       "      <td>2.854647</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.819583</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.581437</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.940521</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>11.528023</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.797708</td>\n",
       "      <td>0.680833</td>\n",
       "      <td>0.613226</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.940417</td>\n",
       "      <td>0.680417</td>\n",
       "      <td>4.091111</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.801979</td>\n",
       "      <td>0.674583</td>\n",
       "      <td>0.495619</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_tf__min_df param_tf__max_df param_tf__ngram_range  \\\n",
       "20                 1              0.5                (1, 1)   \n",
       "12                 1              0.5                (1, 1)   \n",
       "92                 1              0.5                (1, 1)   \n",
       "22                 2              0.5                (1, 1)   \n",
       "84                 1              0.5                (1, 1)   \n",
       "..               ...              ...                   ...   \n",
       "27                 2             0.05                (1, 2)   \n",
       "209                1             0.05                (1, 2)   \n",
       "48                 1             0.05                (1, 1)   \n",
       "211                2             0.05                (1, 2)   \n",
       "51                 2             0.05                (1, 2)   \n",
       "\n",
       "    param_gbtree__n_estimators param_gbtree__max_depth  \\\n",
       "20                         300                       5   \n",
       "12                         200                       5   \n",
       "92                         300                      10   \n",
       "22                         300                       5   \n",
       "84                         200                      10   \n",
       "..                         ...                     ...   \n",
       "27                         100                       5   \n",
       "209                        300                      20   \n",
       "48                         100                       5   \n",
       "211                        300                      20   \n",
       "51                         100                       5   \n",
       "\n",
       "    param_gbtree__min_samples_leaf  mean_train_score  mean_test_score  \\\n",
       "20                               1          0.941979         0.776667   \n",
       "12                               1          0.923750         0.771667   \n",
       "92                               1          0.996146         0.770833   \n",
       "22                               1          0.947604         0.769583   \n",
       "84                               1          0.995937         0.769583   \n",
       "..                             ...               ...              ...   \n",
       "27                               3          0.819583         0.683333   \n",
       "209                              5          0.940521         0.683333   \n",
       "48                               5          0.797708         0.680833   \n",
       "211                              5          0.940417         0.680417   \n",
       "51                               5          0.801979         0.674583   \n",
       "\n",
       "     mean_fit_time  rank_test_score  \n",
       "20        2.447076                1  \n",
       "12        1.560614                2  \n",
       "92        4.124050                3  \n",
       "22        1.807707                4  \n",
       "84        2.854647                5  \n",
       "..             ...              ...  \n",
       "27        0.581437              212  \n",
       "209      11.528023              212  \n",
       "48        0.613226              214  \n",
       "211       4.091111              215  \n",
       "51        0.495619              216  \n",
       "\n",
       "[216 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(tf_gbtree_grid_searcher, list(tf_gbtree_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gbtree__max_depth': 5,\n",
       " 'gbtree__min_samples_leaf': 1,\n",
       " 'gbtree__n_estimators': 300,\n",
       " 'tf__max_df': 0.5,\n",
       " 'tf__min_df': 1,\n",
       " 'tf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_gbtree_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBTree: Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree_filename = os.path.join(output_dir, 'bow_tf_gbtree_yproba1_test.txt')\n",
    "test_on_estimator(tf_gbtree_grid_searcher.best_estimator_, x_test_text, gbtree_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBD: Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-cbbc0ed7d83c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_ax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtr_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train log loss'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mte_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test log loss'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, loss_ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4), sharex=True, sharey=True)\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    tr_label = 'train log loss' if run_id == 0 else ''\n",
    "    te_label = 'test log loss' if run_id == 0 else ''\n",
    "    \n",
    "    loss_ax.plot(np.log2(size_list), tr_loss_arr[:,run_id], 'bd', label=tr_label)\n",
    "    loss_ax.plot(np.log2(size_list), te_loss_arr[:,run_id], 'rd', label=te_label)\n",
    "\n",
    "loss_ax.set_xticks(np.log2(size_list));\n",
    "loss_ax.set_xticklabels(size_list);\n",
    "loss_ax.xaxis.grid(False);\n",
    "\n",
    "loss_ax.set_ylim([0, 0.8]); # Don't touch this please\n",
    "loss_ax.set_yticks(np.arange(0, 0.8, 0.1));\n",
    "loss_ax.set_title(\"Log Loss vs Size\")\n",
    "loss_ax.set_ylabel('log loss');\n",
    "loss_ax.set_xlabel('size');\n",
    "loss_ax.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## L1-Logistic Regression: Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.LogisticRegression(penalty='l1', solver='saga', random_state=RANDOM_STATE)\n",
    "# logit_lasso hyperparameter grid\n",
    "lasso_parameters = {\n",
    "     'lasso__C': np.logspace(-4, 4, 9),\n",
    "     'lasso__max_iter': [20, 40], # sneaky way to do \"early stopping\" \n",
    "}\n",
    "lasso_pipeline_tuple = ('lasso', lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on the tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=3)]: Done 143 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=3)]: Done 303 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=3)]: Done 545 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=3)]: Done 720 out of 720 | elapsed:  3.3min finished\n",
      "/Users/dylanphelan/opt/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('count',\n",
       "                                        CountVectorizer(stop_words='english')),\n",
       "                                       ('lasso',\n",
       "                                        LogisticRegression(penalty='l1',\n",
       "                                                           random_state=101,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'count__max_df': (0.05, 0.5),\n",
       "                         'count__min_df': array([1, 2]),\n",
       "                         'count__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lasso__C': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04]),\n",
       "                         'lasso__max_iter': [20, 40]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_lasso_pipeline = Pipeline([\n",
    "    count_pipeline_tuple,\n",
    "    lasso_pipeline_tuple,\n",
    " ])\n",
    "count_lasso_full_grid = { \n",
    "    **count_parameters,\n",
    "    **lasso_parameters\n",
    "}\n",
    "\n",
    "\n",
    "count_lasso_grid_searcher = GridSearchCV(\n",
    "    count_lasso_pipeline, \n",
    "    count_lasso_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "count_lasso_grid_searcher.fit(x_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (144, 25)\n",
      "Number of trials used in grid search:  144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_count__min_df</th>\n",
       "      <th>param_count__max_df</th>\n",
       "      <th>param_count__ngram_range</th>\n",
       "      <th>param_lasso__C</th>\n",
       "      <th>param_lasso__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.967708</td>\n",
       "      <td>0.797083</td>\n",
       "      <td>0.914771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.963646</td>\n",
       "      <td>0.797083</td>\n",
       "      <td>0.749147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>10000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.968021</td>\n",
       "      <td>0.796250</td>\n",
       "      <td>0.920900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.967917</td>\n",
       "      <td>0.796250</td>\n",
       "      <td>0.968059</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.978958</td>\n",
       "      <td>0.795417</td>\n",
       "      <td>2.858857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027523</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.029619</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027353</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.030030</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.034940</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_count__min_df param_count__max_df param_count__ngram_range  \\\n",
       "84                    1                 0.5                   (1, 1)   \n",
       "82                    1                 0.5                   (1, 1)   \n",
       "88                    1                 0.5                   (1, 1)   \n",
       "86                    1                 0.5                   (1, 1)   \n",
       "104                   1                 0.5                   (1, 2)   \n",
       "..                  ...                 ...                      ...   \n",
       "109                   2                 0.5                   (1, 1)   \n",
       "110                   2                 0.5                   (1, 1)   \n",
       "111                   2                 0.5                   (1, 1)   \n",
       "113                   2                 0.5                   (1, 1)   \n",
       "0                     1                0.05                   (1, 1)   \n",
       "\n",
       "    param_lasso__C param_lasso__max_iter  mean_train_score  mean_test_score  \\\n",
       "84             100                    20          0.967708         0.797083   \n",
       "82              10                    20          0.963646         0.797083   \n",
       "88           10000                    20          0.968021         0.796250   \n",
       "86            1000                    20          0.967917         0.796250   \n",
       "104           1000                    20          0.978958         0.795417   \n",
       "..             ...                   ...               ...              ...   \n",
       "109         0.0001                    40          0.500000         0.500000   \n",
       "110          0.001                    20          0.500000         0.500000   \n",
       "111          0.001                    40          0.500000         0.500000   \n",
       "113           0.01                    40          0.500000         0.500000   \n",
       "0           0.0001                    20          0.500000         0.500000   \n",
       "\n",
       "     mean_fit_time  rank_test_score  \n",
       "84        0.914771                1  \n",
       "82        0.749147                1  \n",
       "88        0.920900                3  \n",
       "86        0.968059                3  \n",
       "104       2.858857                5  \n",
       "..             ...              ...  \n",
       "109       0.027523               97  \n",
       "110       0.029619               97  \n",
       "111       0.027353               97  \n",
       "113       0.030030               97  \n",
       "0         0.034940               97  \n",
       "\n",
       "[144 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(count_lasso_grid_searcher, list(count_lasso_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count__max_df': 0.5,\n",
       " 'count__min_df': 1,\n",
       " 'count__ngram_range': (1, 1),\n",
       " 'lasso__C': 10.0,\n",
       " 'lasso__max_iter': 20}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_lasso_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-Logistic Regression: Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_filename = os.path.join(output_dir, 'bow_count_lasso_yproba1_test.txt')\n",
    "test_on_estimator(count_lasso_grid_searcher.best_estimator_, x_test_text, lasso_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive: Things We May Need \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# np.argwhere(count_rf_grid_searcher.cv_results_[\"rank_test_score\"] == 1)\n",
    "# count_rf_grid_searcher.cv_results_[\"mean_train_score\"][29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_grid_searcher.fit(x_train_text_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_grid_search_results_df = pd.DataFrame(random_forest_grid_searcher.cv_results_).copy()\n",
    "# n_trials_grid_search = random_forest_grid_search_results_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_keys = ['param_n_estimators', 'param_max_depth']\n",
    "\n",
    "# # Rearrange row order so it is easy to skim\n",
    "# random_forest_grid_search_results_df.sort_values(param_keys, inplace=True)\n",
    "# random_forest_grid_search_results_df[param_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_grid_searcher.fit(x_train_text_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_forest_grid_search_results_df = pd.DataFrame(random_forest_grid_searcher.cv_results_).copy()\n",
    "# n_trials_grid_search = random_forest_grid_search_results_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_keys = ['param_n_estimators', 'param_max_depth']\n",
    "\n",
    "# Rearrange row order so it is easy to skim\n",
    "# random_forest_grid_search_results_df.sort_values(param_keys, inplace=True)\n",
    "# random_forest_grid_search_results_df[param_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_random_forest = random_forest_classifier.set_params(**random_forest_grid_searcher.best_params_)\n",
    "# best_random_forest.fit(x_train_text_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient Boosted Tree classifier with default values\n",
    "# gbtree_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=5, min_samples_leaf=1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient Boosted Tree hyperparameter grid\n",
    "# gbtree_parameter_grid = dict(\n",
    "#     n_estimators = [20, 50, 100],\n",
    "#     max_depth = [5, 10],\n",
    "#     #min_samples_leaf = [1, 3, 5],\n",
    "#     #random_state=[101, 202],  # try two possible seeds to initialize parameters\n",
    "#     random_state=[100],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbtree_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "#     gbtree_classifier,\n",
    "#     gbtree_parameter_grid,\n",
    "#     scoring='balanced_accuracy',\n",
    "#     cv=cv_splitter,\n",
    "#     return_train_score=True,\n",
    "#     refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbtree_grid_searcher.fit(x_train_text_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gbtree_grid_search_results_df = pd.DataFrame(gbtree_grid_searcher.cv_results_).copy()\n",
    "# n_trials_grid_search = gbtree_grid_search_results_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_keys = ['param_n_estimators', 'param_max_depth']\n",
    "\n",
    "# # Rearrange row order so it is easy to skim\n",
    "# gbtree_grid_search_results_df.sort_values(param_keys, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gbtree_grid_search_results_df[param_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_gbtree = gbtree_classifier.set_params(**gbtree_grid_searcher.best_params_)\n",
    "# best_gbtree.fit(x_train_text_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_gbtree_yhat_test = best_gbtree.predict(x_test_text_count)\n",
    "# with open('bow_gbtree_countvectorizer_test_preds.txt', 'w') as f:\n",
    "#     for pred in best_gbtree_yhat_test:\n",
    "#         f.write(str(pred) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso = sklearn.linear_model.LogisticRegression(\n",
    "#     penalty='l1', solver='saga', random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_hyperparameter_grid_by_name = dict(\n",
    "#     C=np.logspace(-4, 4, 9),\n",
    "#     max_iter=[20, 40], # sneaky way to do \"early stopping\" \n",
    "#                        # we'll take either iter 20 or iter 40 in training process, by best valid performance\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_searcher = sklearn.model_selection.GridSearchCV(\n",
    "#     lasso,\n",
    "#     lasso_hyperparameter_grid_by_name,\n",
    "#     scoring='balanced_accuracy',\n",
    "#     cv=cv_splitter,\n",
    "#     return_train_score=True,\n",
    "#     refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_searcher.fit(x_train_text_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_search_results_df = pd.DataFrame(lasso_searcher.cv_results_).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_keys = ['param_C', 'param_max_iter']\n",
    "\n",
    "# # Rearrange row order so it is easy to skim\n",
    "# lasso_search_results_df.sort_values(param_keys, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_search_results_df[param_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lasso = lasso.set_params(**lasso_searcher.best_params_)\n",
    "# best_lasso.fit(x_train_text_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_lasso_yhat_test = best_lasso.predict_proba(x_test_text_count)[:,1]\n",
    "# np.savetxt('yproba1_test.txt', best_lasso_yhat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
