{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project B: Problem 1 Classifier Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import cleaned data (using HW4 data for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "x_tr_NF.shape: (6346, 7729)\n",
      "y_tr_N.shape : (6346,)\n",
      "mean(y_tr_N) : 0.500\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(\"../hw4/data_product_reviews/\")\n",
    "x_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'x_train.csv.zip'))\n",
    "y_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'y_train.csv'))\n",
    "x_tr_NF = np.minimum(x_tr_df.values, 1.0).copy()\n",
    "y_tr_N = y_tr_df.values[:,0].copy()\n",
    "\n",
    "print(\"Training data\")\n",
    "print(\"x_tr_NF.shape: %s\" % str(x_tr_NF.shape))\n",
    "print(\"y_tr_N.shape : %s\" % str(y_tr_N.shape))\n",
    "print(\"mean(y_tr_N) : %.3f\" % np.mean(y_tr_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Even smaller dataset\n",
    "HW4 dataset took too long for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generated this training set for you.\n",
    "\n",
    "N = 12\n",
    "\n",
    "x_tr_N = np.asarray([\n",
    "    -0.975, -0.825, -0.603, -0.378, -0.284, -0.102,\n",
    "     0.169,  0.311,  0.431,  0.663,  0.795,  0.976])\n",
    "x_tr_NF = x_tr_N.reshape((N,1)) # need an (N,1) shaped array for later use with sklearn\n",
    "\n",
    "y_tr_N = np.asarray([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(n_examples=10, seed=101, flip_fraction=0.15):\n",
    "    N = int(n_examples)\n",
    "    prng = np.random.RandomState(seed)\n",
    "\n",
    "    # Make x values between -1 and 1, roughly evenly spaced\n",
    "    x_N = np.linspace(-1, 1, N) + 0.05 * prng.randn(N)\n",
    "\n",
    "    # Make y values such that broadly, the true function says:\n",
    "    # y_n = 1  if x_n > 0 \n",
    "    # y_n = 0  otherwise\n",
    "    y_N = np.asarray(x_N > 0, dtype=np.int32)\n",
    "\n",
    "    # flip a small percentage of the values\n",
    "    chosen_ids = prng.permutation(np.arange(N))[:int(np.floor(flip_fraction * N))]\n",
    "    y_N[chosen_ids] = 1 - y_N[chosen_ids]\n",
    "    return x_N.reshape((N,1)), y_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 100\n",
    "x_va_MF, y_va_M = make_dataset(n_examples=M, seed=201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training samples = 12\n",
      "Fraction positive training samples = 0.5\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = x_tr_NF.shape[0]\n",
    "num_positive_train_samples = np.count_nonzero(y_tr_N == 1)\n",
    "fraction_positive_train = float(num_positive_train_samples) / float(num_train_samples)\n",
    "\n",
    "\n",
    "print(f\"Total number of training samples = {num_train_samples}\")\n",
    "print(f\"Fraction positive training samples = {fraction_positive_train}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "#cv_splitter.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter searcher: Gradient Boosted Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Tree classifier with default values\n",
    "gbtree_classifier = sklearn.ensemble.GradientBoostingClassifier(n_estimators=100, max_depth=5, min_samples_leaf=1, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Tree hyperparameter grid\n",
    "gbtree_parameter_grid = dict(\n",
    "    n_estimators = [20, 50, 100],\n",
    "    max_depth = [5, 10],\n",
    "    #min_samples_leaf = [1, 3, 5],\n",
    "    #random_state=[101, 202],  # try two possible seeds to initialize parameters\n",
    "    random_state=[100],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree_grid_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    gbtree_classifier,\n",
    "    gbtree_parameter_grid,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv_splitter,\n",
    "    return_train_score=True,\n",
    "    refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=GradientBoostingClassifier(max_depth=5, n_estimators=20,\n",
       "                                                  random_state=101),\n",
       "             param_grid={'max_depth': [5, 10], 'n_estimators': [20, 50, 100],\n",
       "                         'random_state': [100]},\n",
       "             refit=False, return_train_score=True, scoring='balanced_accuracy')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtree_grid_searcher.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick the best version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (6, 23)\n",
      "Dataframe has columns:\n",
      "-- mean_fit_time\n",
      "-- std_fit_time\n",
      "-- mean_score_time\n",
      "-- std_score_time\n",
      "-- param_max_depth\n",
      "-- param_n_estimators\n",
      "-- param_random_state\n",
      "-- params\n",
      "-- split0_test_score\n",
      "-- split1_test_score\n",
      "-- split2_test_score\n",
      "-- split3_test_score\n",
      "-- split4_test_score\n",
      "-- mean_test_score\n",
      "-- std_test_score\n",
      "-- rank_test_score\n",
      "-- split0_train_score\n",
      "-- split1_train_score\n",
      "-- split2_train_score\n",
      "-- split3_train_score\n",
      "-- split4_train_score\n",
      "-- mean_train_score\n",
      "-- std_train_score\n"
     ]
    }
   ],
   "source": [
    "gbtree_grid_search_results_df = pd.DataFrame(gbtree_grid_searcher.cv_results_).copy()\n",
    "print(\"Dataframe has shape: %s\" % (str(gbtree_grid_search_results_df.shape)))\n",
    "n_trials_grid_search = gbtree_grid_search_results_df.shape[0]\n",
    "\n",
    "print(\"Dataframe has columns:\")\n",
    "for c in gbtree_grid_search_results_df.columns:\n",
    "    print(\"-- %s\" % c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_keys = ['param_n_estimators', 'param_max_depth']\n",
    "\n",
    "# Rearrange row order so it is easy to skim\n",
    "gbtree_grid_search_results_df.sort_values(param_keys, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth  mean_train_score  mean_test_score  \\\n",
       "0                 20               5               1.0             0.75   \n",
       "3                 20              10               1.0             0.75   \n",
       "1                 50               5               1.0             0.75   \n",
       "4                 50              10               1.0             0.75   \n",
       "2                100               5               1.0             0.75   \n",
       "5                100              10               1.0             0.75   \n",
       "\n",
       "   rank_test_score  \n",
       "0                1  \n",
       "3                1  \n",
       "1                1  \n",
       "4                1  \n",
       "2                1  \n",
       "5                1  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbtree_grid_search_results_df[param_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, n_estimators=20, random_state=100)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbtree = gbtree_classifier.set_params(**gbtree_grid_searcher.best_params_)\n",
    "best_gbtree.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4), sharex=True, sharey=True)\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    tr_label = 'train log loss' if run_id == 0 else ''\n",
    "    te_label = 'test log loss' if run_id == 0 else ''\n",
    "    \n",
    "    loss_ax.plot(np.log2(size_list), tr_loss_arr[:,run_id], 'bd', label=tr_label)\n",
    "    loss_ax.plot(np.log2(size_list), te_loss_arr[:,run_id], 'rd', label=te_label)\n",
    "\n",
    "loss_ax.set_xticks(np.log2(size_list));\n",
    "loss_ax.set_xticklabels(size_list);\n",
    "loss_ax.xaxis.grid(False);\n",
    "\n",
    "loss_ax.set_ylim([0, 0.8]); # Don't touch this please\n",
    "loss_ax.set_yticks(np.arange(0, 0.8, 0.1));\n",
    "loss_ax.set_title(\"Log Loss vs Size\")\n",
    "loss_ax.set_ylabel('log loss');\n",
    "loss_ax.set_xlabel('size');\n",
    "loss_ax.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search: L1-Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.LogisticRegression(\n",
    "    penalty='l1', solver='saga', random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_hyperparameter_grid_by_name = dict(\n",
    "    C=np.logspace(-4, 4, 9),\n",
    "    max_iter=[20, 40], # sneaky way to do \"early stopping\" \n",
    "                       # we'll take either iter 20 or iter 40 in training process, by best valid performance\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_searcher = sklearn.model_selection.GridSearchCV(\n",
    "    lasso,\n",
    "    lasso_hyperparameter_grid_by_name,\n",
    "    scoring='balanced_accuracy',\n",
    "    cv=cv_splitter,\n",
    "    return_train_score=True,\n",
    "    refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(penalty='l1', random_state=101,\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': array([1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03,\n",
       "       1.e+04]),\n",
       "                         'max_iter': [20, 40]},\n",
       "             refit=False, return_train_score=True, scoring='balanced_accuracy')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_searcher.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_search_results_df = pd.DataFrame(lasso_searcher.cv_results_).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, max_iter=20, penalty='l1', random_state=101,\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lasso = lasso.set_params(**lasso_searcher.best_params_)\n",
    "best_lasso.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
