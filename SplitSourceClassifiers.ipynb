{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split-Source Classifiers\n",
    "Ensemble of classifiers based on the source of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import sklearn.neural_network\n",
    "\n",
    "# Custom functions \n",
    "# Custom functions \n",
    "from utils import (\n",
    "    print_gridsearch_results, \n",
    "    test_on_estimator, \n",
    "    plot_cv_train_test, \n",
    "    plot_cv_folds, \n",
    "    analysis_of_mistakes,\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "---------------\n",
      "x_train_df shape: (2400, 2) \n",
      "x_test_df shape: (600, 2) \n",
      "y_train_df shape: (2400, 1) \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['amazon', 'imdb', 'yelp'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'data_reviews'\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "# Where to output predictions on the test_set\n",
    "x_test_df = pd.read_csv(os.path.join(data_dir, 'x_test.csv'))\n",
    "output_dir = 'split_source_predictions'\n",
    "\n",
    "print(\"Shape of data\\n---------------\")\n",
    "print(f\"x_train_df shape: {x_train_df.shape} \")\n",
    "print(f\"x_test_df shape: {x_test_df.shape} \")\n",
    "print(f\"y_train_df shape: {y_train_df.shape} \")\n",
    "\n",
    "# # Get the text as a list of strings\n",
    "# x_train_text = x_train_df['text'].values\n",
    "# x_test_text = x_test_df['text'].values\n",
    "# y_train = y_train_df['is_positive_sentiment'].values\n",
    "\n",
    "# Get list of website names\n",
    "x_train_df['website_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website_name</th>\n",
       "      <th>text</th>\n",
       "      <th>is_positive_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Oh and I forgot to also mention the weird colo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>THAT one didn't work either.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Waste of 13 bucks.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon</td>\n",
       "      <td>Product is useless, since it does not have eno...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon</td>\n",
       "      <td>None of the three sizes they sent with the hea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>yelp</td>\n",
       "      <td>The sweet potato fries were very good and seas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>yelp</td>\n",
       "      <td>I could eat their bruschetta all day it is dev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Ambience is perfect.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>yelp</td>\n",
       "      <td>We ordered the duck rare and it was pink and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2399</th>\n",
       "      <td>yelp</td>\n",
       "      <td>Service was good and the company was better!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     website_name                                               text  \\\n",
       "0          amazon  Oh and I forgot to also mention the weird colo...   \n",
       "1          amazon                       THAT one didn't work either.   \n",
       "2          amazon                                 Waste of 13 bucks.   \n",
       "3          amazon  Product is useless, since it does not have eno...   \n",
       "4          amazon  None of the three sizes they sent with the hea...   \n",
       "...           ...                                                ...   \n",
       "2395         yelp  The sweet potato fries were very good and seas...   \n",
       "2396         yelp  I could eat their bruschetta all day it is dev...   \n",
       "2397         yelp                               Ambience is perfect.   \n",
       "2398         yelp  We ordered the duck rare and it was pink and t...   \n",
       "2399         yelp       Service was good and the company was better!   \n",
       "\n",
       "      is_positive_sentiment  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "...                     ...  \n",
       "2395                      1  \n",
       "2396                      1  \n",
       "2397                      1  \n",
       "2398                      1  \n",
       "2399                      1  \n",
       "\n",
       "[2400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataset = pd.concat((x_train_df, y_train_df), axis=1)\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_train = combined_dataset[combined_dataset['website_name'] == 'amazon']\n",
    "amazon_x_train = amazon_train['text'].values\n",
    "amazon_y_train = amazon_train['is_positive_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = combined_dataset[combined_dataset['website_name'] == 'imdb']\n",
    "imdb_x_train = imdb_train['text'].values\n",
    "imdb_y_train = imdb_train['is_positive_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_train = combined_dataset[combined_dataset['website_name'] == 'yelp']\n",
    "yelp_x_train = yelp_train['text'].values\n",
    "yelp_y_train = yelp_train['is_positive_sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_x_df = x_test_df[x_test_df['website_name'] == 'amazon']\n",
    "imdb_x_df = x_test_df[x_test_df['website_name'] == 'imdb']\n",
    "yelp_x_df = x_test_df[x_test_df['website_name'] == 'yelp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define stable CV-splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = sklearn.model_selection.StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct TFIDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# #  Parameters for grid search\n",
    "# tf_parameters = { \n",
    "#     'tf__min_df': np.arange(1,3),\n",
    "#     'tf__max_df': (0.05, 0.5),\n",
    "#     'tf__ngram_range': [(1, 1), (1, 2)],\n",
    "# }\n",
    "\n",
    "# Static Parameters based on earlier grid_search \n",
    "tf_vectorizer.set_params(min_df = 1, ngram_range = (1,2))\n",
    "\n",
    "# Set the tuple for the pipeline\n",
    "tf_pipeline_tuple = (\"tf\", tf_vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1-Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.LogisticRegression(penalty='l1', solver='saga', random_state=RANDOM_STATE)\n",
    "# logit_lasso hyperparameter grid\n",
    "lasso_parameters = {\n",
    "     'lasso__C': np.logspace(-3, 3, 7),\n",
    "     'lasso__max_iter': [20, 40, 60], # sneaky way to do \"early stopping\" \n",
    "}\n",
    "lasso_pipeline_tuple = ('lasso', lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train L1-LR classifier on Amazon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  31 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=3)]: Done 105 out of 105 | elapsed:    9.9s finished\n",
      "/Users/dylanphelan/opt/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('lasso',\n",
       "                                        LogisticRegression(penalty='l1',\n",
       "                                                           random_state=123,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'lasso__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'lasso__max_iter': [20, 40, 60]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_tf_lasso_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    lasso_pipeline_tuple,\n",
    " ])\n",
    "amazon_tf_lasso_full_grid = { \n",
    "#     **count_parameters,\n",
    "    **lasso_parameters\n",
    "}\n",
    "\n",
    "\n",
    "amazon_tf_lasso_grid_searcher = GridSearchCV(\n",
    "    amazon_tf_lasso_pipeline, \n",
    "    amazon_tf_lasso_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "amazon_tf_lasso_grid_searcher.fit(amazon_x_train, amazon_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (21, 22)\n",
      "Number of trials used in grid search:  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__C</th>\n",
       "      <th>param_lasso__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.81000</td>\n",
       "      <td>0.621128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80750</td>\n",
       "      <td>0.470451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>0.258704</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000</td>\n",
       "      <td>60</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80125</td>\n",
       "      <td>0.806793</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>0.563114</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>0.083791</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.997812</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>0.122280</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79500</td>\n",
       "      <td>0.285502</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.997812</td>\n",
       "      <td>0.79500</td>\n",
       "      <td>0.158897</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.757188</td>\n",
       "      <td>0.75250</td>\n",
       "      <td>0.028437</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.757188</td>\n",
       "      <td>0.75250</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.757188</td>\n",
       "      <td>0.75250</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.018288</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.017146</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.017394</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.020110</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.027532</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_lasso__C param_lasso__max_iter  mean_train_score  mean_test_score  \\\n",
       "17            100                    60          0.998125          0.81000   \n",
       "16            100                    40          0.998125          0.80750   \n",
       "15            100                    20          0.998125          0.80375   \n",
       "20           1000                    60          0.998125          0.80125   \n",
       "19           1000                    40          0.998125          0.80000   \n",
       "12             10                    20          0.997500          0.79750   \n",
       "13             10                    40          0.997812          0.79625   \n",
       "18           1000                    20          0.998125          0.79500   \n",
       "14             10                    60          0.997812          0.79500   \n",
       "11              1                    60          0.757188          0.75250   \n",
       "10              1                    40          0.757188          0.75250   \n",
       "9               1                    20          0.757188          0.75250   \n",
       "8             0.1                    60          0.500000          0.50000   \n",
       "7             0.1                    40          0.500000          0.50000   \n",
       "6             0.1                    20          0.500000          0.50000   \n",
       "5            0.01                    60          0.500000          0.50000   \n",
       "4            0.01                    40          0.500000          0.50000   \n",
       "3            0.01                    20          0.500000          0.50000   \n",
       "2           0.001                    60          0.500000          0.50000   \n",
       "1           0.001                    40          0.500000          0.50000   \n",
       "0           0.001                    20          0.500000          0.50000   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "17       0.621128                1  \n",
       "16       0.470451                2  \n",
       "15       0.258704                3  \n",
       "20       0.806793                4  \n",
       "19       0.563114                5  \n",
       "12       0.083791                6  \n",
       "13       0.122280                7  \n",
       "18       0.285502                8  \n",
       "14       0.158897                9  \n",
       "11       0.028437               10  \n",
       "10       0.027422               10  \n",
       "9        0.022620               10  \n",
       "8        0.018358               13  \n",
       "7        0.018288               13  \n",
       "6        0.018498               13  \n",
       "5        0.017146               13  \n",
       "4        0.017072               13  \n",
       "3        0.017394               13  \n",
       "2        0.023828               13  \n",
       "1        0.020110               13  \n",
       "0        0.027532               13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(amazon_tf_lasso_grid_searcher, list(amazon_tf_lasso_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4233"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(amazon_tf_lasso_grid_searcher.best_estimator_[0].vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train L1-LR pipeline on IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 105 | elapsed:    9.4s remaining:    0.5s\n",
      "[Parallel(n_jobs=3)]: Done 105 out of 105 | elapsed:   10.4s finished\n",
      "/Users/dylanphelan/opt/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('lasso',\n",
       "                                        LogisticRegression(penalty='l1',\n",
       "                                                           random_state=123,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'lasso__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'lasso__max_iter': [20, 40, 60]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_tf_lasso_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    lasso_pipeline_tuple,\n",
    " ])\n",
    "imdb_tf_lasso_full_grid = { \n",
    "#     **count_parameters,\n",
    "    **lasso_parameters\n",
    "}\n",
    "\n",
    "\n",
    "imdb_tf_lasso_grid_searcher = GridSearchCV(\n",
    "    imdb_tf_lasso_pipeline, \n",
    "    imdb_tf_lasso_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "imdb_tf_lasso_grid_searcher.fit(imdb_x_train, imdb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (21, 22)\n",
      "Number of trials used in grid search:  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__C</th>\n",
       "      <th>param_lasso__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.279127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75375</td>\n",
       "      <td>0.410488</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75375</td>\n",
       "      <td>0.897405</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.886791</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.74875</td>\n",
       "      <td>0.436201</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.74875</td>\n",
       "      <td>0.689389</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.74500</td>\n",
       "      <td>0.127068</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.996562</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>0.205664</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>0.161936</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.632188</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.049260</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.632188</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.632812</td>\n",
       "      <td>0.59000</td>\n",
       "      <td>0.028492</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.024193</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.025568</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.034032</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.026871</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.024171</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.033804</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.025320</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.027788</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_lasso__C param_lasso__max_iter  mean_train_score  mean_test_score  \\\n",
       "20           1000                    60          1.000000          0.75625   \n",
       "15            100                    20          1.000000          0.75375   \n",
       "19           1000                    40          1.000000          0.75375   \n",
       "17            100                    60          1.000000          0.75000   \n",
       "18           1000                    20          1.000000          0.74875   \n",
       "16            100                    40          1.000000          0.74875   \n",
       "12             10                    20          0.995000          0.74500   \n",
       "14             10                    60          0.996562          0.73875   \n",
       "13             10                    40          0.995937          0.73625   \n",
       "11              1                    60          0.632188          0.59375   \n",
       "10              1                    40          0.632188          0.59375   \n",
       "9               1                    20          0.632812          0.59000   \n",
       "8             0.1                    60          0.500000          0.50000   \n",
       "7             0.1                    40          0.500000          0.50000   \n",
       "6             0.1                    20          0.500000          0.50000   \n",
       "5            0.01                    60          0.500000          0.50000   \n",
       "4            0.01                    40          0.500000          0.50000   \n",
       "3            0.01                    20          0.500000          0.50000   \n",
       "2           0.001                    60          0.500000          0.50000   \n",
       "1           0.001                    40          0.500000          0.50000   \n",
       "0           0.001                    20          0.500000          0.50000   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "20       1.279127                1  \n",
       "15       0.410488                2  \n",
       "19       0.897405                2  \n",
       "17       0.886791                4  \n",
       "18       0.436201                5  \n",
       "16       0.689389                5  \n",
       "12       0.127068                7  \n",
       "14       0.205664                8  \n",
       "13       0.161936                9  \n",
       "11       0.049260               10  \n",
       "10       0.035357               10  \n",
       "9        0.028492               12  \n",
       "8        0.024193               13  \n",
       "7        0.025568               13  \n",
       "6        0.034032               13  \n",
       "5        0.026871               13  \n",
       "4        0.024171               13  \n",
       "3        0.033804               13  \n",
       "2        0.025320               13  \n",
       "1        0.027290               13  \n",
       "0        0.027788               13  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(imdb_tf_lasso_grid_searcher, list(imdb_tf_lasso_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6749"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_tf_lasso_grid_searcher.best_estimator_[0].vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train L1-LR pipeline on Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  74 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 105 | elapsed:    6.8s remaining:    0.3s\n",
      "[Parallel(n_jobs=3)]: Done 105 out of 105 | elapsed:    7.5s finished\n",
      "/Users/dylanphelan/opt/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('lasso',\n",
       "                                        LogisticRegression(penalty='l1',\n",
       "                                                           random_state=123,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'lasso__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'lasso__max_iter': [20, 40, 60]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_tf_lasso_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    lasso_pipeline_tuple,\n",
    " ])\n",
    "yelp_tf_lasso_full_grid = { \n",
    "#     **count_parameters,\n",
    "    **lasso_parameters\n",
    "}\n",
    "\n",
    "\n",
    "yelp_tf_lasso_grid_searcher = GridSearchCV(\n",
    "    yelp_tf_lasso_pipeline, \n",
    "    yelp_tf_lasso_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "yelp_tf_lasso_grid_searcher.fit(yelp_x_train, yelp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (21, 22)\n",
      "Number of trials used in grid search:  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__C</th>\n",
       "      <th>param_lasso__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.491751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.610252</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.271898</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000</td>\n",
       "      <td>60</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>0.904340</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78375</td>\n",
       "      <td>0.653458</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.305852</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.77750</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.138057</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.76875</td>\n",
       "      <td>0.173914</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.029209</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.028961</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.020765</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.018864</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.020873</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.020937</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_lasso__C param_lasso__max_iter  mean_train_score  mean_test_score  \\\n",
       "16            100                    40          0.997500          0.78750   \n",
       "19           1000                    40          0.997500          0.78625   \n",
       "15            100                    20          0.997500          0.78625   \n",
       "20           1000                    60          0.997500          0.78500   \n",
       "17            100                    60          0.997500          0.78375   \n",
       "18           1000                    20          0.997500          0.78125   \n",
       "12             10                    20          0.997188          0.77750   \n",
       "13             10                    40          0.997188          0.77500   \n",
       "14             10                    60          0.997500          0.76875   \n",
       "11              1                    60          0.742500          0.72000   \n",
       "10              1                    40          0.742500          0.72000   \n",
       "9               1                    20          0.742188          0.72000   \n",
       "8             0.1                    60          0.500000          0.50000   \n",
       "7             0.1                    40          0.500000          0.50000   \n",
       "6             0.1                    20          0.500000          0.50000   \n",
       "5            0.01                    60          0.500000          0.50000   \n",
       "4            0.01                    40          0.500000          0.50000   \n",
       "3            0.01                    20          0.500000          0.50000   \n",
       "2           0.001                    60          0.500000          0.50000   \n",
       "1           0.001                    40          0.500000          0.50000   \n",
       "0           0.001                    20          0.500000          0.50000   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "16       0.491751                1  \n",
       "19       0.610252                2  \n",
       "15       0.271898                3  \n",
       "20       0.904340                4  \n",
       "17       0.653458                5  \n",
       "18       0.305852                6  \n",
       "12       0.090821                7  \n",
       "13       0.138057                8  \n",
       "14       0.173914                9  \n",
       "11       0.029209               10  \n",
       "10       0.028961               10  \n",
       "9        0.023117               10  \n",
       "8        0.020765               13  \n",
       "7        0.018864               13  \n",
       "6        0.018871               13  \n",
       "5        0.023159               13  \n",
       "4        0.021173               13  \n",
       "3        0.020873               13  \n",
       "2        0.017852               13  \n",
       "1        0.020937               13  \n",
       "0        0.021363               13  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(yelp_tf_lasso_grid_searcher, list(yelp_tf_lasso_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4613"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yelp_tf_lasso_grid_searcher.best_estimator_[0].vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate L1-LR test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_lasso_filename = os.path.join(output_dir, 'splitsource_tf_lasso_yproba1_test.txt')\n",
    "\n",
    "# amazon_x_test = tf_vectorizer(amazon_x_df['text'].values)\n",
    "amazon_yhat_positive_proba = amazon_tf_lasso_grid_searcher.best_estimator_.predict_proba(amazon_x_df['text'].values)[:, 1]\n",
    "\n",
    "# imdb_x_test = tf_vectorizer(imdb_x_df['text'].values)\n",
    "imdb_yhat_positive_proba = imdb_tf_lasso_grid_searcher.best_estimator_.predict_proba(imdb_x_df['text'].values)[:, 1]\n",
    "\n",
    "# yelp_x_test = tf_vectorizer(yelp_x_df['text'].values)\n",
    "yelp_yhat_positive_proba = yelp_tf_lasso_grid_searcher.best_estimator_.predict_proba(yelp_x_df['text'].values)[:, 1]\n",
    "\n",
    "np.savetxt(tf_lasso_filename, np.r_[amazon_yhat_positive_proba, imdb_yhat_positive_proba, yelp_yhat_positive_proba])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Pipeline on Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = sklearn.neural_network.MLPClassifier(solver='lbfgs', random_state=RANDOM_STATE)\n",
    "mlp_parameters = {\n",
    "    'mlp__hidden_layer_sizes': [16, 32, 64],\n",
    "    'mlp__alpha': [0.0001,0.01,1, 10],\n",
    "    'mlp__max_iter': [50, 100, 200, 500], # sneaky way to do \"early stopping\" \n",
    "}\n",
    "mlp_pipeline_tuple = ('mlp', mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MLP pipeline on Amazon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   59.7s\n"
     ]
    }
   ],
   "source": [
    "amazon_tf_mlp_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    mlp_pipeline_tuple,\n",
    " ])\n",
    "amazon_tf_mlp_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **mlp_parameters\n",
    "}\n",
    "\n",
    "\n",
    "amazon_tf_mlp_grid_searcher = GridSearchCV(\n",
    "    amazon_tf_mlp_pipeline, \n",
    "    amazon_tf_mlp_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "amazon_tf_mlp_grid_searcher.fit(amazon_x_train, amazon_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (48, 23)\n",
      "Number of trials used in grid search:  48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_mlp__hidden_layer_sizes</th>\n",
       "      <th>param_mlp__alpha</th>\n",
       "      <th>param_mlp__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>1.870596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>3.189671</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>1.391155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>1.625681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>1.832335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>0.806531</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>0.813847</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>0.835278</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>0.816622</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>3.261040</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>3.430442</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.80250</td>\n",
       "      <td>3.270794</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>1.076959</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>1.058419</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>1.084706</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79750</td>\n",
       "      <td>1.248658</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>3.617861</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>3.376180</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>3.766261</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>2.052726</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>2.073857</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>1.724832</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>1.520922</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>0.972595</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>0.999253</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79625</td>\n",
       "      <td>0.980080</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79375</td>\n",
       "      <td>0.849253</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>3.086631</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>2.448125</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>2.478969</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>1.105167</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>0.783718</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>0.992333</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>1.032527</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>0.742170</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>0.986996</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>0.961588</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>2.268562</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>2.585348</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.78875</td>\n",
       "      <td>0.765013</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.977653</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.897146</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.761782</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>0.966232</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>1.757886</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>1.862650</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>1.788689</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>1.636756</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_mlp__hidden_layer_sizes param_mlp__alpha param_mlp__max_iter  \\\n",
       "30                            32                1                 200   \n",
       "32                            64                1                  50   \n",
       "28                            32                1                  50   \n",
       "29                            32                1                 100   \n",
       "31                            32                1                 500   \n",
       "24                            16                1                  50   \n",
       "25                            16                1                 100   \n",
       "26                            16                1                 200   \n",
       "27                            16                1                 500   \n",
       "35                            64                1                 500   \n",
       "33                            64                1                 100   \n",
       "34                            64                1                 200   \n",
       "7                             32           0.0001                 500   \n",
       "6                             32           0.0001                 200   \n",
       "5                             32           0.0001                 100   \n",
       "4                             32           0.0001                  50   \n",
       "22                            64             0.01                 200   \n",
       "21                            64             0.01                 100   \n",
       "23                            64             0.01                 500   \n",
       "18                            32             0.01                 200   \n",
       "17                            32             0.01                 100   \n",
       "19                            32             0.01                 500   \n",
       "16                            32             0.01                  50   \n",
       "15                            16             0.01                 500   \n",
       "14                            16             0.01                 200   \n",
       "13                            16             0.01                 100   \n",
       "12                            16             0.01                  50   \n",
       "20                            64             0.01                  50   \n",
       "45                            64               10                 100   \n",
       "44                            64               10                  50   \n",
       "43                            32               10                 500   \n",
       "39                            16               10                 500   \n",
       "41                            32               10                 100   \n",
       "40                            32               10                  50   \n",
       "38                            16               10                 200   \n",
       "42                            32               10                 200   \n",
       "37                            16               10                 100   \n",
       "47                            64               10                 500   \n",
       "46                            64               10                 200   \n",
       "36                            16               10                  50   \n",
       "3                             16           0.0001                 500   \n",
       "2                             16           0.0001                 200   \n",
       "1                             16           0.0001                 100   \n",
       "0                             16           0.0001                  50   \n",
       "11                            64           0.0001                 500   \n",
       "10                            64           0.0001                 200   \n",
       "9                             64           0.0001                 100   \n",
       "8                             64           0.0001                  50   \n",
       "\n",
       "    mean_train_score  mean_test_score  mean_fit_time  rank_test_score  \n",
       "30          0.998125          0.80375       1.870596                1  \n",
       "32          0.998125          0.80375       3.189671                1  \n",
       "28          0.998125          0.80375       1.391155                1  \n",
       "29          0.998125          0.80375       1.625681                1  \n",
       "31          0.998125          0.80375       1.832335                1  \n",
       "24          0.998125          0.80250       0.806531                6  \n",
       "25          0.998125          0.80250       0.813847                6  \n",
       "26          0.998125          0.80250       0.835278                6  \n",
       "27          0.998125          0.80250       0.816622                6  \n",
       "35          0.998125          0.80250       3.261040                6  \n",
       "33          0.998125          0.80250       3.430442                6  \n",
       "34          0.998125          0.80250       3.270794                6  \n",
       "7           0.998125          0.79750       1.076959               13  \n",
       "6           0.998125          0.79750       1.058419               13  \n",
       "5           0.998125          0.79750       1.084706               13  \n",
       "4           0.998125          0.79750       1.248658               13  \n",
       "22          0.998125          0.79625       3.617861               17  \n",
       "21          0.998125          0.79625       3.376180               17  \n",
       "23          0.998125          0.79625       3.766261               17  \n",
       "18          0.998125          0.79625       2.052726               17  \n",
       "17          0.998125          0.79625       2.073857               17  \n",
       "19          0.998125          0.79625       1.724832               17  \n",
       "16          0.998125          0.79625       1.520922               23  \n",
       "15          0.998125          0.79625       0.972595               23  \n",
       "14          0.998125          0.79625       0.999253               23  \n",
       "13          0.998125          0.79625       0.980080               23  \n",
       "12          0.998125          0.79375       0.849253               27  \n",
       "20          0.998125          0.79125       3.086631               28  \n",
       "45          0.995937          0.78875       2.448125               29  \n",
       "44          0.995937          0.78875       2.478969               29  \n",
       "43          0.995937          0.78875       1.105167               29  \n",
       "39          0.995937          0.78875       0.783718               29  \n",
       "41          0.995937          0.78875       0.992333               29  \n",
       "40          0.995937          0.78875       1.032527               29  \n",
       "38          0.995937          0.78875       0.742170               29  \n",
       "42          0.995937          0.78875       0.986996               29  \n",
       "37          0.995937          0.78875       0.961588               29  \n",
       "47          0.995937          0.78875       2.268562               29  \n",
       "46          0.995937          0.78875       2.585348               29  \n",
       "36          0.995937          0.78875       0.765013               29  \n",
       "3           0.998125          0.78625       0.977653               41  \n",
       "2           0.998125          0.78625       0.897146               41  \n",
       "1           0.998125          0.78625       0.761782               41  \n",
       "0           0.998125          0.78625       0.966232               41  \n",
       "11          0.998125          0.78500       1.757886               45  \n",
       "10          0.998125          0.78500       1.862650               45  \n",
       "9           0.998125          0.78500       1.788689               45  \n",
       "8           0.998125          0.78500       1.636756               45  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(amazon_tf_mlp_grid_searcher, list(amazon_tf_mlp_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MLP pipeline on IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=3)]: Done 240 out of 240 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('mlp',\n",
       "                                        MLPClassifier(random_state=123,\n",
       "                                                      solver='lbfgs'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'mlp__alpha': [0.0001, 0.01, 1, 10],\n",
       "                         'mlp__hidden_layer_sizes': [16, 32, 64],\n",
       "                         'mlp__max_iter': [50, 100, 200, 500]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_tf_mlp_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    mlp_pipeline_tuple,\n",
    " ])\n",
    "imdb_tf_mlp_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **mlp_parameters\n",
    "}\n",
    "\n",
    "\n",
    "imdb_tf_mlp_grid_searcher = GridSearchCV(\n",
    "    imdb_tf_mlp_pipeline, \n",
    "    imdb_tf_mlp_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=5, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "imdb_tf_mlp_grid_searcher.fit(imdb_x_train, imdb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (48, 23)\n",
      "Number of trials used in grid search:  48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_mlp__hidden_layer_sizes</th>\n",
       "      <th>param_mlp__alpha</th>\n",
       "      <th>param_mlp__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>5.163308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>3.472196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>3.307467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.76000</td>\n",
       "      <td>3.197352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>6.490193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>1.531367</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>1.561036</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>6.062405</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>1.434991</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>1.776293</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.990313</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>2.073640</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.990313</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>2.016941</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>2.776016</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.990313</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>2.065502</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.990313</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>1.751868</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>6.596546</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>3.676050</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>3.627408</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>3.973319</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>3.604654</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.079937</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.317760</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.417637</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.407089</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>1.661819</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>1.638334</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>1.467985</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>1.517771</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>1.433412</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>1.253751</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>1.391858</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>1.356307</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>2.709105</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>2.641102</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>2.442638</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>1.056917</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.918986</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>0.961523</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73500</td>\n",
       "      <td>1.022263</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>3.455357</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>3.306357</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>3.470167</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>3.364509</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>5.201127</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>5.389540</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>2.304269</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>5.704602</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>5.888821</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_mlp__hidden_layer_sizes param_mlp__alpha param_mlp__max_iter  \\\n",
       "32                            64                1                  50   \n",
       "31                            32                1                 500   \n",
       "30                            32                1                 200   \n",
       "29                            32                1                 100   \n",
       "34                            64                1                 200   \n",
       "25                            16                1                 100   \n",
       "27                            16                1                 500   \n",
       "35                            64                1                 500   \n",
       "26                            16                1                 200   \n",
       "24                            16                1                  50   \n",
       "42                            32               10                 200   \n",
       "41                            32               10                 100   \n",
       "28                            32                1                  50   \n",
       "43                            32               10                 500   \n",
       "40                            32               10                  50   \n",
       "33                            64                1                 100   \n",
       "46                            64               10                 200   \n",
       "47                            64               10                 500   \n",
       "45                            64               10                 100   \n",
       "44                            64               10                  50   \n",
       "36                            16               10                  50   \n",
       "39                            16               10                 500   \n",
       "37                            16               10                 100   \n",
       "38                            16               10                 200   \n",
       "7                             32           0.0001                 500   \n",
       "6                             32           0.0001                 200   \n",
       "5                             32           0.0001                 100   \n",
       "4                             32           0.0001                  50   \n",
       "15                            16             0.01                 500   \n",
       "14                            16             0.01                 200   \n",
       "13                            16             0.01                 100   \n",
       "12                            16             0.01                  50   \n",
       "18                            32             0.01                 200   \n",
       "19                            32             0.01                 500   \n",
       "17                            32             0.01                 100   \n",
       "0                             16           0.0001                  50   \n",
       "3                             16           0.0001                 500   \n",
       "2                             16           0.0001                 200   \n",
       "1                             16           0.0001                 100   \n",
       "11                            64           0.0001                 500   \n",
       "10                            64           0.0001                 200   \n",
       "9                             64           0.0001                 100   \n",
       "8                             64           0.0001                  50   \n",
       "21                            64             0.01                 100   \n",
       "20                            64             0.01                  50   \n",
       "16                            32             0.01                  50   \n",
       "22                            64             0.01                 200   \n",
       "23                            64             0.01                 500   \n",
       "\n",
       "    mean_train_score  mean_test_score  mean_fit_time  rank_test_score  \n",
       "32          1.000000          0.76000       5.163308                1  \n",
       "31          1.000000          0.76000       3.472196                1  \n",
       "30          1.000000          0.76000       3.307467                1  \n",
       "29          1.000000          0.76000       3.197352                1  \n",
       "34          1.000000          0.75875       6.490193                5  \n",
       "25          1.000000          0.75875       1.531367                5  \n",
       "27          1.000000          0.75875       1.561036                5  \n",
       "35          1.000000          0.75875       6.062405                5  \n",
       "26          1.000000          0.75875       1.434991                5  \n",
       "24          1.000000          0.75750       1.776293               10  \n",
       "42          0.990313          0.75750       2.073640               10  \n",
       "41          0.990313          0.75750       2.016941               10  \n",
       "28          1.000000          0.75750       2.776016               10  \n",
       "43          0.990313          0.75750       2.065502               10  \n",
       "40          0.990313          0.75750       1.751868               10  \n",
       "33          1.000000          0.75750       6.596546               10  \n",
       "46          0.990625          0.75750       3.676050               17  \n",
       "47          0.990625          0.75750       3.627408               17  \n",
       "45          0.990625          0.75750       3.973319               17  \n",
       "44          0.990625          0.75750       3.604654               17  \n",
       "36          0.990625          0.75625       1.079937               21  \n",
       "39          0.990625          0.75625       1.317760               22  \n",
       "37          0.990625          0.75625       1.417637               22  \n",
       "38          0.990625          0.75625       1.407089               22  \n",
       "7           1.000000          0.73875       1.661819               25  \n",
       "6           1.000000          0.73875       1.638334               25  \n",
       "5           1.000000          0.73875       1.467985               25  \n",
       "4           1.000000          0.73875       1.517771               25  \n",
       "15          1.000000          0.73625       1.433412               29  \n",
       "14          1.000000          0.73625       1.253751               29  \n",
       "13          1.000000          0.73625       1.391858               29  \n",
       "12          1.000000          0.73625       1.356307               29  \n",
       "18          1.000000          0.73500       2.709105               33  \n",
       "19          1.000000          0.73500       2.641102               33  \n",
       "17          1.000000          0.73500       2.442638               33  \n",
       "0           1.000000          0.73500       1.056917               36  \n",
       "3           1.000000          0.73500       0.918986               36  \n",
       "2           1.000000          0.73500       0.961523               36  \n",
       "1           1.000000          0.73500       1.022263               36  \n",
       "11          1.000000          0.73375       3.455357               40  \n",
       "10          1.000000          0.73375       3.306357               40  \n",
       "9           1.000000          0.73375       3.470167               40  \n",
       "8           1.000000          0.73375       3.364509               40  \n",
       "21          1.000000          0.72875       5.201127               44  \n",
       "20          1.000000          0.72875       5.389540               44  \n",
       "16          1.000000          0.72875       2.304269               44  \n",
       "22          1.000000          0.72875       5.704602               44  \n",
       "23          1.000000          0.72875       5.888821               44  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(imdb_tf_mlp_grid_searcher, list(imdb_tf_mlp_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MLP pipeline on Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=3)]: Done 240 out of 240 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('mlp',\n",
       "                                        MLPClassifier(random_state=123,\n",
       "                                                      solver='lbfgs'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'mlp__alpha': [0.0001, 0.01, 1, 10],\n",
       "                         'mlp__hidden_layer_sizes': [16, 32, 64],\n",
       "                         'mlp__max_iter': [50, 100, 200, 500]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_tf_mlp_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    mlp_pipeline_tuple,\n",
    " ])\n",
    "yelp_tf_mlp_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **mlp_parameters\n",
    "}\n",
    "\n",
    "\n",
    "yelp_tf_mlp_grid_searcher = GridSearchCV(\n",
    "    yelp_tf_mlp_pipeline, \n",
    "    yelp_tf_mlp_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "yelp_tf_mlp_grid_searcher.fit(yelp_x_train, yelp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (48, 23)\n",
      "Number of trials used in grid search:  48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_mlp__hidden_layer_sizes</th>\n",
       "      <th>param_mlp__alpha</th>\n",
       "      <th>param_mlp__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.993125</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>0.929766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>1.423992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.993125</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>1.022622</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>1.341438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>1.408300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>1.420648</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.993125</td>\n",
       "      <td>0.79125</td>\n",
       "      <td>0.968841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79000</td>\n",
       "      <td>2.278597</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79000</td>\n",
       "      <td>2.364537</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.993125</td>\n",
       "      <td>0.79000</td>\n",
       "      <td>0.764004</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79000</td>\n",
       "      <td>2.409441</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.79000</td>\n",
       "      <td>2.306146</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>2.095515</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>2.103648</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>1.694779</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>2.085668</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>1.347743</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>1.335489</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78625</td>\n",
       "      <td>1.209501</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>3.450926</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>3.457491</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>4.087090</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>1.696395</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>0.851499</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78500</td>\n",
       "      <td>0.891334</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78375</td>\n",
       "      <td>3.183879</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78375</td>\n",
       "      <td>1.147813</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78375</td>\n",
       "      <td>2.255135</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78375</td>\n",
       "      <td>2.331455</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>2.449228</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>2.497103</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>2.452053</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>0.815648</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>1.214859</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>1.303934</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78250</td>\n",
       "      <td>1.208104</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>2.345142</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.936448</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>2.315766</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>1.215835</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>1.213987</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>1.208065</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>4.570219</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>4.669880</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>4.703189</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77625</td>\n",
       "      <td>0.994732</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77625</td>\n",
       "      <td>0.990063</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>3.371425</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_mlp__hidden_layer_sizes param_mlp__alpha param_mlp__max_iter  \\\n",
       "37                            16               10                 100   \n",
       "43                            32               10                 500   \n",
       "38                            16               10                 200   \n",
       "42                            32               10                 200   \n",
       "41                            32               10                 100   \n",
       "40                            32               10                  50   \n",
       "39                            16               10                 500   \n",
       "47                            64               10                 500   \n",
       "46                            64               10                 200   \n",
       "36                            16               10                  50   \n",
       "44                            64               10                  50   \n",
       "45                            64               10                 100   \n",
       "31                            32                1                 500   \n",
       "29                            32                1                 100   \n",
       "28                            32                1                  50   \n",
       "30                            32                1                 200   \n",
       "27                            16                1                 500   \n",
       "26                            16                1                 200   \n",
       "25                            16                1                 100   \n",
       "33                            64                1                 100   \n",
       "34                            64                1                 200   \n",
       "35                            64                1                 500   \n",
       "16                            32             0.01                  50   \n",
       "12                            16             0.01                  50   \n",
       "24                            16                1                  50   \n",
       "32                            64                1                  50   \n",
       "4                             32           0.0001                  50   \n",
       "19                            32             0.01                 500   \n",
       "18                            32             0.01                 200   \n",
       "11                            64           0.0001                 500   \n",
       "9                             64           0.0001                 100   \n",
       "10                            64           0.0001                 200   \n",
       "0                             16           0.0001                  50   \n",
       "7                             32           0.0001                 500   \n",
       "6                             32           0.0001                 200   \n",
       "5                             32           0.0001                 100   \n",
       "8                             64           0.0001                  50   \n",
       "1                             16           0.0001                 100   \n",
       "17                            32             0.01                 100   \n",
       "15                            16             0.01                 500   \n",
       "14                            16             0.01                 200   \n",
       "13                            16             0.01                 100   \n",
       "21                            64             0.01                 100   \n",
       "22                            64             0.01                 200   \n",
       "23                            64             0.01                 500   \n",
       "3                             16           0.0001                 500   \n",
       "2                             16           0.0001                 200   \n",
       "20                            64             0.01                  50   \n",
       "\n",
       "    mean_train_score  mean_test_score  mean_fit_time  rank_test_score  \n",
       "37          0.993125          0.79125       0.929766                1  \n",
       "43          0.993437          0.79125       1.423992                1  \n",
       "38          0.993125          0.79125       1.022622                1  \n",
       "42          0.993437          0.79125       1.341438                1  \n",
       "41          0.993437          0.79125       1.408300                1  \n",
       "40          0.993437          0.79125       1.420648                1  \n",
       "39          0.993125          0.79125       0.968841                1  \n",
       "47          0.993437          0.79000       2.278597                8  \n",
       "46          0.993437          0.79000       2.364537                8  \n",
       "36          0.993125          0.79000       0.764004                8  \n",
       "44          0.993437          0.79000       2.409441                8  \n",
       "45          0.993437          0.79000       2.306146                8  \n",
       "31          0.997500          0.78625       2.095515               13  \n",
       "29          0.997500          0.78625       2.103648               13  \n",
       "28          0.997500          0.78625       1.694779               13  \n",
       "30          0.997500          0.78625       2.085668               13  \n",
       "27          0.997500          0.78625       1.347743               17  \n",
       "26          0.997500          0.78625       1.335489               17  \n",
       "25          0.997500          0.78625       1.209501               17  \n",
       "33          0.997500          0.78500       3.450926               20  \n",
       "34          0.997500          0.78500       3.457491               20  \n",
       "35          0.997500          0.78500       4.087090               20  \n",
       "16          0.997500          0.78500       1.696395               20  \n",
       "12          0.997500          0.78500       0.851499               20  \n",
       "24          0.997500          0.78500       0.891334               25  \n",
       "32          0.997500          0.78375       3.183879               26  \n",
       "4           0.997500          0.78375       1.147813               26  \n",
       "19          0.997500          0.78375       2.255135               28  \n",
       "18          0.997500          0.78375       2.331455               28  \n",
       "11          0.997500          0.78250       2.449228               30  \n",
       "9           0.997500          0.78250       2.497103               30  \n",
       "10          0.997500          0.78250       2.452053               30  \n",
       "0           0.997500          0.78250       0.815648               33  \n",
       "7           0.997500          0.78250       1.214859               33  \n",
       "6           0.997500          0.78250       1.303934               33  \n",
       "5           0.997500          0.78250       1.208104               33  \n",
       "8           0.997500          0.78125       2.345142               37  \n",
       "1           0.997500          0.78125       0.936448               37  \n",
       "17          0.997500          0.78125       2.315766               39  \n",
       "15          0.997500          0.77875       1.215835               40  \n",
       "14          0.997500          0.77875       1.213987               40  \n",
       "13          0.997500          0.77875       1.208065               40  \n",
       "21          0.997500          0.77875       4.570219               43  \n",
       "22          0.997500          0.77875       4.669880               43  \n",
       "23          0.997500          0.77875       4.703189               43  \n",
       "3           0.997500          0.77625       0.994732               46  \n",
       "2           0.997500          0.77625       0.990063               46  \n",
       "20          0.997500          0.77500       3.371425               48  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(yelp_tf_mlp_grid_searcher, list(yelp_tf_mlp_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate MLP test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mlp_filename = os.path.join(output_dir, 'splitsource_tf_mlp_yproba1_test.txt')\n",
    "\n",
    "# amazon_x_test = tf_vectorizer(amazon_x_df['text'].values)\n",
    "amazon_yhat_positive_proba = amazon_tf_mlp_grid_searcher.best_estimator_.predict_proba(amazon_x_df['text'].values)[:, 1]\n",
    "\n",
    "# imdb_x_test = tf_vectorizer(imdb_x_df['text'].values)\n",
    "imdb_yhat_positive_proba = imdb_tf_mlp_grid_searcher.best_estimator_.predict_proba(imdb_x_df['text'].values)[:, 1]\n",
    "\n",
    "# yelp_x_test = tf_vectorizer(yelp_x_df['text'].values)\n",
    "yelp_yhat_positive_proba = yelp_tf_mlp_grid_searcher.best_estimator_.predict_proba(yelp_x_df['text'].values)[:, 1]\n",
    "\n",
    "np.savetxt(tf_mlp_filename, np.r_[amazon_yhat_positive_proba, imdb_yhat_positive_proba, yelp_yhat_positive_proba])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Gradient Boosted Tree pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=5, min_samples_leaf=1, random_state=RANDOM_STATE)\n",
    "# GradientBoosting-Tree hyperparameter grid\n",
    "gbtree_parameters = {\n",
    "    \"gbtree__n_estimators\": [100, 200, 300],\n",
    "    \"gbtree__max_depth\": [5, 10, 20],\n",
    "    \"gbtree__min_samples_leaf\": [1, 3, 5],\n",
    "}\n",
    "gbtree_pipeline_tuple = ('gbtree', gbtree_classifier)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GBTree on Amazon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=3)]: Done 135 out of 135 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('gbtree',\n",
       "                                        GradientBoostingClassifier(max_depth=5,\n",
       "                                                                   random_state=123))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'gbtree__max_depth': [5, 10, 20],\n",
       "                         'gbtree__min_samples_leaf': [1, 3, 5],\n",
       "                         'gbtree__n_estimators': [100, 200, 300]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_tf_gbtree_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    gbtree_pipeline_tuple,\n",
    " ])\n",
    "amazon_tf_gbtree_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **gbtree_parameters\n",
    "}\n",
    "\n",
    "\n",
    "amazon_tf_gbtree_grid_searcher = GridSearchCV(\n",
    "    amazon_tf_gbtree_pipeline, \n",
    "    amazon_tf_gbtree_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "amazon_tf_gbtree_grid_searcher.fit(amazon_x_train, amazon_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (27, 23)\n",
      "Number of trials used in grid search:  27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_gbtree__n_estimators</th>\n",
       "      <th>param_gbtree__max_depth</th>\n",
       "      <th>param_gbtree__min_samples_leaf</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77875</td>\n",
       "      <td>2.556552</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77625</td>\n",
       "      <td>2.438857</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>1.467556</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.478909</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>3.774988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.924063</td>\n",
       "      <td>0.77500</td>\n",
       "      <td>0.878520</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.939688</td>\n",
       "      <td>0.77375</td>\n",
       "      <td>0.954777</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77375</td>\n",
       "      <td>8.050723</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77375</td>\n",
       "      <td>1.301967</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77125</td>\n",
       "      <td>5.200863</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.77000</td>\n",
       "      <td>1.831243</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.76875</td>\n",
       "      <td>1.118255</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.952812</td>\n",
       "      <td>0.76750</td>\n",
       "      <td>1.376132</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.76500</td>\n",
       "      <td>0.419604</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>5.758325</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.76125</td>\n",
       "      <td>1.926954</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.899375</td>\n",
       "      <td>0.76125</td>\n",
       "      <td>0.946252</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.902812</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>0.898005</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.75750</td>\n",
       "      <td>2.740304</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931875</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.818850</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>1.976647</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.75375</td>\n",
       "      <td>1.735155</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.75250</td>\n",
       "      <td>3.834234</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>3.528073</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930625</td>\n",
       "      <td>0.74750</td>\n",
       "      <td>2.059280</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.940625</td>\n",
       "      <td>0.74125</td>\n",
       "      <td>3.065828</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.73875</td>\n",
       "      <td>4.967295</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_gbtree__n_estimators param_gbtree__max_depth  \\\n",
       "10                        200                      10   \n",
       "18                        100                      20   \n",
       "1                         200                       5   \n",
       "3                         100                       5   \n",
       "11                        300                      10   \n",
       "0                         100                       5   \n",
       "4                         200                       5   \n",
       "20                        300                      20   \n",
       "9                         100                      10   \n",
       "19                        200                      20   \n",
       "2                         300                       5   \n",
       "12                        100                      10   \n",
       "5                         300                       5   \n",
       "6                         100                       5   \n",
       "23                        300                      20   \n",
       "13                        200                      10   \n",
       "7                         200                       5   \n",
       "15                        100                      10   \n",
       "14                        300                      10   \n",
       "24                        100                      20   \n",
       "21                        100                      20   \n",
       "8                         300                       5   \n",
       "22                        200                      20   \n",
       "25                        200                      20   \n",
       "16                        200                      10   \n",
       "17                        300                      10   \n",
       "26                        300                      20   \n",
       "\n",
       "   param_gbtree__min_samples_leaf  mean_train_score  mean_test_score  \\\n",
       "10                              1          0.998125          0.77875   \n",
       "18                              1          0.998125          0.77625   \n",
       "1                               1          0.998125          0.77500   \n",
       "3                               3          0.903750          0.77500   \n",
       "11                              1          0.998125          0.77500   \n",
       "0                               1          0.924063          0.77500   \n",
       "4                               3          0.939688          0.77375   \n",
       "20                              1          0.998125          0.77375   \n",
       "9                               1          0.998125          0.77375   \n",
       "19                              1          0.998125          0.77125   \n",
       "2                               1          0.998125          0.77000   \n",
       "12                              3          0.942500          0.76875   \n",
       "5                               3          0.952812          0.76750   \n",
       "6                               5          0.871875          0.76500   \n",
       "23                              3          0.973125          0.76250   \n",
       "13                              3          0.967187          0.76125   \n",
       "7                               5          0.899375          0.76125   \n",
       "15                              5          0.902812          0.75875   \n",
       "14                              3          0.971875          0.75750   \n",
       "24                              5          0.931875          0.75625   \n",
       "21                              3          0.968750          0.75625   \n",
       "8                               5          0.914062          0.75375   \n",
       "22                              3          0.973125          0.75250   \n",
       "25                              5          0.944375          0.75000   \n",
       "16                              5          0.930625          0.74750   \n",
       "17                              5          0.940625          0.74125   \n",
       "26                              5          0.945312          0.73875   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "10       2.556552                1  \n",
       "18       2.438857                2  \n",
       "1        1.467556                3  \n",
       "3        0.478909                3  \n",
       "11       3.774988                3  \n",
       "0        0.878520                6  \n",
       "4        0.954777                7  \n",
       "20       8.050723                7  \n",
       "9        1.301967                7  \n",
       "19       5.200863               10  \n",
       "2        1.831243               11  \n",
       "12       1.118255               12  \n",
       "5        1.376132               13  \n",
       "6        0.419604               14  \n",
       "23       5.758325               15  \n",
       "13       1.926954               16  \n",
       "7        0.946252               16  \n",
       "15       0.898005               18  \n",
       "14       2.740304               19  \n",
       "24       1.818850               20  \n",
       "21       1.976647               21  \n",
       "8        1.735155               22  \n",
       "22       3.834234               23  \n",
       "25       3.528073               24  \n",
       "16       2.059280               25  \n",
       "17       3.065828               26  \n",
       "26       4.967295               27  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(amazon_tf_gbtree_grid_searcher, list(amazon_tf_gbtree_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GBTree on IMDB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=3)]: Done 135 out of 135 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('gbtree',\n",
       "                                        GradientBoostingClassifier(max_depth=5,\n",
       "                                                                   random_state=123))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'gbtree__max_depth': [5, 10, 20],\n",
       "                         'gbtree__min_samples_leaf': [1, 3, 5],\n",
       "                         'gbtree__n_estimators': [100, 200, 300]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_tf_gbtree_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    gbtree_pipeline_tuple,\n",
    " ])\n",
    "imdb_tf_gbtree_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **gbtree_parameters\n",
    "}\n",
    "\n",
    "\n",
    "imdb_tf_gbtree_grid_searcher = GridSearchCV(\n",
    "    imdb_tf_gbtree_pipeline, \n",
    "    imdb_tf_gbtree_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "imdb_tf_gbtree_grid_searcher.fit(imdb_x_train, imdb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (27, 23)\n",
      "Number of trials used in grid search:  27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_gbtree__n_estimators</th>\n",
       "      <th>param_gbtree__max_depth</th>\n",
       "      <th>param_gbtree__min_samples_leaf</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.73750</td>\n",
       "      <td>4.280513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>6.651887</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.952500</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>1.026561</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>3.208768</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.908750</td>\n",
       "      <td>0.73000</td>\n",
       "      <td>0.832723</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.73000</td>\n",
       "      <td>8.286133</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999063</td>\n",
       "      <td>0.72625</td>\n",
       "      <td>4.513877</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>2.329493</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.945625</td>\n",
       "      <td>0.72375</td>\n",
       "      <td>1.612523</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.72125</td>\n",
       "      <td>1.606114</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>2.380197</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954062</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>2.249205</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.855938</td>\n",
       "      <td>0.71875</td>\n",
       "      <td>0.753090</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.71375</td>\n",
       "      <td>12.362867</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.968438</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>2.913690</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.889375</td>\n",
       "      <td>0.71000</td>\n",
       "      <td>1.542975</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.897188</td>\n",
       "      <td>0.70625</td>\n",
       "      <td>1.376998</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>2.875013</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.973750</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>4.491125</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>0.69500</td>\n",
       "      <td>3.669760</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.924375</td>\n",
       "      <td>0.69375</td>\n",
       "      <td>2.512123</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.909062</td>\n",
       "      <td>0.69375</td>\n",
       "      <td>2.313826</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.928438</td>\n",
       "      <td>0.69125</td>\n",
       "      <td>2.368649</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.68625</td>\n",
       "      <td>5.362247</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.975625</td>\n",
       "      <td>0.68375</td>\n",
       "      <td>7.815729</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942187</td>\n",
       "      <td>0.67250</td>\n",
       "      <td>4.480601</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944063</td>\n",
       "      <td>0.66750</td>\n",
       "      <td>6.117627</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_gbtree__n_estimators param_gbtree__max_depth  \\\n",
       "18                        100                      20   \n",
       "11                        300                      10   \n",
       "0                         100                       5   \n",
       "2                         300                       5   \n",
       "3                         100                       5   \n",
       "19                        200                      20   \n",
       "10                        200                      10   \n",
       "9                         100                      10   \n",
       "12                        100                      10   \n",
       "4                         200                       5   \n",
       "1                         200                       5   \n",
       "5                         300                       5   \n",
       "6                         100                       5   \n",
       "20                        300                      20   \n",
       "13                        200                      10   \n",
       "7                         200                       5   \n",
       "15                        100                      10   \n",
       "21                        100                      20   \n",
       "14                        300                      10   \n",
       "17                        300                      10   \n",
       "16                        200                      10   \n",
       "8                         300                       5   \n",
       "24                        100                      20   \n",
       "22                        200                      20   \n",
       "23                        300                      20   \n",
       "25                        200                      20   \n",
       "26                        300                      20   \n",
       "\n",
       "   param_gbtree__min_samples_leaf  mean_train_score  mean_test_score  \\\n",
       "18                              1          0.999063          0.73750   \n",
       "11                              1          0.999063          0.73625   \n",
       "0                               1          0.952500          0.73375   \n",
       "2                               1          0.998750          0.73125   \n",
       "3                               3          0.908750          0.73000   \n",
       "19                              1          0.999063          0.73000   \n",
       "10                              1          0.999063          0.72625   \n",
       "9                               1          0.998750          0.72500   \n",
       "12                              3          0.945625          0.72375   \n",
       "4                               3          0.935625          0.72125   \n",
       "1                               1          0.998750          0.72000   \n",
       "5                               3          0.954062          0.71875   \n",
       "6                               5          0.855938          0.71875   \n",
       "20                              1          1.000000          0.71375   \n",
       "13                              3          0.968438          0.71000   \n",
       "7                               5          0.889375          0.71000   \n",
       "15                              5          0.897188          0.70625   \n",
       "21                              3          0.970313          0.70500   \n",
       "14                              3          0.973750          0.70000   \n",
       "17                              5          0.936250          0.69500   \n",
       "16                              5          0.924375          0.69375   \n",
       "8                               5          0.909062          0.69375   \n",
       "24                              5          0.928438          0.69125   \n",
       "22                              3          0.975000          0.68625   \n",
       "23                              3          0.975625          0.68375   \n",
       "25                              5          0.942187          0.67250   \n",
       "26                              5          0.944063          0.66750   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "18       4.280513                1  \n",
       "11       6.651887                2  \n",
       "0        1.026561                3  \n",
       "2        3.208768                4  \n",
       "3        0.832723                5  \n",
       "19       8.286133                6  \n",
       "10       4.513877                7  \n",
       "9        2.329493                8  \n",
       "12       1.612523                9  \n",
       "4        1.606114               10  \n",
       "1        2.380197               11  \n",
       "5        2.249205               12  \n",
       "6        0.753090               13  \n",
       "20      12.362867               14  \n",
       "13       2.913690               15  \n",
       "7        1.542975               15  \n",
       "15       1.376998               17  \n",
       "21       2.875013               18  \n",
       "14       4.491125               19  \n",
       "17       3.669760               20  \n",
       "16       2.512123               21  \n",
       "8        2.313826               21  \n",
       "24       2.368649               23  \n",
       "22       5.362247               24  \n",
       "23       7.815729               25  \n",
       "25       4.480601               26  \n",
       "26       6.117627               27  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(imdb_tf_gbtree_grid_searcher, list(imdb_tf_gbtree_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GBTree on Yelp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 135 out of 135 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tf',\n",
       "                                        TfidfVectorizer(ngram_range=(1, 2),\n",
       "                                                        stop_words='english')),\n",
       "                                       ('gbtree',\n",
       "                                        GradientBoostingClassifier(max_depth=5,\n",
       "                                                                   random_state=123))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'gbtree__max_depth': [5, 10, 20],\n",
       "                         'gbtree__min_samples_leaf': [1, 3, 5],\n",
       "                         'gbtree__n_estimators': [100, 200, 300]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_tf_gbtree_pipeline = Pipeline([\n",
    "    tf_pipeline_tuple,\n",
    "    gbtree_pipeline_tuple,\n",
    " ])\n",
    "yelp_tf_gbtree_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **gbtree_parameters\n",
    "}\n",
    "\n",
    "\n",
    "yelp_tf_gbtree_grid_searcher = GridSearchCV(\n",
    "    yelp_tf_gbtree_pipeline, \n",
    "    yelp_tf_gbtree_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "yelp_tf_gbtree_grid_searcher.fit(yelp_x_train, yelp_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (27, 23)\n",
      "Number of trials used in grid search:  27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_gbtree__n_estimators</th>\n",
       "      <th>param_gbtree__max_depth</th>\n",
       "      <th>param_gbtree__min_samples_leaf</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.923125</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>0.861517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.854375</td>\n",
       "      <td>0.73625</td>\n",
       "      <td>0.509330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>3.945416</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.73375</td>\n",
       "      <td>1.477007</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.73250</td>\n",
       "      <td>1.409518</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.73125</td>\n",
       "      <td>2.145985</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>0.580733</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.935312</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>1.067190</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.950313</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>1.625991</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>2.728589</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.72875</td>\n",
       "      <td>5.185046</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.72750</td>\n",
       "      <td>7.664142</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.969688</td>\n",
       "      <td>0.72625</td>\n",
       "      <td>3.888782</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.72375</td>\n",
       "      <td>2.037637</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.72250</td>\n",
       "      <td>2.595923</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.939688</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>1.062112</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.969688</td>\n",
       "      <td>0.72000</td>\n",
       "      <td>5.528560</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.71625</td>\n",
       "      <td>1.816436</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.968125</td>\n",
       "      <td>0.71375</td>\n",
       "      <td>2.819423</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>0.70500</td>\n",
       "      <td>4.865084</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.888437</td>\n",
       "      <td>0.70250</td>\n",
       "      <td>1.008347</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.891563</td>\n",
       "      <td>0.70250</td>\n",
       "      <td>0.950610</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920937</td>\n",
       "      <td>0.70125</td>\n",
       "      <td>1.802318</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.70000</td>\n",
       "      <td>1.843291</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.906875</td>\n",
       "      <td>0.69750</td>\n",
       "      <td>1.470141</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931562</td>\n",
       "      <td>0.69625</td>\n",
       "      <td>2.612043</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.69625</td>\n",
       "      <td>3.359234</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_gbtree__n_estimators param_gbtree__max_depth  \\\n",
       "0                         100                       5   \n",
       "6                         100                       5   \n",
       "11                        300                      10   \n",
       "1                         200                       5   \n",
       "9                         100                      10   \n",
       "2                         300                       5   \n",
       "3                         100                       5   \n",
       "4                         200                       5   \n",
       "5                         300                       5   \n",
       "10                        200                      10   \n",
       "19                        200                      20   \n",
       "20                        300                      20   \n",
       "22                        200                      20   \n",
       "13                        200                      10   \n",
       "18                        100                      20   \n",
       "12                        100                      10   \n",
       "23                        300                      20   \n",
       "21                        100                      20   \n",
       "14                        300                      10   \n",
       "26                        300                      20   \n",
       "7                         200                       5   \n",
       "15                        100                      10   \n",
       "16                        200                      10   \n",
       "24                        100                      20   \n",
       "8                         300                       5   \n",
       "17                        300                      10   \n",
       "25                        200                      20   \n",
       "\n",
       "   param_gbtree__min_samples_leaf  mean_train_score  mean_test_score  \\\n",
       "0                               1          0.923125          0.73625   \n",
       "6                               5          0.854375          0.73625   \n",
       "11                              1          0.997500          0.73375   \n",
       "1                               1          0.997500          0.73375   \n",
       "9                               1          0.997500          0.73250   \n",
       "2                               1          0.997500          0.73125   \n",
       "3                               3          0.895000          0.72875   \n",
       "4                               3          0.935312          0.72875   \n",
       "5                               3          0.950313          0.72875   \n",
       "10                              1          0.997500          0.72875   \n",
       "19                              1          0.997500          0.72875   \n",
       "20                              1          0.997500          0.72750   \n",
       "22                              3          0.969688          0.72625   \n",
       "13                              3          0.962500          0.72375   \n",
       "18                              1          0.997500          0.72250   \n",
       "12                              3          0.939688          0.72000   \n",
       "23                              3          0.969688          0.72000   \n",
       "21                              3          0.962500          0.71625   \n",
       "14                              3          0.968125          0.71375   \n",
       "26                              5          0.935000          0.70500   \n",
       "7                               5          0.888437          0.70250   \n",
       "15                              5          0.891563          0.70250   \n",
       "16                              5          0.920937          0.70125   \n",
       "24                              5          0.923750          0.70000   \n",
       "8                               5          0.906875          0.69750   \n",
       "17                              5          0.931562          0.69625   \n",
       "25                              5          0.933125          0.69625   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "0        0.861517                1  \n",
       "6        0.509330                1  \n",
       "11       3.945416                3  \n",
       "1        1.477007                4  \n",
       "9        1.409518                5  \n",
       "2        2.145985                6  \n",
       "3        0.580733                7  \n",
       "4        1.067190                7  \n",
       "5        1.625991                7  \n",
       "10       2.728589                7  \n",
       "19       5.185046                7  \n",
       "20       7.664142               12  \n",
       "22       3.888782               13  \n",
       "13       2.037637               14  \n",
       "18       2.595923               15  \n",
       "12       1.062112               16  \n",
       "23       5.528560               16  \n",
       "21       1.816436               18  \n",
       "14       2.819423               19  \n",
       "26       4.865084               20  \n",
       "7        1.008347               21  \n",
       "15       0.950610               22  \n",
       "16       1.802318               23  \n",
       "24       1.843291               24  \n",
       "8        1.470141               25  \n",
       "17       2.612043               26  \n",
       "25       3.359234               26  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(yelp_tf_gbtree_grid_searcher, list(yelp_tf_gbtree_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train GBTree predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_gbtree_filename = os.path.join(output_dir, 'splitsource_tf_gbtree_yproba1_test.txt')\n",
    "\n",
    "# amazon_x_test = tf_vectorizer(amazon_x_df['text'].values)\n",
    "amazon_yhat_positive_proba = amazon_tf_gbtree_grid_searcher.best_estimator_.predict_proba(amazon_x_df['text'].values)[:, 1]\n",
    "\n",
    "# imdb_x_test = tf_vectorizer(imdb_x_df['text'].values)\n",
    "imdb_yhat_positive_proba = imdb_tf_gbtree_grid_searcher.best_estimator_.predict_proba(imdb_x_df['text'].values)[:, 1]\n",
    "\n",
    "# yelp_x_test = tf_vectorizer(yelp_x_df['text'].values)\n",
    "yelp_yhat_positive_proba = yelp_tf_gbtree_grid_searcher.best_estimator_.predict_proba(yelp_x_df['text'].values)[:, 1]\n",
    "\n",
    "np.savetxt(tf_gbtree_filename, np.r_[amazon_yhat_positive_proba, imdb_yhat_positive_proba, yelp_yhat_positive_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
