{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Classifier Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import sklearn.neural_network\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Custom functions  \n",
    "from utils import (\n",
    "    print_gridsearch_results, \n",
    "    test_on_estimator, \n",
    "    plot_cv_train_test, \n",
    "    plot_cv_folds, \n",
    "    analysis_of_mistakes,\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "---------------\n",
      "x_train_df shape: (2400, 2) \n",
      "y_train_df shape: (2400, 1) \n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data_reviews'\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "print(\"Shape of data\\n---------------\")\n",
    "print(f\"x_train_df shape: {x_train_df.shape} \")\n",
    "print(f\"y_train_df shape: {y_train_df.shape} \")\n",
    "\n",
    "# Get the text as a list of strings\n",
    "x_train_text = x_train_df['text'].values\n",
    "y_train = y_train_df['is_positive_sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'embedding_predictions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training samples = 2400\n",
      "Fraction positive training samples = 0.5\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = x_train_text.shape[0]\n",
    "num_positive_train_samples = np.count_nonzero(y_train == 1)\n",
    "fraction_positive_train = float(num_positive_train_samples) / float(num_train_samples)\n",
    "\n",
    "\n",
    "print(f\"Total number of training samples = {num_train_samples}\")\n",
    "print(f\"Fraction positive training samples = {fraction_positive_train}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_path = os.path.join(\n",
    "    'pretrained_embedding_vectors/',\n",
    "    'glove.6B.50d.txt.zip')\n",
    "\n",
    "word_embeddings = pd.read_csv(\n",
    "    zip_file_path,\n",
    "    header=None, sep=' ', index_col=0,\n",
    "    nrows=100000, compression='zip', encoding='utf-8', quoting=3)\n",
    "\n",
    "# Build a dict that will map from string word to 50-dim vector\n",
    "word_list = word_embeddings.index.values.tolist()\n",
    "word2vec = OrderedDict(zip(word_list, word_embeddings.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "x_train_embeddings = np.zeros((num_train_samples, 50))\n",
    "\n",
    "unique_vocab_words = set()\n",
    "\n",
    "for ind in range(num_train_samples):\n",
    "    sample = x_train_text[ind]\n",
    "    stripped_sample = re.sub(r'[^\\w\\s]', '', sample).lower()\n",
    "    sample_embedding = []\n",
    "    #print(f\"Current sample = {stripped_sample}\")\n",
    "    for word in stripped_sample.split(' '):\n",
    "        if word in word2vec.keys() and word not in text.ENGLISH_STOP_WORDS:\n",
    "            sample_embedding.append(word2vec[word])\n",
    "            unique_vocab_words.add(word)\n",
    "            \n",
    "    if len(sample_embedding) == 0:\n",
    "        sample_embedding = [0] * 50\n",
    "        \n",
    "    sample_embedding = np.array(sample_embedding)\n",
    "    avg_sample_embedding = np.nanmean(sample_embedding, axis=0)\n",
    "    x_train_embeddings[ind] = avg_sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3902"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of vocab set\n",
    "len(unique_vocab_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test set for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.read_csv(os.path.join(data_dir, 'x_test.csv'))\n",
    "\n",
    "# Get the text as a list of strings\n",
    "x_test_text = x_test_df['text'].values\n",
    "num_test_samples = x_test_text.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_embeddings = np.zeros((num_test_samples, 50))\n",
    "\n",
    "for ind in range(num_test_samples):\n",
    "    sample = x_test_text[ind]\n",
    "    stripped_sample = re.sub(r'[^\\w\\s]', '', sample).lower()\n",
    "    sample_embedding = []\n",
    "    #print(f\"Current sample = {stripped_sample}\")\n",
    "    for word in stripped_sample.split(' '):\n",
    "        if word in word2vec.keys() and word not in text.ENGLISH_STOP_WORDS:\n",
    "            sample_embedding.append(word2vec[word])\n",
    "            unique_vocab_words.add(word)\n",
    "            \n",
    "    if len(sample_embedding) == 0:\n",
    "        sample_embedding = [0] * 50\n",
    "        \n",
    "    sample_embedding = np.array(sample_embedding)\n",
    "    avg_sample_embedding = np.nanmean(sample_embedding, axis=0)\n",
    "    x_test_embeddings[ind] = avg_sample_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable CV splitter  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splitter = sklearn.model_selection.StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter searcher: Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rf__max_depth': array([ 1,  4,  8, 11, 15]), 'rf__n_estimators': array([  1,  50, 100, 150, 200])}\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "# Random Forest hyperparameter grid\n",
    "rf_parameters = {\n",
    "    \"rf__max_depth\": np.linspace(1, 15, 5).astype(int),\n",
    "    \"rf__n_estimators\": np.linspace(1,200,5).astype(int),\n",
    "}\n",
    "rf_pipeline_tuple = ('rf', rf_classifier)\n",
    "print(rf_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=4)]: Done 125 out of 125 | elapsed:   48.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('rf',\n",
       "                                        RandomForestClassifier(random_state=123))]),\n",
       "             n_jobs=4,\n",
       "             param_grid={'rf__max_depth': array([ 1,  4,  8, 11, 15]),\n",
       "                         'rf__n_estimators': array([  1,  50, 100, 150, 200])},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rf_pipeline = Pipeline([\n",
    "#     embedding_pipeline_tuple,\n",
    "    rf_pipeline_tuple,\n",
    " ])\n",
    "embedding_rf_full_grid = { \n",
    "    **rf_parameters\n",
    "}\n",
    "\n",
    "\n",
    "embedding_rf_grid_searcher = GridSearchCV(\n",
    "    embedding_rf_pipeline, \n",
    "    embedding_rf_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=4,  \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "embedding_rf_grid_searcher.fit(x_train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (25, 22)\n",
      "Number of trials used in grid search:  25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>0.993125</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>3.971049</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>3.381581</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>150</td>\n",
       "      <td>0.993437</td>\n",
       "      <td>0.750833</td>\n",
       "      <td>3.000432</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>0.992708</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>1.645861</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.746250</td>\n",
       "      <td>2.787339</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.960833</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>1.432667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.744583</td>\n",
       "      <td>2.148737</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>0.955521</td>\n",
       "      <td>0.742917</td>\n",
       "      <td>0.669140</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>0.963438</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>2.825635</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>150</td>\n",
       "      <td>0.962083</td>\n",
       "      <td>0.740833</td>\n",
       "      <td>2.100476</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>0.990729</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.863935</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.957905</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.813125</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>1.040134</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.803021</td>\n",
       "      <td>0.725417</td>\n",
       "      <td>0.759438</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.725417</td>\n",
       "      <td>1.890368</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.811979</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>1.399652</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.700833</td>\n",
       "      <td>0.515705</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.289037</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.699583</td>\n",
       "      <td>0.862964</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.725937</td>\n",
       "      <td>0.699583</td>\n",
       "      <td>0.249137</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856979</td>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835729</td>\n",
       "      <td>0.611250</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771250</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.656042</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.501667</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_rf__max_depth param_rf__n_estimators  mean_train_score  \\\n",
       "19                  11                    200          0.993125   \n",
       "24                  15                    200          0.996354   \n",
       "18                  11                    150          0.993437   \n",
       "17                  11                    100          0.992708   \n",
       "23                  15                    150          0.996354   \n",
       "12                   8                    100          0.960833   \n",
       "22                  15                    100          0.996354   \n",
       "11                   8                     50          0.955521   \n",
       "14                   8                    200          0.963438   \n",
       "13                   8                    150          0.962083   \n",
       "16                  11                     50          0.990729   \n",
       "21                  15                     50          0.996354   \n",
       "7                    4                    100          0.813125   \n",
       "6                    4                     50          0.803021   \n",
       "9                    4                    200          0.812500   \n",
       "8                    4                    150          0.811979   \n",
       "2                    1                    100          0.725000   \n",
       "4                    1                    200          0.727500   \n",
       "3                    1                    150          0.727083   \n",
       "1                    1                     50          0.725937   \n",
       "20                  15                      1          0.856979   \n",
       "15                  11                      1          0.835729   \n",
       "10                   8                      1          0.771250   \n",
       "5                    4                      1          0.656042   \n",
       "0                    1                      1          0.562500   \n",
       "\n",
       "    mean_test_score  mean_fit_time  rank_test_score  \n",
       "19         0.751667       3.971049                1  \n",
       "24         0.751250       3.381581                2  \n",
       "18         0.750833       3.000432                3  \n",
       "17         0.747917       1.645861                4  \n",
       "23         0.746250       2.787339                5  \n",
       "12         0.745833       1.432667                6  \n",
       "22         0.744583       2.148737                7  \n",
       "11         0.742917       0.669140                8  \n",
       "14         0.742500       2.825635                9  \n",
       "13         0.740833       2.100476               10  \n",
       "16         0.735417       0.863935               11  \n",
       "21         0.735417       0.957905               12  \n",
       "7          0.727083       1.040134               13  \n",
       "6          0.725417       0.759438               14  \n",
       "9          0.725417       1.890368               14  \n",
       "8          0.721667       1.399652               16  \n",
       "2          0.700833       0.515705               17  \n",
       "4          0.700000       1.289037               18  \n",
       "3          0.699583       0.862964               19  \n",
       "1          0.699583       0.249137               20  \n",
       "20         0.615000       0.031163               21  \n",
       "15         0.611250       0.018435               22  \n",
       "10         0.606250       0.015640               23  \n",
       "5          0.605000       0.017880               24  \n",
       "0          0.501667       0.007840               25  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(embedding_rf_grid_searcher, list(embedding_rf_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 11, 'rf__n_estimators': 200}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rf_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00783992, 0.24913659, 0.5157053 , 0.86296377, 1.28903723,\n",
       "        0.01788001, 0.75943794, 1.04013381, 1.39965248, 1.89036808,\n",
       "        0.01564045, 0.66914043, 1.4326674 , 2.10047617, 2.82563505,\n",
       "        0.01843524, 0.86393466, 1.6458611 , 3.00043182, 3.97104917,\n",
       "        0.03116341, 0.95790486, 2.14873667, 2.78733897, 3.38158078]),\n",
       " 'std_fit_time': array([0.00184978, 0.01441229, 0.04399008, 0.10747266, 0.10202933,\n",
       "        0.00517005, 0.08315472, 0.1213042 , 0.10609579, 0.03664479,\n",
       "        0.00252775, 0.04225509, 0.04321488, 0.03266807, 0.09467674,\n",
       "        0.00207996, 0.01993691, 0.04358878, 0.11286744, 0.08083102,\n",
       "        0.01566803, 0.08682026, 0.17089338, 0.04509297, 0.25079374]),\n",
       " 'mean_score_time': array([0.0029726 , 0.0123086 , 0.02787857, 0.06669569, 0.07538447,\n",
       "        0.00718102, 0.0375268 , 0.02863722, 0.03520279, 0.04605684,\n",
       "        0.00280666, 0.01463556, 0.03159924, 0.04063215, 0.05440679,\n",
       "        0.0027689 , 0.0194304 , 0.03212428, 0.07225933, 0.05999637,\n",
       "        0.00902958, 0.01877127, 0.03726306, 0.04738946, 0.04852858]),\n",
       " 'std_score_time': array([0.00118959, 0.00101018, 0.00833111, 0.02984108, 0.0434997 ,\n",
       "        0.00437793, 0.02138688, 0.01041043, 0.00522736, 0.00449039,\n",
       "        0.00060861, 0.00151734, 0.00364733, 0.00252064, 0.00731563,\n",
       "        0.000129  , 0.00604573, 0.00588547, 0.03097178, 0.00993018,\n",
       "        0.01251104, 0.00417107, 0.00501689, 0.00972005, 0.01187503]),\n",
       " 'param_rf__max_depth': masked_array(data=[1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 11, 11,\n",
       "                    11, 11, 11, 15, 15, 15, 15, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_rf__n_estimators': masked_array(data=[1, 50, 100, 150, 200, 1, 50, 100, 150, 200, 1, 50, 100,\n",
       "                    150, 200, 1, 50, 100, 150, 200, 1, 50, 100, 150, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'rf__max_depth': 1, 'rf__n_estimators': 1},\n",
       "  {'rf__max_depth': 1, 'rf__n_estimators': 50},\n",
       "  {'rf__max_depth': 1, 'rf__n_estimators': 100},\n",
       "  {'rf__max_depth': 1, 'rf__n_estimators': 150},\n",
       "  {'rf__max_depth': 1, 'rf__n_estimators': 200},\n",
       "  {'rf__max_depth': 4, 'rf__n_estimators': 1},\n",
       "  {'rf__max_depth': 4, 'rf__n_estimators': 50},\n",
       "  {'rf__max_depth': 4, 'rf__n_estimators': 100},\n",
       "  {'rf__max_depth': 4, 'rf__n_estimators': 150},\n",
       "  {'rf__max_depth': 4, 'rf__n_estimators': 200},\n",
       "  {'rf__max_depth': 8, 'rf__n_estimators': 1},\n",
       "  {'rf__max_depth': 8, 'rf__n_estimators': 50},\n",
       "  {'rf__max_depth': 8, 'rf__n_estimators': 100},\n",
       "  {'rf__max_depth': 8, 'rf__n_estimators': 150},\n",
       "  {'rf__max_depth': 8, 'rf__n_estimators': 200},\n",
       "  {'rf__max_depth': 11, 'rf__n_estimators': 1},\n",
       "  {'rf__max_depth': 11, 'rf__n_estimators': 50},\n",
       "  {'rf__max_depth': 11, 'rf__n_estimators': 100},\n",
       "  {'rf__max_depth': 11, 'rf__n_estimators': 150},\n",
       "  {'rf__max_depth': 11, 'rf__n_estimators': 200},\n",
       "  {'rf__max_depth': 15, 'rf__n_estimators': 1},\n",
       "  {'rf__max_depth': 15, 'rf__n_estimators': 50},\n",
       "  {'rf__max_depth': 15, 'rf__n_estimators': 100},\n",
       "  {'rf__max_depth': 15, 'rf__n_estimators': 150},\n",
       "  {'rf__max_depth': 15, 'rf__n_estimators': 200}],\n",
       " 'split0_test_score': array([0.5125    , 0.66041667, 0.65208333, 0.65208333, 0.65208333,\n",
       "        0.54791667, 0.70833333, 0.70625   , 0.70208333, 0.70833333,\n",
       "        0.58125   , 0.74791667, 0.74791667, 0.74166667, 0.75      ,\n",
       "        0.59166667, 0.72708333, 0.74166667, 0.75208333, 0.75625   ,\n",
       "        0.63333333, 0.70625   , 0.73125   , 0.7375    , 0.74583333]),\n",
       " 'split1_test_score': array([0.51875   , 0.68333333, 0.67916667, 0.68333333, 0.68541667,\n",
       "        0.63958333, 0.71666667, 0.71875   , 0.72291667, 0.71666667,\n",
       "        0.57916667, 0.70625   , 0.72708333, 0.725     , 0.725     ,\n",
       "        0.64375   , 0.74166667, 0.7375    , 0.7375    , 0.72916667,\n",
       "        0.63125   , 0.7375    , 0.74791667, 0.73333333, 0.7375    ]),\n",
       " 'split2_test_score': array([0.49166667, 0.7125    , 0.72083333, 0.71875   , 0.72291667,\n",
       "        0.67708333, 0.73333333, 0.72708333, 0.725     , 0.7375    ,\n",
       "        0.67916667, 0.73333333, 0.73541667, 0.725     , 0.73333333,\n",
       "        0.60833333, 0.73333333, 0.75208333, 0.74583333, 0.74583333,\n",
       "        0.61458333, 0.74583333, 0.75625   , 0.75      , 0.75416667]),\n",
       " 'split3_test_score': array([0.45833333, 0.7125    , 0.72291667, 0.72083333, 0.72083333,\n",
       "        0.5625    , 0.72916667, 0.73541667, 0.725     , 0.725     ,\n",
       "        0.57916667, 0.77291667, 0.77291667, 0.76041667, 0.75208333,\n",
       "        0.57708333, 0.74583333, 0.75      , 0.75833333, 0.7625    ,\n",
       "        0.61041667, 0.75208333, 0.75208333, 0.7625    , 0.76666667]),\n",
       " 'split4_test_score': array([0.52708333, 0.72916667, 0.72916667, 0.72291667, 0.71875   ,\n",
       "        0.59791667, 0.73958333, 0.74791667, 0.73333333, 0.73958333,\n",
       "        0.6125    , 0.75416667, 0.74583333, 0.75208333, 0.75208333,\n",
       "        0.63541667, 0.72916667, 0.75833333, 0.76041667, 0.76458333,\n",
       "        0.58541667, 0.73541667, 0.73541667, 0.74791667, 0.75208333]),\n",
       " 'mean_test_score': array([0.50166667, 0.69958333, 0.70083333, 0.69958333, 0.7       ,\n",
       "        0.605     , 0.72541667, 0.72708333, 0.72166667, 0.72541667,\n",
       "        0.60625   , 0.74291667, 0.74583333, 0.74083333, 0.7425    ,\n",
       "        0.61125   , 0.73541667, 0.74791667, 0.75083333, 0.75166667,\n",
       "        0.615     , 0.73541667, 0.74458333, 0.74625   , 0.75125   ]),\n",
       " 'std_test_score': array([0.02462919, 0.02452323, 0.03012128, 0.02786999, 0.02763854,\n",
       "        0.04797279, 0.01136515, 0.01419116, 0.010425  , 0.01196058,\n",
       "        0.03859512, 0.02230626, 0.01547848, 0.01422781, 0.01122683,\n",
       "        0.02529685, 0.00721688, 0.00745356, 0.0083956 , 0.01300374,\n",
       "        0.01730045, 0.01575639, 0.00964653, 0.01024017, 0.00964653]),\n",
       " 'rank_test_score': array([25, 20, 17, 19, 18, 24, 14, 13, 16, 14, 23,  8,  6, 10,  9, 22, 11,\n",
       "         4,  3,  1, 21, 12,  7,  5,  2], dtype=int32),\n",
       " 'split0_train_score': array([0.5609375 , 0.72552083, 0.72291667, 0.721875  , 0.72760417,\n",
       "        0.6453125 , 0.80052083, 0.80416667, 0.8046875 , 0.803125  ,\n",
       "        0.76979167, 0.9578125 , 0.9609375 , 0.96302083, 0.9609375 ,\n",
       "        0.82760417, 0.990625  , 0.99166667, 0.99270833, 0.99270833,\n",
       "        0.859375  , 0.99635417, 0.99635417, 0.99635417, 0.99635417]),\n",
       " 'split1_train_score': array([0.578125  , 0.7296875 , 0.73072917, 0.72864583, 0.728125  ,\n",
       "        0.66145833, 0.80104167, 0.8140625 , 0.80885417, 0.809375  ,\n",
       "        0.79322917, 0.95677083, 0.96197917, 0.96041667, 0.96197917,\n",
       "        0.859375  , 0.99270833, 0.99375   , 0.99427083, 0.99479167,\n",
       "        0.8640625 , 0.99739583, 0.99739583, 0.99739583, 0.99739583]),\n",
       " 'split2_train_score': array([0.56041667, 0.72447917, 0.71927083, 0.72447917, 0.71979167,\n",
       "        0.6765625 , 0.80989583, 0.81354167, 0.81145833, 0.8125    ,\n",
       "        0.78645833, 0.953125  , 0.96302083, 0.9625    , 0.96354167,\n",
       "        0.82135417, 0.98958333, 0.99270833, 0.9921875 , 0.9921875 ,\n",
       "        0.86041667, 0.99583333, 0.99583333, 0.99583333, 0.99583333]),\n",
       " 'split3_train_score': array([0.5640625 , 0.721875  , 0.72291667, 0.72916667, 0.73177083,\n",
       "        0.64166667, 0.80052083, 0.81041667, 0.81510417, 0.8140625 ,\n",
       "        0.728125  , 0.95520833, 0.96145833, 0.96354167, 0.96666667,\n",
       "        0.82239583, 0.9921875 , 0.9953125 , 0.99583333, 0.99479167,\n",
       "        0.8515625 , 0.996875  , 0.996875  , 0.996875  , 0.996875  ]),\n",
       " 'split4_train_score': array([0.54895833, 0.728125  , 0.72916667, 0.73125   , 0.73020833,\n",
       "        0.65520833, 0.803125  , 0.8234375 , 0.81979167, 0.8234375 ,\n",
       "        0.77864583, 0.9546875 , 0.95677083, 0.9609375 , 0.9640625 ,\n",
       "        0.84791667, 0.98854167, 0.99010417, 0.9921875 , 0.99114583,\n",
       "        0.84947917, 0.9953125 , 0.9953125 , 0.9953125 , 0.9953125 ]),\n",
       " 'mean_train_score': array([0.5625    , 0.7259375 , 0.725     , 0.72708333, 0.7275    ,\n",
       "        0.65604167, 0.80302083, 0.813125  , 0.81197917, 0.8125    ,\n",
       "        0.77125   , 0.95552083, 0.96083333, 0.96208333, 0.9634375 ,\n",
       "        0.83572917, 0.99072917, 0.99270833, 0.9934375 , 0.993125  ,\n",
       "        0.85697917, 0.99635417, 0.99635417, 0.99635417, 0.99635417]),\n",
       " 'std_train_score': array([0.00934602, 0.00274415, 0.00428225, 0.00340738, 0.00413267,\n",
       "        0.01243298, 0.00356913, 0.00624479, 0.00517699, 0.00662913,\n",
       "        0.02293891, 0.00163379, 0.00214492, 0.00120582, 0.00195988,\n",
       "        0.01521903, 0.00155902, 0.00177389, 0.00142064, 0.00145087,\n",
       "        0.00553751, 0.00073657, 0.00073657, 0.00073657, 0.00073657])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rf_grid_searcher.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_rf_filename = os.path.join(output_dir, 'emb_rf_yproba1_test.txt')\n",
    "test_on_estimator(embedding_rf_grid_searcher.best_estimator_, x_test_embeddings, embedding_rf_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter searcher: Gradient Boosted Tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbtree_classifier = GradientBoostingClassifier(n_estimators=100, max_depth=5, min_samples_leaf=1, random_state=RANDOM_STATE)\n",
    "# GradientBoosting-Tree hyperparameter grid\n",
    "gbtree_parameters = {\n",
    "    \"gbtree__n_estimators\": [100, 200, 300],\n",
    "    \"gbtree__max_depth\": [5, 10, 20],\n",
    "    \"gbtree__min_samples_leaf\": [1, 3, 5],\n",
    "}\n",
    "gbtree_pipeline_tuple = ('gbtree', gbtree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=3)]: Done 135 out of 135 | elapsed: 23.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('gbtree',\n",
       "                                        GradientBoostingClassifier(max_depth=5,\n",
       "                                                                   random_state=123))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'gbtree__max_depth': [5, 10, 20],\n",
       "                         'gbtree__min_samples_leaf': [1, 3, 5],\n",
       "                         'gbtree__n_estimators': [100, 200, 300]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_gbtree_pipeline = Pipeline([\n",
    "#     tf_pipeline_tuple,\n",
    "    gbtree_pipeline_tuple,\n",
    " ])\n",
    "embedding_gbtree_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **gbtree_parameters\n",
    "}\n",
    "\n",
    "\n",
    "embedding_gbtree_grid_searcher = GridSearchCV(\n",
    "    embedding_gbtree_pipeline, \n",
    "    embedding_gbtree_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "embedding_gbtree_grid_searcher.fit(x_train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (27, 23)\n",
      "Number of trials used in grid search:  27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_gbtree__n_estimators</th>\n",
       "      <th>param_gbtree__max_depth</th>\n",
       "      <th>param_gbtree__min_samples_leaf</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.753333</td>\n",
       "      <td>28.033063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>43.464620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>39.437778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.749167</td>\n",
       "      <td>22.476392</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.995313</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>11.528823</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>41.072321</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>35.086122</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>35.255301</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>29.182798</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.995729</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>13.359479</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>62.828636</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>300</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.744583</td>\n",
       "      <td>40.187262</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>17.542989</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.744167</td>\n",
       "      <td>25.424781</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.742083</td>\n",
       "      <td>14.533200</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.741250</td>\n",
       "      <td>42.264807</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.740417</td>\n",
       "      <td>53.453642</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>300</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.737083</td>\n",
       "      <td>54.508863</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.737083</td>\n",
       "      <td>29.017922</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.734583</td>\n",
       "      <td>36.780783</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.733750</td>\n",
       "      <td>18.418102</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.732083</td>\n",
       "      <td>12.516643</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>25.965424</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>14.372342</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.662917</td>\n",
       "      <td>41.818493</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.648750</td>\n",
       "      <td>13.005276</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.646250</td>\n",
       "      <td>26.133644</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_gbtree__n_estimators param_gbtree__max_depth  \\\n",
       "4                         200                       5   \n",
       "2                         300                       5   \n",
       "5                         300                       5   \n",
       "7                         200                       5   \n",
       "6                         100                       5   \n",
       "17                        300                      10   \n",
       "16                        200                      10   \n",
       "26                        300                      20   \n",
       "1                         200                       5   \n",
       "3                         100                       5   \n",
       "11                        300                      10   \n",
       "8                         300                       5   \n",
       "15                        100                      10   \n",
       "25                        200                      20   \n",
       "0                         100                       5   \n",
       "23                        300                      20   \n",
       "10                        200                      10   \n",
       "14                        300                      10   \n",
       "22                        200                      20   \n",
       "13                        200                      10   \n",
       "12                        100                      10   \n",
       "24                        100                      20   \n",
       "9                         100                      10   \n",
       "21                        100                      20   \n",
       "20                        300                      20   \n",
       "18                        100                      20   \n",
       "19                        200                      20   \n",
       "\n",
       "   param_gbtree__min_samples_leaf  mean_train_score  mean_test_score  \\\n",
       "4                               3          0.996354         0.753333   \n",
       "2                               1          0.996354         0.751250   \n",
       "5                               3          0.996354         0.751250   \n",
       "7                               5          0.996354         0.749167   \n",
       "6                               5          0.995313         0.747917   \n",
       "17                              5          0.996354         0.747917   \n",
       "16                              5          0.996354         0.746667   \n",
       "26                              5          0.996354         0.745833   \n",
       "1                               1          0.996354         0.745000   \n",
       "3                               3          0.995729         0.745000   \n",
       "11                              1          0.996354         0.745000   \n",
       "8                               5          0.996354         0.744583   \n",
       "15                              5          0.996354         0.744167   \n",
       "25                              5          0.996354         0.744167   \n",
       "0                               1          0.995833         0.742083   \n",
       "23                              3          0.996354         0.741250   \n",
       "10                              1          0.996354         0.740417   \n",
       "14                              3          0.996354         0.737083   \n",
       "22                              3          0.996354         0.737083   \n",
       "13                              3          0.996354         0.734583   \n",
       "12                              3          0.996354         0.733750   \n",
       "24                              5          0.996354         0.732083   \n",
       "9                               1          0.996354         0.729167   \n",
       "21                              3          0.996354         0.729167   \n",
       "20                              1          0.996354         0.662917   \n",
       "18                              1          0.996354         0.648750   \n",
       "19                              1          0.996354         0.646250   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "4       28.033063                1  \n",
       "2       43.464620                2  \n",
       "5       39.437778                3  \n",
       "7       22.476392                4  \n",
       "6       11.528823                5  \n",
       "17      41.072321                5  \n",
       "16      35.086122                7  \n",
       "26      35.255301                8  \n",
       "1       29.182798                9  \n",
       "3       13.359479               10  \n",
       "11      62.828636               10  \n",
       "8       40.187262               12  \n",
       "15      17.542989               13  \n",
       "25      25.424781               13  \n",
       "0       14.533200               15  \n",
       "23      42.264807               16  \n",
       "10      53.453642               17  \n",
       "14      54.508863               18  \n",
       "22      29.017922               19  \n",
       "13      36.780783               20  \n",
       "12      18.418102               21  \n",
       "24      12.516643               22  \n",
       "9       25.965424               23  \n",
       "21      14.372342               23  \n",
       "20      41.818493               25  \n",
       "18      13.005276               26  \n",
       "19      26.133644               27  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(embedding_gbtree_grid_searcher, list(embedding_gbtree_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gbtree__max_depth': 5,\n",
       " 'gbtree__min_samples_leaf': 3,\n",
       " 'gbtree__n_estimators': 200}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_gbtree_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_gbtree_filename = os.path.join(output_dir, 'emb_gbtree_yproba1_test.txt')\n",
    "test_on_estimator(embedding_gbtree_grid_searcher.best_estimator_, x_test_embeddings, embedding_gbtree_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search: L1-Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.LogisticRegression(penalty='l1', solver='saga', random_state=RANDOM_STATE)\n",
    "# logit_lasso hyperparameter grid\n",
    "lasso_parameters = {\n",
    "     'lasso__C': np.logspace(-3, 3, 7),\n",
    "     'lasso__max_iter': [20, 40, 60], # sneaky way to do \"early stopping\" \n",
    "}\n",
    "lasso_pipeline_tuple = ('lasso', lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 21 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  85 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=3)]: Done 105 out of 105 | elapsed:    2.7s finished\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('lasso',\n",
       "                                        LogisticRegression(penalty='l1',\n",
       "                                                           random_state=123,\n",
       "                                                           solver='saga'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'lasso__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'lasso__max_iter': [20, 40, 60]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_lasso_pipeline = Pipeline([\n",
    "    lasso_pipeline_tuple,\n",
    " ])\n",
    "embedding_lasso_full_grid = { \n",
    "    **lasso_parameters\n",
    "}\n",
    "\n",
    "\n",
    "embedding_lasso_grid_searcher = GridSearchCV(\n",
    "    embedding_lasso_pipeline, \n",
    "    embedding_lasso_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "embedding_lasso_grid_searcher.fit(x_train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (21, 22)\n",
      "Number of trials used in grid search:  21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_lasso__C</th>\n",
       "      <th>param_lasso__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.770625</td>\n",
       "      <td>0.757083</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>0.769479</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.145226</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.768854</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.769896</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.101625</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.048301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0.770104</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.103908</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.769167</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.049382</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.770937</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.135521</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.769896</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.097136</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>0.769583</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.146920</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.770521</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.049444</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1000</td>\n",
       "      <td>60</td>\n",
       "      <td>0.769375</td>\n",
       "      <td>0.755833</td>\n",
       "      <td>0.139993</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.763750</td>\n",
       "      <td>0.750417</td>\n",
       "      <td>0.048760</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.763750</td>\n",
       "      <td>0.750417</td>\n",
       "      <td>0.042979</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.763750</td>\n",
       "      <td>0.750417</td>\n",
       "      <td>0.045254</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.01</td>\n",
       "      <td>60</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.01</td>\n",
       "      <td>40</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.028935</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>20</td>\n",
       "      <td>0.667708</td>\n",
       "      <td>0.667500</td>\n",
       "      <td>0.032097</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>60</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.012375</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>40</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_lasso__C param_lasso__max_iter  mean_train_score  mean_test_score  \\\n",
       "10              1                    40          0.770625         0.757083   \n",
       "17            100                    60          0.769479         0.756667   \n",
       "18           1000                    20          0.768854         0.756667   \n",
       "16            100                    40          0.769896         0.756667   \n",
       "15            100                    20          0.768750         0.756667   \n",
       "13             10                    40          0.770104         0.756667   \n",
       "12             10                    20          0.769167         0.756667   \n",
       "11              1                    60          0.770937         0.756667   \n",
       "19           1000                    40          0.769896         0.756667   \n",
       "14             10                    60          0.769583         0.756250   \n",
       "9               1                    20          0.770521         0.756250   \n",
       "20           1000                    60          0.769375         0.755833   \n",
       "7             0.1                    40          0.763750         0.750417   \n",
       "6             0.1                    20          0.763750         0.750417   \n",
       "8             0.1                    60          0.763750         0.750417   \n",
       "5            0.01                    60          0.667708         0.667500   \n",
       "4            0.01                    40          0.667708         0.667500   \n",
       "3            0.01                    20          0.667708         0.667500   \n",
       "2           0.001                    60          0.500000         0.500000   \n",
       "1           0.001                    40          0.500000         0.500000   \n",
       "0           0.001                    20          0.500000         0.500000   \n",
       "\n",
       "    mean_fit_time  rank_test_score  \n",
       "10       0.093070                1  \n",
       "17       0.145226                2  \n",
       "18       0.052000                3  \n",
       "16       0.101625                3  \n",
       "15       0.048301                3  \n",
       "13       0.103908                3  \n",
       "12       0.049382                3  \n",
       "11       0.135521                3  \n",
       "19       0.097136                3  \n",
       "14       0.146920               10  \n",
       "9        0.049444               10  \n",
       "20       0.139993               12  \n",
       "7        0.048760               13  \n",
       "6        0.042979               13  \n",
       "8        0.045254               13  \n",
       "5        0.031208               16  \n",
       "4        0.028935               16  \n",
       "3        0.032097               16  \n",
       "2        0.012375               19  \n",
       "1        0.011401               19  \n",
       "0        0.009798               19  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(embedding_lasso_grid_searcher, list(embedding_lasso_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso__C': 1.0, 'lasso__max_iter': 40}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_lasso_grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = sklearn.neural_network.MLPClassifier(solver='lbfgs', random_state=RANDOM_STATE)\n",
    "mlp_parameters = {\n",
    "    'mlp__hidden_layer_sizes': [16, 32, 64],\n",
    "    'mlp__alpha': [0.0001,0.01,1, 10],\n",
    "    'mlp__max_iter': [50, 100, 200, 500], # sneaky way to do \"early stopping\" \n",
    "}\n",
    "mlp_pipeline_tuple = ('mlp', mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=3)]: Done 240 out of 240 | elapsed:  2.7min finished\n",
      "/Users/moose/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('mlp',\n",
       "                                        MLPClassifier(random_state=123,\n",
       "                                                      solver='lbfgs'))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'mlp__alpha': [0.0001, 0.01, 1, 10],\n",
       "                         'mlp__hidden_layer_sizes': [16, 32, 64],\n",
       "                         'mlp__max_iter': [50, 100, 200, 500]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_mlp_pipeline = Pipeline([\n",
    "#     tf_pipeline_tuple,\n",
    "    mlp_pipeline_tuple,\n",
    " ])\n",
    "embedding_mlp_full_grid = { \n",
    "#     **tf_parameters,\n",
    "    **mlp_parameters\n",
    "}\n",
    "\n",
    "\n",
    "embedding_mlp_grid_searcher = GridSearchCV(\n",
    "    embedding_mlp_pipeline, \n",
    "    embedding_mlp_full_grid, \n",
    "    cv=cv_splitter, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "embedding_mlp_grid_searcher.fit(x_train_embeddings, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (48, 23)\n",
      "Number of trials used in grid search:  48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_mlp__hidden_layer_sizes</th>\n",
       "      <th>param_mlp__alpha</th>\n",
       "      <th>param_mlp__max_iter</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.804479</td>\n",
       "      <td>0.761250</td>\n",
       "      <td>0.351655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.813438</td>\n",
       "      <td>0.757917</td>\n",
       "      <td>0.661384</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.826771</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>1.756300</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.834792</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>4.266096</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.801771</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.474778</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.796042</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.284882</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>1.637326</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.189260</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.817396</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.895919</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.818542</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>1.023344</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.811458</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.537580</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>0.824167</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>2.484810</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.828542</td>\n",
       "      <td>0.737917</td>\n",
       "      <td>0.443011</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.737083</td>\n",
       "      <td>0.798048</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836146</td>\n",
       "      <td>0.735833</td>\n",
       "      <td>0.392334</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.833542</td>\n",
       "      <td>0.732500</td>\n",
       "      <td>0.362612</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.856458</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>0.498948</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.877292</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.801023</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.867813</td>\n",
       "      <td>0.728333</td>\n",
       "      <td>1.019304</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.947396</td>\n",
       "      <td>0.727917</td>\n",
       "      <td>1.339204</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.865521</td>\n",
       "      <td>0.720417</td>\n",
       "      <td>1.145669</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.917813</td>\n",
       "      <td>0.717083</td>\n",
       "      <td>0.720477</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.971250</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>1.603397</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.881354</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.645936</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.918229</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>1.398908</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>50</td>\n",
       "      <td>0.854479</td>\n",
       "      <td>0.714583</td>\n",
       "      <td>0.523937</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.990521</td>\n",
       "      <td>0.713750</td>\n",
       "      <td>2.943024</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.942396</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>2.568976</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.995313</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>5.551230</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>0.852396</td>\n",
       "      <td>0.711250</td>\n",
       "      <td>0.457547</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.708750</td>\n",
       "      <td>3.979071</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>1.371505</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.705833</td>\n",
       "      <td>3.423155</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.954375</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>1.705297</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>100</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.880172</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.955937</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>1.803630</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.699583</td>\n",
       "      <td>8.930140</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100</td>\n",
       "      <td>0.879583</td>\n",
       "      <td>0.698750</td>\n",
       "      <td>0.852730</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>3.841917</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.933125</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>1.149111</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.695000</td>\n",
       "      <td>4.474872</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.694583</td>\n",
       "      <td>3.733469</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.993646</td>\n",
       "      <td>0.693750</td>\n",
       "      <td>1.963548</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>200</td>\n",
       "      <td>0.933021</td>\n",
       "      <td>0.689167</td>\n",
       "      <td>1.581241</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>200</td>\n",
       "      <td>0.987396</td>\n",
       "      <td>0.688750</td>\n",
       "      <td>1.939552</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.996354</td>\n",
       "      <td>0.687917</td>\n",
       "      <td>5.724396</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>500</td>\n",
       "      <td>0.971042</td>\n",
       "      <td>0.680417</td>\n",
       "      <td>2.635255</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>500</td>\n",
       "      <td>0.975313</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>4.102235</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_mlp__hidden_layer_sizes param_mlp__alpha param_mlp__max_iter  \\\n",
       "37                            16               10                 100   \n",
       "38                            16               10                 200   \n",
       "46                            64               10                 200   \n",
       "47                            64               10                 500   \n",
       "44                            64               10                  50   \n",
       "40                            32               10                  50   \n",
       "39                            16               10                 500   \n",
       "36                            16               10                  50   \n",
       "45                            64               10                 100   \n",
       "42                            32               10                 200   \n",
       "41                            32               10                 100   \n",
       "43                            32               10                 500   \n",
       "24                            16                1                  50   \n",
       "32                            64                1                  50   \n",
       "0                             16           0.0001                  50   \n",
       "12                            16             0.01                  50   \n",
       "28                            32                1                  50   \n",
       "25                            16                1                 100   \n",
       "20                            64             0.01                  50   \n",
       "33                            64                1                 100   \n",
       "8                             64           0.0001                  50   \n",
       "29                            32                1                 100   \n",
       "30                            32                1                 200   \n",
       "13                            16             0.01                 100   \n",
       "26                            16                1                 200   \n",
       "4                             32           0.0001                  50   \n",
       "34                            64                1                 200   \n",
       "27                            16                1                 500   \n",
       "35                            64                1                 500   \n",
       "16                            32             0.01                  50   \n",
       "31                            32                1                 500   \n",
       "5                             32           0.0001                 100   \n",
       "22                            64             0.01                 200   \n",
       "21                            64             0.01                 100   \n",
       "17                            32             0.01                 100   \n",
       "9                             64           0.0001                 100   \n",
       "23                            64             0.01                 500   \n",
       "1                             16           0.0001                 100   \n",
       "7                             32           0.0001                 500   \n",
       "14                            16             0.01                 200   \n",
       "11                            64           0.0001                 500   \n",
       "10                            64           0.0001                 200   \n",
       "6                             32           0.0001                 200   \n",
       "2                             16           0.0001                 200   \n",
       "18                            32             0.01                 200   \n",
       "19                            32             0.01                 500   \n",
       "15                            16             0.01                 500   \n",
       "3                             16           0.0001                 500   \n",
       "\n",
       "    mean_train_score  mean_test_score  mean_fit_time  rank_test_score  \n",
       "37          0.804479         0.761250       0.351655                1  \n",
       "38          0.813438         0.757917       0.661384                2  \n",
       "46          0.826771         0.756250       1.756300                3  \n",
       "47          0.834792         0.755000       4.266096                4  \n",
       "44          0.801771         0.755000       0.474778                5  \n",
       "40          0.796042         0.754167       0.284882                6  \n",
       "39          0.818750         0.753750       1.637326                7  \n",
       "36          0.790000         0.753750       0.189260                7  \n",
       "45          0.817396         0.752917       0.895919                9  \n",
       "42          0.818542         0.752500       1.023344               10  \n",
       "41          0.811458         0.752083       0.537580               11  \n",
       "43          0.824167         0.751250       2.484810               12  \n",
       "24          0.828542         0.737917       0.443011               13  \n",
       "32          0.868750         0.737083       0.798048               14  \n",
       "0           0.836146         0.735833       0.392334               15  \n",
       "12          0.833542         0.732500       0.362612               16  \n",
       "28          0.856458         0.731667       0.498948               17  \n",
       "25          0.877292         0.730000       0.801023               18  \n",
       "20          0.867813         0.728333       1.019304               19  \n",
       "33          0.947396         0.727917       1.339204               20  \n",
       "8           0.865521         0.720417       1.145669               21  \n",
       "29          0.917813         0.717083       0.720477               22  \n",
       "30          0.971250         0.716667       1.603397               23  \n",
       "13          0.881354         0.715000       0.645936               24  \n",
       "26          0.918229         0.715000       1.398908               24  \n",
       "4           0.854479         0.714583       0.523937               26  \n",
       "34          0.990521         0.713750       2.943024               27  \n",
       "27          0.942396         0.712500       2.568976               28  \n",
       "35          0.995313         0.711250       5.551230               29  \n",
       "16          0.852396         0.711250       0.457547               29  \n",
       "31          0.989583         0.708750       3.979071               31  \n",
       "5           0.927083         0.706667       1.371505               32  \n",
       "22          0.996354         0.705833       3.423155               33  \n",
       "21          0.954375         0.703333       1.705297               34  \n",
       "17          0.920000         0.703333       0.880172               34  \n",
       "9           0.955937         0.703333       1.803630               36  \n",
       "23          0.996354         0.699583       8.930140               37  \n",
       "1           0.879583         0.698750       0.852730               38  \n",
       "7           0.996354         0.697917       3.841917               39  \n",
       "14          0.933125         0.695000       1.149111               40  \n",
       "11          0.996354         0.695000       4.474872               41  \n",
       "10          0.996354         0.694583       3.733469               42  \n",
       "6           0.993646         0.693750       1.963548               43  \n",
       "2           0.933021         0.689167       1.581241               44  \n",
       "18          0.987396         0.688750       1.939552               45  \n",
       "19          0.996354         0.687917       5.724396               46  \n",
       "15          0.971042         0.680417       2.635255               47  \n",
       "3           0.975313         0.673333       4.102235               48  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(embedding_mlp_grid_searcher, list(embedding_mlp_full_grid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.39233398, 0.85272956, 1.58124065, 4.10223503, 0.52393689,\n",
       "        1.37150464, 1.9635478 , 3.84191656, 1.14566927, 1.80362964,\n",
       "        3.7334692 , 4.47487202, 0.36261239, 0.64593606, 1.14911051,\n",
       "        2.635255  , 0.45754714, 0.88017225, 1.93955154, 5.72439585,\n",
       "        1.01930408, 1.70529728, 3.42315545, 8.93013968, 0.44301085,\n",
       "        0.80102258, 1.398908  , 2.56897616, 0.49894814, 0.72047734,\n",
       "        1.60339727, 3.97907147, 0.79804831, 1.3392035 , 2.9430243 ,\n",
       "        5.5512301 , 0.1892601 , 0.3516552 , 0.66138415, 1.6373261 ,\n",
       "        0.28488216, 0.5375802 , 1.02334356, 2.48480959, 0.47477822,\n",
       "        0.89591918, 1.75629969, 4.26609616]),\n",
       " 'std_fit_time': array([0.08077334, 0.26557566, 0.45463242, 0.56751109, 0.06505576,\n",
       "        0.1743594 , 0.10817558, 0.24098089, 0.53685281, 0.35345875,\n",
       "        0.379522  , 0.38288586, 0.08205786, 0.08352565, 0.11598425,\n",
       "        0.10700622, 0.09158697, 0.08756102, 0.21945929, 0.3463939 ,\n",
       "        0.14784618, 0.15516254, 0.22614622, 0.43849385, 0.09392469,\n",
       "        0.12642943, 0.1541823 , 0.15210705, 0.12864131, 0.06622314,\n",
       "        0.17112466, 0.17585659, 0.2034237 , 0.03793617, 0.14323533,\n",
       "        0.65278521, 0.01711356, 0.01303945, 0.02556494, 0.0208395 ,\n",
       "        0.02605441, 0.00877307, 0.00761033, 0.07271152, 0.0305731 ,\n",
       "        0.02653198, 0.04813034, 0.42933436]),\n",
       " 'mean_score_time': array([0.00496807, 0.0029696 , 0.00279498, 0.00464587, 0.00584593,\n",
       "        0.00671616, 0.00702958, 0.00358777, 0.00506306, 0.00412316,\n",
       "        0.00881066, 0.00641661, 0.0085906 , 0.00447521, 0.00303998,\n",
       "        0.00310006, 0.0032793 , 0.00381818, 0.00792384, 0.00359745,\n",
       "        0.00614533, 0.00807014, 0.00748806, 0.00450673, 0.00522199,\n",
       "        0.00327015, 0.01606402, 0.0056942 , 0.00338755, 0.00363727,\n",
       "        0.00318103, 0.00565028, 0.00510554, 0.00366969, 0.0045548 ,\n",
       "        0.00479798, 0.00280151, 0.00290356, 0.00282102, 0.00291338,\n",
       "        0.0032815 , 0.00311832, 0.00329666, 0.00300279, 0.00366297,\n",
       "        0.00344186, 0.00439129, 0.0029253 ]),\n",
       " 'std_score_time': array([2.76509608e-03, 1.61724199e-04, 1.27012002e-04, 2.03244683e-03,\n",
       "        5.17958130e-03, 3.62890689e-03, 3.88253542e-03, 7.02918566e-04,\n",
       "        2.53121168e-03, 7.85650414e-04, 3.49232367e-03, 4.40691121e-03,\n",
       "        4.27713586e-03, 2.12254484e-03, 3.65614610e-04, 2.12519993e-04,\n",
       "        2.71187970e-04, 7.12910313e-04, 5.79810411e-03, 7.61996572e-04,\n",
       "        4.13163457e-03, 4.59454065e-03, 5.92981307e-03, 1.17157022e-03,\n",
       "        4.36666429e-03, 7.33472972e-04, 1.72865003e-02, 2.82008789e-03,\n",
       "        3.22002262e-04, 9.36146516e-04, 8.21996451e-05, 4.77521563e-03,\n",
       "        2.79667878e-03, 2.79677062e-04, 1.23880929e-03, 2.67472737e-03,\n",
       "        8.51320069e-05, 1.77244265e-04, 1.44230070e-04, 9.02678811e-05,\n",
       "        2.21192705e-04, 1.13528048e-04, 4.25526937e-04, 6.39498187e-05,\n",
       "        2.17522565e-04, 8.36406085e-05, 1.42056783e-03, 7.74831809e-04]),\n",
       " 'param_mlp__alpha': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_mlp__hidden_layer_sizes': masked_array(data=[16, 16, 16, 16, 32, 32, 32, 32, 64, 64, 64, 64, 16, 16,\n",
       "                    16, 16, 32, 32, 32, 32, 64, 64, 64, 64, 16, 16, 16, 16,\n",
       "                    32, 32, 32, 32, 64, 64, 64, 64, 16, 16, 16, 16, 32, 32,\n",
       "                    32, 32, 64, 64, 64, 64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_mlp__max_iter': masked_array(data=[50, 100, 200, 500, 50, 100, 200, 500, 50, 100, 200,\n",
       "                    500, 50, 100, 200, 500, 50, 100, 200, 500, 50, 100,\n",
       "                    200, 500, 50, 100, 200, 500, 50, 100, 200, 500, 50,\n",
       "                    100, 200, 500, 50, 100, 200, 500, 50, 100, 200, 500,\n",
       "                    50, 100, 200, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'mlp__alpha': 0.0001,\n",
       "   'mlp__hidden_layer_sizes': 16,\n",
       "   'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 0.0001, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 0.01, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 1, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 16, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 32, 'mlp__max_iter': 500},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 50},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 100},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 200},\n",
       "  {'mlp__alpha': 10, 'mlp__hidden_layer_sizes': 64, 'mlp__max_iter': 500}],\n",
       " 'split0_test_score': array([0.74166667, 0.70625   , 0.69375   , 0.68541667, 0.69791667,\n",
       "        0.69375   , 0.66458333, 0.67291667, 0.7125    , 0.71875   ,\n",
       "        0.68125   , 0.67916667, 0.75833333, 0.72291667, 0.725     ,\n",
       "        0.72083333, 0.70833333, 0.68958333, 0.65208333, 0.6625    ,\n",
       "        0.70833333, 0.73333333, 0.72291667, 0.70833333, 0.75416667,\n",
       "        0.72916667, 0.70625   , 0.71666667, 0.73333333, 0.71458333,\n",
       "        0.70416667, 0.69583333, 0.73333333, 0.72083333, 0.71666667,\n",
       "        0.70416667, 0.7625    , 0.77083333, 0.77291667, 0.7625    ,\n",
       "        0.76041667, 0.75      , 0.75      , 0.75625   , 0.75833333,\n",
       "        0.77083333, 0.77708333, 0.77708333]),\n",
       " 'split1_test_score': array([0.72291667, 0.69375   , 0.69166667, 0.71666667, 0.71458333,\n",
       "        0.70208333, 0.69583333, 0.68958333, 0.7125    , 0.68125   ,\n",
       "        0.67708333, 0.66875   , 0.70625   , 0.69791667, 0.67291667,\n",
       "        0.66666667, 0.71666667, 0.71041667, 0.69583333, 0.68333333,\n",
       "        0.7125    , 0.65833333, 0.67708333, 0.68958333, 0.71458333,\n",
       "        0.70208333, 0.6875    , 0.70625   , 0.71875   , 0.70416667,\n",
       "        0.71458333, 0.69583333, 0.72291667, 0.7125    , 0.69375   ,\n",
       "        0.68958333, 0.72291667, 0.7375    , 0.72708333, 0.72708333,\n",
       "        0.72291667, 0.71666667, 0.72708333, 0.7125    , 0.72708333,\n",
       "        0.7125    , 0.72083333, 0.71875   ]),\n",
       " 'split2_test_score': array([0.72916667, 0.69166667, 0.68541667, 0.64375   , 0.71041667,\n",
       "        0.71458333, 0.71666667, 0.70833333, 0.71666667, 0.68333333,\n",
       "        0.69166667, 0.68541667, 0.70208333, 0.71041667, 0.69375   ,\n",
       "        0.67916667, 0.69375   , 0.71875   , 0.70416667, 0.69375   ,\n",
       "        0.7375    , 0.71458333, 0.72083333, 0.70833333, 0.71875   ,\n",
       "        0.73333333, 0.72708333, 0.71041667, 0.71875   , 0.72708333,\n",
       "        0.71666667, 0.70416667, 0.75      , 0.73958333, 0.7125    ,\n",
       "        0.71041667, 0.73541667, 0.73958333, 0.73541667, 0.73125   ,\n",
       "        0.73333333, 0.73333333, 0.73333333, 0.73125   , 0.73958333,\n",
       "        0.72708333, 0.73125   , 0.72916667]),\n",
       " 'split3_test_score': array([0.74583333, 0.68958333, 0.68541667, 0.65625   , 0.73333333,\n",
       "        0.68541667, 0.68958333, 0.69583333, 0.71875   , 0.70833333,\n",
       "        0.71875   , 0.72083333, 0.74583333, 0.70833333, 0.67916667,\n",
       "        0.67708333, 0.725     , 0.69583333, 0.67916667, 0.6875    ,\n",
       "        0.74166667, 0.70416667, 0.69166667, 0.69791667, 0.75      ,\n",
       "        0.725     , 0.70833333, 0.71041667, 0.73958333, 0.7       ,\n",
       "        0.70833333, 0.71666667, 0.72708333, 0.72083333, 0.72083333,\n",
       "        0.73541667, 0.76458333, 0.76875   , 0.75833333, 0.76458333,\n",
       "        0.76458333, 0.7625    , 0.75833333, 0.75416667, 0.76458333,\n",
       "        0.7625    , 0.7625    , 0.75625   ]),\n",
       " 'split4_test_score': array([0.73958333, 0.7125    , 0.68958333, 0.66458333, 0.71666667,\n",
       "        0.7375    , 0.70208333, 0.72291667, 0.74166667, 0.725     ,\n",
       "        0.70416667, 0.72083333, 0.75      , 0.73541667, 0.70416667,\n",
       "        0.65833333, 0.7125    , 0.70208333, 0.7125    , 0.7125    ,\n",
       "        0.74166667, 0.70625   , 0.71666667, 0.69375   , 0.75208333,\n",
       "        0.76041667, 0.74583333, 0.71875   , 0.74791667, 0.73958333,\n",
       "        0.73958333, 0.73125   , 0.75208333, 0.74583333, 0.725     ,\n",
       "        0.71666667, 0.78333333, 0.78958333, 0.79583333, 0.78333333,\n",
       "        0.78958333, 0.79791667, 0.79375   , 0.80208333, 0.78541667,\n",
       "        0.79166667, 0.78958333, 0.79375   ]),\n",
       " 'mean_test_score': array([0.73583333, 0.69875   , 0.68916667, 0.67333333, 0.71458333,\n",
       "        0.70666667, 0.69375   , 0.69791667, 0.72041667, 0.70333333,\n",
       "        0.69458333, 0.695     , 0.7325    , 0.715     , 0.695     ,\n",
       "        0.68041667, 0.71125   , 0.70333333, 0.68875   , 0.68791667,\n",
       "        0.72833333, 0.70333333, 0.70583333, 0.69958333, 0.73791667,\n",
       "        0.73      , 0.715     , 0.7125    , 0.73166667, 0.71708333,\n",
       "        0.71666667, 0.70875   , 0.73708333, 0.72791667, 0.71375   ,\n",
       "        0.71125   , 0.75375   , 0.76125   , 0.75791667, 0.75375   ,\n",
       "        0.75416667, 0.75208333, 0.7525    , 0.75125   , 0.755     ,\n",
       "        0.75291667, 0.75625   , 0.755     ]),\n",
       " 'std_test_score': array([0.00847791, 0.0089946 , 0.00333333, 0.0255631 , 0.01141089,\n",
       "        0.01818119, 0.017129  , 0.01692508, 0.01089725, 0.01799884,\n",
       "        0.01528661, 0.02175463, 0.02351861, 0.01293681, 0.01856857,\n",
       "        0.0215542 , 0.01034139, 0.01034139, 0.0213925 , 0.01615893,\n",
       "        0.0147667 , 0.02474172, 0.01822887, 0.00761486, 0.01745033,\n",
       "        0.01866183, 0.01986937, 0.00456435, 0.0115169 , 0.01463681,\n",
       "        0.0122899 , 0.01359126, 0.01188779, 0.01261062, 0.01083333,\n",
       "        0.01505776, 0.02170669, 0.01992172, 0.02497916, 0.02138438,\n",
       "        0.02371708, 0.02763854, 0.02347428, 0.03006359, 0.02022444,\n",
       "        0.02903542, 0.02631935, 0.02818589]),\n",
       " 'rank_test_score': array([15, 38, 44, 48, 26, 32, 43, 39, 21, 36, 42, 41, 16, 24, 40, 47, 29,\n",
       "        34, 45, 46, 19, 34, 33, 37, 13, 18, 24, 28, 17, 22, 23, 31, 14, 20,\n",
       "        27, 29,  7,  1,  2,  7,  6, 11, 10, 12,  5,  9,  3,  4],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([0.82864583, 0.86666667, 0.92604167, 0.97239583, 0.86197917,\n",
       "        0.9390625 , 0.99635417, 0.99635417, 0.85729167, 0.95104167,\n",
       "        0.99635417, 0.99635417, 0.82708333, 0.88229167, 0.928125  ,\n",
       "        0.965625  , 0.85260417, 0.92239583, 0.99427083, 0.99635417,\n",
       "        0.86875   , 0.9453125 , 0.99635417, 0.99635417, 0.828125  ,\n",
       "        0.87447917, 0.9171875 , 0.94322917, 0.85416667, 0.915625  ,\n",
       "        0.97083333, 0.99322917, 0.8640625 , 0.9328125 , 0.990625  ,\n",
       "        0.99427083, 0.78385417, 0.80625   , 0.81458333, 0.81822917,\n",
       "        0.79739583, 0.8078125 , 0.80885417, 0.81927083, 0.796875  ,\n",
       "        0.81458333, 0.82239583, 0.83229167]),\n",
       " 'split1_train_score': array([0.84635417, 0.88697917, 0.94114583, 0.978125  , 0.8578125 ,\n",
       "        0.92864583, 0.9953125 , 0.99739583, 0.8765625 , 0.9703125 ,\n",
       "        0.99739583, 0.99739583, 0.8421875 , 0.88854167, 0.93385417,\n",
       "        0.95833333, 0.8640625 , 0.93645833, 0.99479167, 0.99739583,\n",
       "        0.87083333, 0.9640625 , 0.99739583, 0.99739583, 0.84166667,\n",
       "        0.88489583, 0.91614583, 0.93697917, 0.85989583, 0.9171875 ,\n",
       "        0.97604167, 0.9921875 , 0.87291667, 0.95729167, 0.99375   ,\n",
       "        0.996875  , 0.7890625 , 0.82135417, 0.83020833, 0.83333333,\n",
       "        0.80364583, 0.82083333, 0.8375    , 0.84322917, 0.80989583,\n",
       "        0.83125   , 0.84270833, 0.84635417]),\n",
       " 'split2_train_score': array([0.84166667, 0.87395833, 0.91979167, 0.9625    , 0.84947917,\n",
       "        0.92291667, 0.98958333, 0.99583333, 0.875     , 0.96302083,\n",
       "        0.99583333, 0.99583333, 0.82916667, 0.8703125 , 0.9265625 ,\n",
       "        0.965625  , 0.85260417, 0.9078125 , 0.97291667, 0.99583333,\n",
       "        0.86770833, 0.95885417, 0.99583333, 0.99583333, 0.8296875 ,\n",
       "        0.87447917, 0.915625  , 0.94427083, 0.85208333, 0.91875   ,\n",
       "        0.97447917, 0.9890625 , 0.86875   , 0.9515625 , 0.99166667,\n",
       "        0.99583333, 0.8       , 0.8125    , 0.8171875 , 0.82239583,\n",
       "        0.79947917, 0.81875   , 0.8234375 , 0.825     , 0.80572917,\n",
       "        0.82604167, 0.8359375 , 0.84270833]),\n",
       " 'split3_train_score': array([0.82083333, 0.88229167, 0.940625  , 0.9796875 , 0.846875  ,\n",
       "        0.92239583, 0.99375   , 0.996875  , 0.8578125 , 0.9515625 ,\n",
       "        0.996875  , 0.996875  , 0.8359375 , 0.88645833, 0.93854167,\n",
       "        0.99114583, 0.83958333, 0.91197917, 0.99322917, 0.996875  ,\n",
       "        0.8640625 , 0.94635417, 0.996875  , 0.996875  , 0.82239583,\n",
       "        0.8828125 , 0.93020833, 0.94583333, 0.86510417, 0.92760417,\n",
       "        0.97864583, 0.990625  , 0.86875   , 0.95      , 0.9890625 ,\n",
       "        0.99479167, 0.7953125 , 0.79895833, 0.80416667, 0.81875   ,\n",
       "        0.7890625 , 0.80885417, 0.81666667, 0.81614583, 0.7984375 ,\n",
       "        0.80885417, 0.81927083, 0.83385417]),\n",
       " 'split4_train_score': array([0.84322917, 0.88802083, 0.9375    , 0.98385417, 0.85625   ,\n",
       "        0.92239583, 0.99322917, 0.9953125 , 0.8609375 , 0.94375   ,\n",
       "        0.9953125 , 0.9953125 , 0.83333333, 0.87916667, 0.93854167,\n",
       "        0.97447917, 0.853125  , 0.92135417, 0.98177083, 0.9953125 ,\n",
       "        0.86770833, 0.95729167, 0.9953125 , 0.9953125 , 0.82083333,\n",
       "        0.86979167, 0.91197917, 0.94166667, 0.85104167, 0.90989583,\n",
       "        0.95625   , 0.9828125 , 0.86927083, 0.9453125 , 0.9875    ,\n",
       "        0.99479167, 0.78177083, 0.78333333, 0.80104167, 0.80104167,\n",
       "        0.790625  , 0.80104167, 0.80625   , 0.8171875 , 0.79791667,\n",
       "        0.80625   , 0.81354167, 0.81875   ]),\n",
       " 'mean_train_score': array([0.83614583, 0.87958333, 0.93302083, 0.9753125 , 0.85447917,\n",
       "        0.92708333, 0.99364583, 0.99635417, 0.86552083, 0.9559375 ,\n",
       "        0.99635417, 0.99635417, 0.83354167, 0.88135417, 0.933125  ,\n",
       "        0.97104167, 0.85239583, 0.92      , 0.98739583, 0.99635417,\n",
       "        0.8678125 , 0.954375  , 0.99635417, 0.99635417, 0.82854167,\n",
       "        0.87729167, 0.91822917, 0.94239583, 0.85645833, 0.9178125 ,\n",
       "        0.97125   , 0.98958333, 0.86875   , 0.94739583, 0.99052083,\n",
       "        0.9953125 , 0.79      , 0.80447917, 0.8134375 , 0.81875   ,\n",
       "        0.79604167, 0.81145833, 0.81854167, 0.82416667, 0.80177083,\n",
       "        0.81739583, 0.82677083, 0.83479167]),\n",
       " 'std_train_score': array([0.0097528 , 0.00814501, 0.00857463, 0.00738482, 0.00553751,\n",
       "        0.00643814, 0.00231522, 0.00073657, 0.00848431, 0.00947058,\n",
       "        0.00073657, 0.00073657, 0.0053176 , 0.00640773, 0.00504537,\n",
       "        0.01127986, 0.00775744, 0.00991281, 0.00868653, 0.00073657,\n",
       "        0.00219493, 0.00733321, 0.00073657, 0.00073657, 0.00736127,\n",
       "        0.00566345, 0.00624131, 0.0030298 , 0.00529716, 0.00573768,\n",
       "        0.0079153 , 0.00366809, 0.00281443, 0.0082351 , 0.00214492,\n",
       "        0.00093169, 0.0068497 , 0.01288302, 0.01035607, 0.01039059,\n",
       "        0.0054685 , 0.00734357, 0.01124132, 0.01001084, 0.00513067,\n",
       "        0.00971379, 0.01084835, 0.0096003 ])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plotting the CV results for a gridsearch over one feature\n",
    "cv_results = embedding_mlp_grid_searcher.cv_results_\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_mlp_filename = os.path.join(output_dir, 'emb_mlp_yproba1_test.txt')\n",
    "test_on_estimator(embedding_mlp_grid_searcher.best_estimator_, x_test_embeddings, embedding_mlp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_cv_folds(cv_results, param_name, param_label, folds, log10=False, log2=False):\n",
    "    _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Get averages\n",
    "    mean_test_score = cv_results['mean_test_score']\n",
    "    mean_train_score = cv_results['mean_train_score']\n",
    "\n",
    "    # Get x_values\n",
    "    param_values = cv_results[f'param_{param_name}']\n",
    "    x_values = param_values.data.astype(np.float64)\n",
    "    if (log10):\n",
    "        x_values = np.log10(x_values)\n",
    "    elif (log2):\n",
    "        x_values = np.log2(x_values)\n",
    "\n",
    "    ax.plot(x_values, mean_test_score, '-bs', label=f'average test')\n",
    "    ax.plot(x_values, mean_train_score, '-rs', label=f'average train')\n",
    "\n",
    "    # Get overall mean_train_score\n",
    "    for fold in range(folds):\n",
    "        fold_scores = cv_results[f'split{fold}_test_score']\n",
    "        ax.plot(x_values, fold_scores, 's', label=f'{fold}-validation set')\n",
    "\n",
    "    ax.set_title(f\"{param_label} Grid Search Scores\", fontsize=20, fontweight='bold')\n",
    "    ax.set_xlabel(param_label, fontsize=16)\n",
    "    ax.set_ylabel('Balanced Accuracy', fontsize=16)\n",
    "    ax.legend(loc=\"best\", fontsize=15, bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the CV results for a gridsearch over one feature\n",
    "\n",
    "cv_results = embedding_mlp_grid_searcher.cv_results_\n",
    "# Two plots: One comparing train and test performance; one comparing all of the fold scores against one another \n",
    "# Plot one\n",
    "param = list(mlp_parameters.keys())[1]\n",
    "param_label = \"Hidden Layer Size, Log 2\"\n",
    "\n",
    "plot_cv_folds(cv_results, param, param_label, 5, log10=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Oh and I forgot to also mention the weird color effect it has on your phone.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fd028ea89a9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_mlp_best_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_mlp_grid_searcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manalysis_of_mistakes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_mlp_best_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/comp135/sentiment-analysis/utils.py\u001b[0m in \u001b[0;36manalysis_of_mistakes\u001b[0;34m(pipeline_with_vectorizer, x_train_df, y_train)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manalysis_of_mistakes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_with_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mx_train_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mtn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_confusion_matrix_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_with_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0mtf_preprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_with_vectorizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/comp135/sentiment-analysis/utils.py\u001b[0m in \u001b[0;36m_confusion_matrix_idx\u001b[0;34m(estimator, y_train, x_train)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_confusion_matrix_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m# Get all of the indices for each quadrant in the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_final_estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         \"\"\"\n\u001b[1;32m   1003\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Oh and I forgot to also mention the weird color effect it has on your phone.'"
     ]
    }
   ],
   "source": [
    "embedding_mlp_best_pipeline = embedding_mlp_grid_searcher.best_estimator_\n",
    "analysis_of_mistakes(embedding_mlp_best_pipeline, x_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_split_scores_columns = ['split0_train_score','split1_train_score','split2_train_score','split3_train_score','split4_train_score']\n",
    "# test_split_scores_columns = ['split0_test_score','split1_test_score','split2_test_score','split3_test_score','split4_test_score']\n",
    "\n",
    "# hidden_layers16_df = embedding_df[embedding_df['param_mlp__hidden_layer_sizes'] == 16]\n",
    "# hidden_layers16_df_50iters = hidden_layers16_df[hidden_layers16_df['param_mlp__max_iter'] == 50]\n",
    "# hidden_layers16_df_50iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# alpha_values = [0.0001,0.01,1, 10]\n",
    "# y_split0_test = hidden_layers16_df_50iters['split0_test_score'].values\n",
    "# y_split1_test = hidden_layers16_df_50iters['split1_test_score'].values\n",
    "# y_split2_test = hidden_layers16_df_50iters['split2_test_score'].values\n",
    "# y_split3_test = hidden_layers16_df_50iters['split3_test_score'].values\n",
    "# y_split4_test = hidden_layers16_df_50iters['split4_test_score'].values\n",
    "\n",
    "# plt.plot(alpha_values, y_split0_test, linewidth=1)\n",
    "# plt.plot(alpha_values, y_split1_test, linewidth=1)\n",
    "# plt.plot(alpha_values, y_split2_test, linewidth=1)\n",
    "# plt.plot(alpha_values, y_split3_test, linewidth=1)\n",
    "# plt.plot(alpha_values, y_split4_test, linewidth=1)\n",
    "\n",
    "# plt.xticks(alpha_values)\n",
    "# plt.xlabel('Alpha Values')\n",
    "# plt.ylabel('Balanced Accuracy scores')\n",
    "# #display plot\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
