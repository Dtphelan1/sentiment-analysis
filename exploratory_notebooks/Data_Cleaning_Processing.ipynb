{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Custom functions \n",
    "def print_gridsearch_results(grid_searcher, unique_params):\n",
    "    # For a given gridsearcher and the relevant params used in grid_search, print the results of the runs\n",
    "    # Get the data as a pandas DF\n",
    "    gsearch_results_df = pd.DataFrame(grid_searcher.cv_results_).copy()\n",
    "    print(\"Dataframe has shape: %s\" % (str(gsearch_results_df.shape)))\n",
    "    n_trials_grid_search = gsearch_results_df.shape[0]\n",
    "    print(\"Number of trials used in grid search: \", n_trials_grid_search)\n",
    "\n",
    "    # Rearrange row order so it is easy to skim\n",
    "    gsearch_results_df.sort_values('rank_test_score', inplace=True)\n",
    "    # Transform param-text to match up with cv_results_ representation\n",
    "    param_keys = [f\"param_{key}\" for key in unique_params]\n",
    "    return(gsearch_results_df[param_keys + ['mean_train_score', 'mean_test_score', 'mean_fit_time', 'rank_test_score']])\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: Importing the Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data\n",
      "---------------\n",
      "x_train_df shape: (2400, 2) \n",
      "y_train_df shape: (2400, 1) \n"
     ]
    }
   ],
   "source": [
    "data_dir = '../data_reviews'\n",
    "x_train_df = pd.read_csv(os.path.join(data_dir, 'x_train.csv'))\n",
    "y_train_df = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))\n",
    "\n",
    "print(\"Shape of data\\n---------------\")\n",
    "print(f\"x_train_df shape: {x_train_df.shape} \")\n",
    "print(f\"y_train_df shape: {y_train_df.shape} \")\n",
    "\n",
    "# Get the text as a list of strings\n",
    "x_train_text = x_train_df['text'].values\n",
    "y_train = y_train_df['is_positive_sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic comparison of two vectorizers - one with counts and one using tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_vectorizer.fit_transform(x_train_text)\n",
    "x_train_text_count = count_vectorizer.transform(x_train_text).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tf_vectorizer.fit_transform(x_train_text)\n",
    "x_train_text_tf = tf_vectorizer.transform(x_train_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train two Random Forests to compare performance\n",
    "\n",
    "This manual approach to training models is no longer neceesary, as the pipeline enables a much speedier and more effective way of performing this comparison while also tuning hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pipeline to try many tf-idf hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 60 candidates, totalling 420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=3)]: Done 282 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=3)]: Done 420 out of 420 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('clf',\n",
       "                                        RandomForestClassifier(random_state=123))]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'tfidf__max_df': (0.05, 0.1, 0.5, 1.0),\n",
       "                         'tfidf__min_df': array([1, 2, 3, 4, 5]),\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             return_train_score=True, scoring='balanced_accuracy', verbose=3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    " ])\n",
    "tfidf_parameters = {\n",
    "    'tfidf__min_df': np.arange(1,6),\n",
    "    'tfidf__max_df': (0.05, 0.1, 0.5, 1.0),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
    "}\n",
    "\n",
    "tfidf_grid_searcher = GridSearchCV(\n",
    "    tfidf_pipeline, \n",
    "    tfidf_parameters, \n",
    "    cv=7, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "tfidf_grid_searcher.fit(x_train_text, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (60, 27)\n",
      "Number of trials used in grid search:  60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidf__min_df</th>\n",
       "      <th>param_tfidf__max_df</th>\n",
       "      <th>param_tfidf__ngram_range</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.995637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.924576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.786251</td>\n",
       "      <td>0.934312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.780403</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.780403</td>\n",
       "      <td>0.863084</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.780403</td>\n",
       "      <td>0.977097</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.777073</td>\n",
       "      <td>1.043903</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.777073</td>\n",
       "      <td>1.124920</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.777073</td>\n",
       "      <td>1.120552</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.775427</td>\n",
       "      <td>1.874980</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.775427</td>\n",
       "      <td>1.885893</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.775427</td>\n",
       "      <td>1.706737</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.980972</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.980972</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.911444</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.980972</td>\n",
       "      <td>0.774154</td>\n",
       "      <td>0.909964</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.955904</td>\n",
       "      <td>0.769965</td>\n",
       "      <td>0.775965</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.955904</td>\n",
       "      <td>0.769965</td>\n",
       "      <td>0.709534</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.955904</td>\n",
       "      <td>0.769965</td>\n",
       "      <td>0.764895</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.768741</td>\n",
       "      <td>0.855807</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.768741</td>\n",
       "      <td>0.821071</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.768741</td>\n",
       "      <td>0.738255</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.768321</td>\n",
       "      <td>0.810736</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.768321</td>\n",
       "      <td>0.870901</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.768321</td>\n",
       "      <td>0.781736</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.768311</td>\n",
       "      <td>0.736079</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.768311</td>\n",
       "      <td>0.730330</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.967153</td>\n",
       "      <td>0.768311</td>\n",
       "      <td>0.778407</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.765807</td>\n",
       "      <td>0.730099</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.765807</td>\n",
       "      <td>0.755542</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.955903</td>\n",
       "      <td>0.765807</td>\n",
       "      <td>0.757120</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.989237</td>\n",
       "      <td>0.741617</td>\n",
       "      <td>0.961367</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.732048</td>\n",
       "      <td>1.765338</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.995279</td>\n",
       "      <td>0.731509</td>\n",
       "      <td>1.003809</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.987016</td>\n",
       "      <td>0.730285</td>\n",
       "      <td>0.871158</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.975905</td>\n",
       "      <td>0.729542</td>\n",
       "      <td>0.852134</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.941746</td>\n",
       "      <td>0.726135</td>\n",
       "      <td>0.743742</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.957021</td>\n",
       "      <td>0.721576</td>\n",
       "      <td>0.743386</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.942986</td>\n",
       "      <td>0.721195</td>\n",
       "      <td>0.773516</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.958336</td>\n",
       "      <td>0.720345</td>\n",
       "      <td>0.788407</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.973547</td>\n",
       "      <td>0.719493</td>\n",
       "      <td>0.844294</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.579642</td>\n",
       "      <td>1.817633</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.579642</td>\n",
       "      <td>1.730549</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.579642</td>\n",
       "      <td>1.687833</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.579642</td>\n",
       "      <td>1.810466</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560051</td>\n",
       "      <td>0.510308</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560051</td>\n",
       "      <td>0.461837</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560051</td>\n",
       "      <td>0.547168</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560051</td>\n",
       "      <td>0.468648</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.355796</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.328095</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.341886</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.335875</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.289960</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.276427</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.263290</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.322909</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.536529</td>\n",
       "      <td>0.516276</td>\n",
       "      <td>0.253025</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.536529</td>\n",
       "      <td>0.516276</td>\n",
       "      <td>0.248875</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.536529</td>\n",
       "      <td>0.516276</td>\n",
       "      <td>0.227836</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.536529</td>\n",
       "      <td>0.516276</td>\n",
       "      <td>0.246163</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_tfidf__min_df param_tfidf__max_df param_tfidf__ngram_range  \\\n",
       "34                   2                 0.5                   (1, 2)   \n",
       "19                   2                 0.1                   (1, 2)   \n",
       "49                   2                   1                   (1, 2)   \n",
       "18                   2                 0.1                   (1, 1)   \n",
       "48                   2                   1                   (1, 1)   \n",
       "33                   2                 0.5                   (1, 1)   \n",
       "45                   1                   1                   (1, 1)   \n",
       "15                   1                 0.1                   (1, 1)   \n",
       "30                   1                 0.5                   (1, 1)   \n",
       "46                   1                   1                   (1, 2)   \n",
       "31                   1                 0.5                   (1, 2)   \n",
       "16                   1                 0.1                   (1, 2)   \n",
       "22                   3                 0.1                   (1, 2)   \n",
       "37                   3                 0.5                   (1, 2)   \n",
       "52                   3                   1                   (1, 2)   \n",
       "28                   5                 0.1                   (1, 2)   \n",
       "58                   5                   1                   (1, 2)   \n",
       "43                   5                 0.5                   (1, 2)   \n",
       "51                   3                   1                   (1, 1)   \n",
       "36                   3                 0.5                   (1, 1)   \n",
       "21                   3                 0.1                   (1, 1)   \n",
       "25                   4                 0.1                   (1, 2)   \n",
       "55                   4                   1                   (1, 2)   \n",
       "40                   4                 0.5                   (1, 2)   \n",
       "24                   4                 0.1                   (1, 1)   \n",
       "39                   4                 0.5                   (1, 1)   \n",
       "54                   4                   1                   (1, 1)   \n",
       "42                   5                 0.5                   (1, 1)   \n",
       "27                   5                 0.1                   (1, 1)   \n",
       "57                   5                   1                   (1, 1)   \n",
       "4                    2                0.05                   (1, 2)   \n",
       "1                    1                0.05                   (1, 2)   \n",
       "0                    1                0.05                   (1, 1)   \n",
       "3                    2                0.05                   (1, 1)   \n",
       "7                    3                0.05                   (1, 2)   \n",
       "12                   5                0.05                   (1, 1)   \n",
       "9                    4                0.05                   (1, 1)   \n",
       "13                   5                0.05                   (1, 2)   \n",
       "10                   4                0.05                   (1, 2)   \n",
       "6                    3                0.05                   (1, 1)   \n",
       "47                   1                   1                   (2, 2)   \n",
       "17                   1                 0.1                   (2, 2)   \n",
       "2                    1                0.05                   (2, 2)   \n",
       "32                   1                 0.5                   (2, 2)   \n",
       "50                   2                   1                   (2, 2)   \n",
       "20                   2                 0.1                   (2, 2)   \n",
       "5                    2                0.05                   (2, 2)   \n",
       "35                   2                 0.5                   (2, 2)   \n",
       "53                   3                   1                   (2, 2)   \n",
       "23                   3                 0.1                   (2, 2)   \n",
       "38                   3                 0.5                   (2, 2)   \n",
       "8                    3                0.05                   (2, 2)   \n",
       "26                   4                 0.1                   (2, 2)   \n",
       "41                   4                 0.5                   (2, 2)   \n",
       "11                   4                0.05                   (2, 2)   \n",
       "56                   4                   1                   (2, 2)   \n",
       "29                   5                 0.1                   (2, 2)   \n",
       "14                   5                0.05                   (2, 2)   \n",
       "44                   5                 0.5                   (2, 2)   \n",
       "59                   5                   1                   (2, 2)   \n",
       "\n",
       "    mean_train_score  mean_test_score  mean_fit_time  rank_test_score  \n",
       "34          0.992430         0.786251       0.995637                1  \n",
       "19          0.992430         0.786251       0.924576                1  \n",
       "49          0.992430         0.786251       0.934312                1  \n",
       "18          0.992430         0.780403       0.840764                4  \n",
       "48          0.992430         0.780403       0.863084                4  \n",
       "33          0.992430         0.780403       0.977097                4  \n",
       "45          0.997083         0.777073       1.043903                7  \n",
       "15          0.997083         0.777073       1.124920                7  \n",
       "30          0.997083         0.777073       1.120552                7  \n",
       "46          0.997153         0.775427       1.874980               10  \n",
       "31          0.997153         0.775427       1.885893               10  \n",
       "16          0.997153         0.775427       1.706737               10  \n",
       "22          0.980972         0.774154       0.873563               13  \n",
       "37          0.980972         0.774154       0.911444               13  \n",
       "52          0.980972         0.774154       0.909964               13  \n",
       "28          0.955904         0.769965       0.775965               16  \n",
       "58          0.955904         0.769965       0.709534               16  \n",
       "43          0.955904         0.769965       0.764895               16  \n",
       "51          0.980833         0.768741       0.855807               19  \n",
       "36          0.980833         0.768741       0.821071               19  \n",
       "21          0.980833         0.768741       0.738255               19  \n",
       "25          0.967153         0.768321       0.810736               22  \n",
       "55          0.967153         0.768321       0.870901               22  \n",
       "40          0.967153         0.768321       0.781736               22  \n",
       "24          0.967153         0.768311       0.736079               25  \n",
       "39          0.967153         0.768311       0.730330               25  \n",
       "54          0.967153         0.768311       0.778407               25  \n",
       "42          0.955903         0.765807       0.730099               28  \n",
       "27          0.955903         0.765807       0.755542               28  \n",
       "57          0.955903         0.765807       0.757120               28  \n",
       "4           0.989237         0.741617       0.961367               31  \n",
       "1           0.997083         0.732048       1.765338               32  \n",
       "0           0.995279         0.731509       1.003809               33  \n",
       "3           0.987016         0.730285       0.871158               34  \n",
       "7           0.975905         0.729542       0.852134               35  \n",
       "12          0.941746         0.726135       0.743742               36  \n",
       "9           0.957021         0.721576       0.743386               37  \n",
       "13          0.942986         0.721195       0.773516               38  \n",
       "10          0.958336         0.720345       0.788407               39  \n",
       "6           0.973547         0.719493       0.844294               40  \n",
       "47          0.979236         0.579642       1.817633               41  \n",
       "17          0.979236         0.579642       1.730549               41  \n",
       "2           0.979236         0.579642       1.687833               41  \n",
       "32          0.979236         0.579642       1.810466               41  \n",
       "50          0.678749         0.560051       0.510308               45  \n",
       "20          0.678749         0.560051       0.461837               45  \n",
       "5           0.678749         0.560051       0.547168               45  \n",
       "35          0.678749         0.560051       0.468648               45  \n",
       "53          0.589725         0.537128       0.355796               49  \n",
       "23          0.589725         0.537128       0.328095               49  \n",
       "38          0.589725         0.537128       0.341886               49  \n",
       "8           0.589725         0.537128       0.335875               49  \n",
       "26          0.553336         0.522530       0.289960               53  \n",
       "41          0.553336         0.522530       0.276427               53  \n",
       "11          0.553336         0.522530       0.263290               53  \n",
       "56          0.553336         0.522530       0.322909               53  \n",
       "29          0.536529         0.516276       0.253025               57  \n",
       "14          0.536529         0.516276       0.248875               57  \n",
       "44          0.536529         0.516276       0.227836               57  \n",
       "59          0.536529         0.516276       0.246163               57  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(tfidf_grid_searcher, list(tfidf_parameters.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "TfidfVectorizer(max_df=0.1, min_df=2, ngram_range=(1, 2), stop_words='english')\n",
      "{'tfidf__max_df': 0.1, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.00380949, 1.76533845, 1.68783314, 0.8711585 , 0.96136699,\n",
       "        0.54716791, 0.84429421, 0.85213382, 0.3358749 , 0.7433861 ,\n",
       "        0.78840739, 0.26329   , 0.74374199, 0.77351608, 0.2488749 ,\n",
       "        1.12491958, 1.70673708, 1.73054934, 0.84076398, 0.92457587,\n",
       "        0.46183705, 0.73825492, 0.87356343, 0.32809462, 0.73607857,\n",
       "        0.81073628, 0.28995964, 0.7555416 , 0.77596477, 0.25302533,\n",
       "        1.12055159, 1.88589304, 1.81046646, 0.97709686, 0.99563691,\n",
       "        0.46864809, 0.82107118, 0.91144436, 0.34188598, 0.73033026,\n",
       "        0.78173634, 0.27642713, 0.73009855, 0.76489541, 0.2278364 ,\n",
       "        1.04390335, 1.8749796 , 1.81763288, 0.86308353, 0.934312  ,\n",
       "        0.5103083 , 0.855807  , 0.90996436, 0.35579603, 0.77840706,\n",
       "        0.87090118, 0.32290891, 0.75712017, 0.70953366, 0.24616344]),\n",
       " 'std_fit_time': array([0.04221072, 0.05026874, 0.0870811 , 0.06279129, 0.04165447,\n",
       "        0.03546871, 0.04061509, 0.03053882, 0.0091335 , 0.02643231,\n",
       "        0.04098493, 0.02236648, 0.02769582, 0.02243201, 0.01921534,\n",
       "        0.11797889, 0.07969438, 0.11403943, 0.04527783, 0.05968291,\n",
       "        0.03733288, 0.01909157, 0.07085005, 0.01405138, 0.0367995 ,\n",
       "        0.0180486 , 0.0158495 , 0.03754004, 0.03071885, 0.01928148,\n",
       "        0.09349716, 0.06258157, 0.12486793, 0.0797303 , 0.04074687,\n",
       "        0.02877626, 0.0392411 , 0.04079065, 0.04299703, 0.01449515,\n",
       "        0.02370124, 0.01330208, 0.02044726, 0.04512415, 0.00917557,\n",
       "        0.02627493, 0.1603984 , 0.14807974, 0.02971971, 0.04130842,\n",
       "        0.03547857, 0.02139906, 0.03807643, 0.0216486 , 0.03860353,\n",
       "        0.02859591, 0.02180013, 0.04246211, 0.02071206, 0.01797517]),\n",
       " 'mean_score_time': array([0.04878518, 0.05794954, 0.16468855, 0.04864839, 0.05387265,\n",
       "        0.05659294, 0.04495229, 0.04990421, 0.03610505, 0.0401675 ,\n",
       "        0.04330407, 0.02818332, 0.04270656, 0.04156504, 0.02220947,\n",
       "        0.04916378, 0.05250205, 0.16754113, 0.04182175, 0.04909004,\n",
       "        0.04960714, 0.04067734, 0.04670596, 0.03269434, 0.04255131,\n",
       "        0.04582044, 0.02878513, 0.0398047 , 0.04419759, 0.02876384,\n",
       "        0.05169436, 0.06238937, 0.17258229, 0.04765643, 0.04786675,\n",
       "        0.05532472, 0.04534728, 0.0473377 , 0.03605768, 0.04384593,\n",
       "        0.04330128, 0.02785642, 0.04317849, 0.04208326, 0.02305443,\n",
       "        0.04768576, 0.0602654 , 0.17489004, 0.04748852, 0.04773201,\n",
       "        0.05414983, 0.04073429, 0.05057042, 0.04125575, 0.04266589,\n",
       "        0.05252297, 0.03640567, 0.03865685, 0.03993164, 0.02265821]),\n",
       " 'std_score_time': array([0.00644272, 0.00178524, 0.01905734, 0.00339823, 0.01017422,\n",
       "        0.00462527, 0.00349222, 0.00321603, 0.00375179, 0.00205217,\n",
       "        0.00191268, 0.00364045, 0.00449983, 0.00364131, 0.0015555 ,\n",
       "        0.00562198, 0.00234278, 0.00887939, 0.00255245, 0.00529942,\n",
       "        0.00198861, 0.00273641, 0.00517209, 0.00253018, 0.00390593,\n",
       "        0.00405679, 0.00330074, 0.0050626 , 0.00510874, 0.00435694,\n",
       "        0.00682358, 0.00760105, 0.01383774, 0.00703199, 0.00433257,\n",
       "        0.00520422, 0.0030038 , 0.0024982 , 0.00644783, 0.00520132,\n",
       "        0.00400629, 0.0020082 , 0.00070386, 0.00288748, 0.00243234,\n",
       "        0.00284673, 0.00756811, 0.01128338, 0.00555617, 0.00390547,\n",
       "        0.00276526, 0.0017301 , 0.00515528, 0.00353848, 0.00465317,\n",
       "        0.0106837 , 0.00668159, 0.00288083, 0.00202687, 0.00235582]),\n",
       " 'param_tfidf__max_df': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__min_df': masked_array(data=[1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1,\n",
       "                    2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2,\n",
       "                    3, 3, 3, 4, 4, 4, 5, 5, 5, 1, 1, 1, 2, 2, 2, 3, 3, 3,\n",
       "                    4, 4, 4, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 2), (2, 2), (1, 1), (1, 2), (2, 2), (1, 1),\n",
       "                    (1, 2), (2, 2), (1, 1), (1, 2), (2, 2), (1, 1), (1, 2),\n",
       "                    (2, 2), (1, 1), (1, 2), (2, 2), (1, 1), (1, 2), (2, 2),\n",
       "                    (1, 1), (1, 2), (2, 2), (1, 1), (1, 2), (2, 2), (1, 1),\n",
       "                    (1, 2), (2, 2), (1, 1), (1, 2), (2, 2), (1, 1), (1, 2),\n",
       "                    (2, 2), (1, 1), (1, 2), (2, 2), (1, 1), (1, 2), (2, 2),\n",
       "                    (1, 1), (1, 2), (2, 2), (1, 1), (1, 2), (2, 2), (1, 1),\n",
       "                    (1, 2), (2, 2), (1, 1), (1, 2), (2, 2), (1, 1), (1, 2),\n",
       "                    (2, 2), (1, 1), (1, 2), (2, 2)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'tfidf__max_df': 0.05,\n",
       "   'tfidf__min_df': 1,\n",
       "   'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 1, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 2, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 3, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 4, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.05, 'tfidf__min_df': 5, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 2, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 3, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 4, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.1, 'tfidf__min_df': 5, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 1, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 2, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 3, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 4, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 0.5, 'tfidf__min_df': 5, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 1, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 2, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 3, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 4, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 4, 'tfidf__ngram_range': (2, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 1)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)},\n",
       "  {'tfidf__max_df': 1.0, 'tfidf__min_df': 5, 'tfidf__ngram_range': (2, 2)}],\n",
       " 'split0_test_score': array([0.72582619, 0.71130831, 0.60534816, 0.72582619, 0.7374371 ,\n",
       "        0.58484632, 0.71710526, 0.70835033, 0.56436149, 0.72004624,\n",
       "        0.72002924, 0.54678363, 0.70835033, 0.71424929, 0.54385965,\n",
       "        0.78423773, 0.76674487, 0.60534816, 0.77838977, 0.79297566,\n",
       "        0.58484632, 0.78131375, 0.7870937 , 0.56436149, 0.7870767 ,\n",
       "        0.7754318 , 0.54678363, 0.77249082, 0.7870597 , 0.54385965,\n",
       "        0.78423773, 0.76674487, 0.60534816, 0.77838977, 0.79297566,\n",
       "        0.58484632, 0.78131375, 0.7870937 , 0.56436149, 0.7870767 ,\n",
       "        0.7754318 , 0.54678363, 0.77249082, 0.7870597 , 0.54385965,\n",
       "        0.78423773, 0.76674487, 0.60534816, 0.77838977, 0.79297566,\n",
       "        0.58484632, 0.78131375, 0.7870937 , 0.56436149, 0.7870767 ,\n",
       "        0.7754318 , 0.54678363, 0.77249082, 0.7870597 , 0.54385965]),\n",
       " 'split1_test_score': array([0.70819733, 0.71695226, 0.61422209, 0.6995274 , 0.70243438,\n",
       "        0.59368625, 0.67917857, 0.67917857, 0.55856453, 0.68507752,\n",
       "        0.67630559, 0.54389365, 0.70245138, 0.70246838, 0.52923977,\n",
       "        0.75776894, 0.7752958 , 0.61422209, 0.76354889, 0.78109275,\n",
       "        0.59368625, 0.75202298, 0.76366789, 0.55856453, 0.76665987,\n",
       "        0.7754148 , 0.54389365, 0.76665987, 0.78411873, 0.52923977,\n",
       "        0.75776894, 0.7752958 , 0.61422209, 0.76354889, 0.78109275,\n",
       "        0.59368625, 0.75202298, 0.76366789, 0.55856453, 0.76665987,\n",
       "        0.7754148 , 0.54389365, 0.76665987, 0.78411873, 0.52923977,\n",
       "        0.75776894, 0.7752958 , 0.61422209, 0.76354889, 0.78109275,\n",
       "        0.59368625, 0.75202298, 0.76366789, 0.55856453, 0.76665987,\n",
       "        0.7754148 , 0.54389365, 0.76665987, 0.78411873, 0.52923977]),\n",
       " 'split2_test_score': array([0.77563579, 0.76353189, 0.55854753, 0.76667687, 0.75486196,\n",
       "        0.5497756 , 0.77255882, 0.76655787, 0.52051884, 0.7754998 ,\n",
       "        0.76963484, 0.52048484, 0.7754828 , 0.7754658 , 0.51756086,\n",
       "        0.76346389, 0.78097375, 0.55854753, 0.80145859, 0.79273766,\n",
       "        0.5497756 , 0.78986468, 0.78984768, 0.52051884, 0.78110975,\n",
       "        0.78984768, 0.52048484, 0.80159459, 0.80450156, 0.51756086,\n",
       "        0.76346389, 0.78097375, 0.55854753, 0.80145859, 0.79273766,\n",
       "        0.5497756 , 0.78986468, 0.78984768, 0.52051884, 0.78110975,\n",
       "        0.78984768, 0.52048484, 0.80159459, 0.80450156, 0.51756086,\n",
       "        0.76346389, 0.78097375, 0.55854753, 0.80145859, 0.79273766,\n",
       "        0.5497756 , 0.78986468, 0.78984768, 0.52051884, 0.78110975,\n",
       "        0.78984768, 0.52048484, 0.80159459, 0.80450156, 0.51756086]),\n",
       " 'split3_test_score': array([0.75205698, 0.75535496, 0.53177275, 0.74049708, 0.749575  ,\n",
       "        0.51727186, 0.70846933, 0.73500612, 0.51451788, 0.71132531,\n",
       "        0.72023324, 0.499983  , 0.7375561 , 0.72028424, 0.50290698,\n",
       "        0.7378961 , 0.75549096, 0.53177275, 0.75246498, 0.76123691,\n",
       "        0.51727186, 0.73497212, 0.74372705, 0.51451788, 0.74651503,\n",
       "        0.7377771 , 0.499983  , 0.73186115, 0.74061608, 0.50290698,\n",
       "        0.7378961 , 0.75549096, 0.53177275, 0.75246498, 0.76123691,\n",
       "        0.51727186, 0.73497212, 0.74372705, 0.51451788, 0.74651503,\n",
       "        0.7377771 , 0.499983  , 0.73186115, 0.74061608, 0.50290698,\n",
       "        0.7378961 , 0.75549096, 0.53177275, 0.75246498, 0.76123691,\n",
       "        0.51727186, 0.73497212, 0.74372705, 0.51451788, 0.74651503,\n",
       "        0.7377771 , 0.499983  , 0.73186115, 0.74061608, 0.50290698]),\n",
       " 'split4_test_score': array([0.71693526, 0.69680743, 0.57262342, 0.72283422, 0.74337005,\n",
       "        0.5377057 , 0.71705426, 0.74348905, 0.53197674, 0.74031008,\n",
       "        0.72869917, 0.51744186, 0.71110431, 0.70841833, 0.50581395,\n",
       "        0.77857677, 0.75817693, 0.57262342, 0.76982184, 0.75815993,\n",
       "        0.5377057 , 0.75805794, 0.76390589, 0.53197674, 0.72303822,\n",
       "        0.74348905, 0.51744186, 0.72592819, 0.72591119, 0.50581395,\n",
       "        0.77857677, 0.75817693, 0.57262342, 0.76982184, 0.75815993,\n",
       "        0.5377057 , 0.75805794, 0.76390589, 0.53197674, 0.72303822,\n",
       "        0.74348905, 0.51744186, 0.72592819, 0.72591119, 0.50581395,\n",
       "        0.77857677, 0.75817693, 0.57262342, 0.76982184, 0.75815993,\n",
       "        0.5377057 , 0.75805794, 0.76390589, 0.53197674, 0.72303822,\n",
       "        0.74348905, 0.51744186, 0.72592819, 0.72591119, 0.50581395]),\n",
       " 'split5_test_score': array([0.71384129, 0.75231198, 0.56679247, 0.72271522, 0.76094791,\n",
       "        0.55519856, 0.71693526, 0.73152115, 0.53194274, 0.68485652,\n",
       "        0.70821433, 0.51742486, 0.71115531, 0.70818033, 0.51162791,\n",
       "        0.81640147, 0.79306066, 0.56679247, 0.80181559, 0.81930845,\n",
       "        0.55519856, 0.7871787 , 0.78428873, 0.53194274, 0.77260982,\n",
       "        0.77266082, 0.51742486, 0.76679587, 0.76099891, 0.51162791,\n",
       "        0.81640147, 0.79306066, 0.56679247, 0.80181559, 0.81930845,\n",
       "        0.55519856, 0.7871787 , 0.78428873, 0.53194274, 0.77260982,\n",
       "        0.77266082, 0.51742486, 0.76679587, 0.76099891, 0.51162791,\n",
       "        0.81640147, 0.79306066, 0.56679247, 0.80181559, 0.81930845,\n",
       "        0.55519856, 0.7871787 , 0.78428873, 0.53194274, 0.77260982,\n",
       "        0.77266082, 0.51742486, 0.76679587, 0.76099891, 0.51162791]),\n",
       " 'split6_test_score': array([0.72807018, 0.72807018, 0.60818713, 0.73391813, 0.74269006,\n",
       "        0.58187135, 0.7251462 , 0.74269006, 0.5380117 , 0.73391813,\n",
       "        0.71929825, 0.51169591, 0.73684211, 0.71929825, 0.50292398,\n",
       "        0.80116959, 0.79824561, 0.60818713, 0.79532164, 0.79824561,\n",
       "        0.58187135, 0.77777778, 0.78654971, 0.5380117 , 0.80116959,\n",
       "        0.78362573, 0.51169591, 0.79532164, 0.78654971, 0.50292398,\n",
       "        0.80116959, 0.79824561, 0.60818713, 0.79532164, 0.79824561,\n",
       "        0.58187135, 0.77777778, 0.78654971, 0.5380117 , 0.80116959,\n",
       "        0.78362573, 0.51169591, 0.79532164, 0.78654971, 0.50292398,\n",
       "        0.80116959, 0.79824561, 0.60818713, 0.79532164, 0.79824561,\n",
       "        0.58187135, 0.77777778, 0.78654971, 0.5380117 , 0.80116959,\n",
       "        0.78362573, 0.51169591, 0.79532164, 0.78654971, 0.50292398]),\n",
       " 'mean_test_score': array([0.73150901, 0.73204814, 0.57964193, 0.73028501, 0.74161664,\n",
       "        0.56005081, 0.71949253, 0.72954188, 0.5371277 , 0.72157623,\n",
       "        0.72034495, 0.52252968, 0.72613462, 0.72119494, 0.51627616,\n",
       "        0.7770735 , 0.77542694, 0.57964193, 0.78040304, 0.786251  ,\n",
       "        0.56005081, 0.76874114, 0.77415438, 0.5371277 , 0.76831128,\n",
       "        0.768321  , 0.52252968, 0.76580744, 0.76996513, 0.51627616,\n",
       "        0.7770735 , 0.77542694, 0.57964193, 0.78040304, 0.786251  ,\n",
       "        0.56005081, 0.76874114, 0.77415438, 0.5371277 , 0.76831128,\n",
       "        0.768321  , 0.52252968, 0.76580744, 0.76996513, 0.51627616,\n",
       "        0.7770735 , 0.77542694, 0.57964193, 0.78040304, 0.786251  ,\n",
       "        0.56005081, 0.76874114, 0.77415438, 0.5371277 , 0.76831128,\n",
       "        0.768321  , 0.52252968, 0.76580744, 0.76996513, 0.51627616]),\n",
       " 'std_test_score': array([0.02230147, 0.023485  , 0.02834035, 0.01897585, 0.01760445,\n",
       "        0.02585885, 0.02567073, 0.02606832, 0.01708162, 0.02975842,\n",
       "        0.02559886, 0.01570497, 0.0239279 , 0.02293251, 0.01423594,\n",
       "        0.02470874, 0.0152728 , 0.02834035, 0.01814627, 0.01987598,\n",
       "        0.02585885, 0.01912311, 0.01608404, 0.01708162, 0.02432383,\n",
       "        0.0183883 , 0.01570497, 0.02656766, 0.02630283, 0.01423594,\n",
       "        0.02470874, 0.0152728 , 0.02834035, 0.01814627, 0.01987598,\n",
       "        0.02585885, 0.01912311, 0.01608404, 0.01708162, 0.02432383,\n",
       "        0.0183883 , 0.01570497, 0.02656766, 0.02630283, 0.01423594,\n",
       "        0.02470874, 0.0152728 , 0.02834035, 0.01814627, 0.01987598,\n",
       "        0.02585885, 0.01912311, 0.01608404, 0.01708162, 0.02432383,\n",
       "        0.0183883 , 0.01570497, 0.02656766, 0.02630283, 0.01423594]),\n",
       " 'rank_test_score': array([33, 32, 41, 34, 31, 45, 40, 35, 49, 37, 39, 53, 36, 38, 57,  7, 10,\n",
       "        41,  4,  1, 45, 19, 13, 49, 25, 22, 53, 28, 16, 57,  7, 10, 41,  4,\n",
       "         1, 45, 19, 13, 49, 25, 22, 53, 28, 16, 57,  7, 10, 41,  4,  1, 45,\n",
       "        19, 13, 49, 25, 22, 53, 28, 16, 57], dtype=int32),\n",
       " 'split0_train_score': array([0.9956254 , 0.99708313, 0.97910593, 0.98882174, 0.99076584,\n",
       "        0.67345804, 0.97569984, 0.97715898, 0.58113682, 0.95722869,\n",
       "        0.95820146, 0.54664109, 0.94264765, 0.94313356, 0.53449431,\n",
       "        0.99708313, 0.99708313, 0.97910593, 0.99368082, 0.99368082,\n",
       "        0.67345804, 0.98201807, 0.98201854, 0.58113682, 0.96694923,\n",
       "        0.96694923, 0.54664109, 0.95479915, 0.95479962, 0.53449431,\n",
       "        0.99708313, 0.99708313, 0.97910593, 0.99368082, 0.99368082,\n",
       "        0.67345804, 0.98201807, 0.98201854, 0.58113682, 0.96694923,\n",
       "        0.96694923, 0.54664109, 0.95479915, 0.95479962, 0.53449431,\n",
       "        0.99708313, 0.99708313, 0.97910593, 0.99368082, 0.99368082,\n",
       "        0.67345804, 0.98201807, 0.98201854, 0.58113682, 0.96694923,\n",
       "        0.96694923, 0.54664109, 0.95479915, 0.95479962, 0.53449431]),\n",
       " 'split1_train_score': array([0.99611131, 0.99708313, 0.98153547, 0.98784945, 0.98979355,\n",
       "        0.67977249, 0.97521393, 0.97667213, 0.57822089, 0.95820146,\n",
       "        0.95917375, 0.54469698, 0.94459271, 0.94507956, 0.52963854,\n",
       "        0.99708313, 0.9970836 , 0.98153547, 0.99319444, 0.99319492,\n",
       "        0.67977249, 0.98250114, 0.98298847, 0.57822089, 0.96986516,\n",
       "        0.96986421, 0.54469698, 0.96063195, 0.96063289, 0.52963854,\n",
       "        0.99708313, 0.9970836 , 0.98153547, 0.99319444, 0.99319492,\n",
       "        0.67977249, 0.98250114, 0.98298847, 0.57822089, 0.96986516,\n",
       "        0.96986421, 0.54469698, 0.96063195, 0.96063289, 0.52963854,\n",
       "        0.99708313, 0.9970836 , 0.98153547, 0.99319444, 0.99319492,\n",
       "        0.67977249, 0.98250114, 0.98298847, 0.57822089, 0.96986516,\n",
       "        0.96986421, 0.54469698, 0.96063195, 0.96063289, 0.52963854]),\n",
       " 'split2_train_score': array([0.99562257, 0.99756904, 0.97862002, 0.98832732, 0.99173624,\n",
       "        0.68269173, 0.97373919, 0.97521346, 0.59571408, 0.95769144,\n",
       "        0.9586642 , 0.56218827, 0.94358969, 0.94358969, 0.54226744,\n",
       "        0.99756857, 0.99756857, 0.97862002, 0.99513808, 0.99513855,\n",
       "        0.68269173, 0.98055798, 0.98055845, 0.59571408, 0.96549151,\n",
       "        0.96549245, 0.56218827, 0.95382922, 0.95382828, 0.54226744,\n",
       "        0.99756857, 0.99756857, 0.97862002, 0.99513808, 0.99513855,\n",
       "        0.68269173, 0.98055798, 0.98055845, 0.59571408, 0.96549151,\n",
       "        0.96549245, 0.56218827, 0.95382922, 0.95382828, 0.54226744,\n",
       "        0.99756857, 0.99756857, 0.97862002, 0.99513808, 0.99513855,\n",
       "        0.68269173, 0.98055798, 0.98055845, 0.59571408, 0.96549151,\n",
       "        0.96549245, 0.56218827, 0.95382922, 0.95382828, 0.54226744]),\n",
       " 'split3_train_score': array([0.994655  , 0.99659722, 0.97859922, 0.98493636, 0.98833016,\n",
       "        0.68434561, 0.97084265, 0.97422841, 0.59874675, 0.9562616 ,\n",
       "        0.9572079 , 0.56129303, 0.94070969, 0.94213386, 0.54134856,\n",
       "        0.99659722, 0.99659722, 0.97859922, 0.9917353 , 0.9917353 ,\n",
       "        0.68434561, 0.97860489, 0.97860489, 0.59874675, 0.96596182,\n",
       "        0.96596229, 0.56129303, 0.95380748, 0.95380843, 0.54134856,\n",
       "        0.99659722, 0.99659722, 0.97859922, 0.9917353 , 0.9917353 ,\n",
       "        0.68434561, 0.97860489, 0.97860489, 0.59874675, 0.96596182,\n",
       "        0.96596229, 0.56129303, 0.95380748, 0.95380843, 0.54134856,\n",
       "        0.99659722, 0.99659722, 0.97859922, 0.9917353 , 0.9917353 ,\n",
       "        0.68434561, 0.97860489, 0.97860489, 0.59874675, 0.96596182,\n",
       "        0.96596229, 0.56129303, 0.95380748, 0.95380843, 0.54134856]),\n",
       " 'split4_train_score': array([0.99611273, 0.99708313, 0.97957198, 0.98882363, 0.9888241 ,\n",
       "        0.6804574 , 0.97375762, 0.97520117, 0.59291065, 0.95917706,\n",
       "        0.96014935, 0.55983436, 0.94459696, 0.94553569, 0.53891618,\n",
       "        0.99708313, 0.99708313, 0.97957198, 0.99076206, 0.99076159,\n",
       "        0.6804574 , 0.97957813, 0.97957718, 0.59291065, 0.96693694,\n",
       "        0.96693647, 0.55983436, 0.95818255, 0.95818208, 0.53891618,\n",
       "        0.99708313, 0.99708313, 0.97957198, 0.99076206, 0.99076159,\n",
       "        0.6804574 , 0.97957813, 0.97957718, 0.59291065, 0.96693694,\n",
       "        0.96693647, 0.55983436, 0.95818255, 0.95818208, 0.53891618,\n",
       "        0.99708313, 0.99708313, 0.97957198, 0.99076206, 0.99076159,\n",
       "        0.6804574 , 0.97957813, 0.97957718, 0.59291065, 0.96693694,\n",
       "        0.96693647, 0.55983436, 0.95818255, 0.95818208, 0.53891618]),\n",
       " 'split5_train_score': array([0.994655  , 0.99756998, 0.97957198, 0.98541943, 0.98784378,\n",
       "        0.67267813, 0.97327124, 0.97472991, 0.59436932, 0.95771838,\n",
       "        0.95917517, 0.55107855, 0.94119418, 0.94265238, 0.53745703,\n",
       "        0.99756998, 0.99756998, 0.97957198, 0.99124892, 0.99124844,\n",
       "        0.67267813, 0.98055089, 0.98055042, 0.59436932, 0.96790734,\n",
       "        0.96790734, 0.55107855, 0.95380465, 0.95380559, 0.53745703,\n",
       "        0.99756998, 0.99756998, 0.97957198, 0.99124892, 0.99124844,\n",
       "        0.67267813, 0.98055089, 0.98055042, 0.59436932, 0.96790734,\n",
       "        0.96790734, 0.55107855, 0.95380465, 0.95380559, 0.53745703,\n",
       "        0.99756998, 0.99756998, 0.97957198, 0.99124892, 0.99124844,\n",
       "        0.67267813, 0.98055089, 0.98055042, 0.59436932, 0.96790734,\n",
       "        0.96790734, 0.55107855, 0.95380465, 0.95380559, 0.53745703]),\n",
       " 'split6_train_score': array([0.9941691 , 0.99659864, 0.9776482 , 0.98493683, 0.98736638,\n",
       "        0.67784257, 0.97230321, 0.97813411, 0.58697765, 0.95286686,\n",
       "        0.95578231, 0.54761905, 0.93488824, 0.93877551, 0.53158406,\n",
       "        0.99659864, 0.99708455, 0.9776482 , 0.99125364, 0.99125364,\n",
       "        0.67784257, 0.98202138, 0.98250729, 0.58697765, 0.96695821,\n",
       "        0.96695821, 0.54761905, 0.95626822, 0.95626822, 0.53158406,\n",
       "        0.99659864, 0.99708455, 0.9776482 , 0.99125364, 0.99125364,\n",
       "        0.67784257, 0.98202138, 0.98250729, 0.58697765, 0.96695821,\n",
       "        0.96695821, 0.54761905, 0.95626822, 0.95626822, 0.53158406,\n",
       "        0.99659864, 0.99708455, 0.9776482 , 0.99125364, 0.99125364,\n",
       "        0.67784257, 0.98202138, 0.98250729, 0.58697765, 0.96695821,\n",
       "        0.96695821, 0.54761905, 0.95626822, 0.95626822, 0.53158406]),\n",
       " 'mean_train_score': array([0.99527873, 0.99708347, 0.97923612, 0.98701639, 0.98923715,\n",
       "        0.67874942, 0.97354681, 0.97590545, 0.58972517, 0.95702079,\n",
       "        0.9583363 , 0.5533359 , 0.94174559, 0.94298575, 0.53652945,\n",
       "        0.9970834 , 0.99715288, 0.97923612, 0.99243047, 0.99243047,\n",
       "        0.67874942, 0.98083321, 0.98097218, 0.58972517, 0.96715289,\n",
       "        0.96715289, 0.5533359 , 0.95590332, 0.95590359, 0.53652945,\n",
       "        0.9970834 , 0.99715288, 0.97923612, 0.99243047, 0.99243047,\n",
       "        0.67874942, 0.98083321, 0.98097218, 0.58972517, 0.96715289,\n",
       "        0.96715289, 0.5533359 , 0.95590332, 0.95590359, 0.53652945,\n",
       "        0.9970834 , 0.99715288, 0.97923612, 0.99243047, 0.99243047,\n",
       "        0.67874942, 0.98083321, 0.98097218, 0.58972517, 0.96715289,\n",
       "        0.96715289, 0.5533359 , 0.95590332, 0.95590359, 0.53652945]),\n",
       " 'std_train_score': array([0.00072076, 0.00036722, 0.00112353, 0.00169618, 0.0014797 ,\n",
       "        0.00407965, 0.0015321 , 0.00132532, 0.0071975 , 0.00188432,\n",
       "        0.00134239, 0.00698099, 0.00313622, 0.00206452, 0.00445274,\n",
       "        0.00036713, 0.00031047, 0.00112353, 0.0014893 , 0.00148958,\n",
       "        0.00407965, 0.00132523, 0.00148401, 0.0071975 , 0.00132182,\n",
       "        0.00132132, 0.00698099, 0.00244966, 0.00244971, 0.00445274,\n",
       "        0.00036713, 0.00031047, 0.00112353, 0.0014893 , 0.00148958,\n",
       "        0.00407965, 0.00132523, 0.00148401, 0.0071975 , 0.00132182,\n",
       "        0.00132132, 0.00698099, 0.00244966, 0.00244971, 0.00445274,\n",
       "        0.00036713, 0.00031047, 0.00112353, 0.0014893 , 0.00148958,\n",
       "        0.00407965, 0.00132523, 0.00148401, 0.0071975 , 0.00132182,\n",
       "        0.00132132, 0.00698099, 0.00244966, 0.00244971, 0.00445274])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best parameters set:\")\n",
    "print(tfidf_grid_searcher.best_estimator_[0])\n",
    "print(tfidf_grid_searcher.best_params_)\n",
    "cv_results = tfidf_grid_searcher.cv_results_\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterize the vocabulary for this optimal vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4255"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tfidf_vectorizer = tfidf_grid_searcher.best_estimator_[0]\n",
    "best_tfidf_vectorizer.fit_transform(x_train_text)\n",
    "x_train_text_tf_best = best_tfidf_vectorizer.transform(x_train_text).toarray()\n",
    "len(best_tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.float64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 0.1,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'norm': 'l2',\n",
       " 'preprocessor': None,\n",
       " 'smooth_idf': True,\n",
       " 'stop_words': 'english',\n",
       " 'strip_accents': None,\n",
       " 'sublinear_tf': False,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'use_idf': True,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tfidf_vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pipeline to try many CountVectorizer hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 36 candidates, totalling 252 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=3)]: Done 122 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=3)]: Done 252 out of 252 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('count', CountVectorizer(max_df=0.1, min_df=2, ngram_range=(1, 2), stop_words='english')), ('clf', RandomForestClassifier(random_state=123))]\n"
     ]
    }
   ],
   "source": [
    "count_pipeline = Pipeline([\n",
    "    ('count', CountVectorizer(stop_words='english')),\n",
    "    ('clf', RandomForestClassifier(random_state=RANDOM_STATE)),\n",
    " ])\n",
    "count_parameters = {\n",
    "    'count__min_df': np.arange(1, 5),\n",
    "    'count__max_df': (0.05, 0.1, 0.5),\n",
    "    'count__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
    "}\n",
    "\n",
    "count_grid_searcher = GridSearchCV(\n",
    "    count_pipeline, \n",
    "    count_parameters, \n",
    "    cv=7, \n",
    "    n_jobs=3, \n",
    "    verbose=3,\n",
    "    scoring='balanced_accuracy',\n",
    "    return_train_score=True\n",
    ")\n",
    "count_grid_searcher.fit(x_train_text, y_train)\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(count_grid_searcher.best_estimator_.steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has shape: (36, 27)\n",
      "Number of trials used in grid search:  36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_count__min_df</th>\n",
       "      <th>param_count__max_df</th>\n",
       "      <th>param_count__ngram_range</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.787487</td>\n",
       "      <td>1.303181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.787487</td>\n",
       "      <td>1.731245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>1.483919</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>1.627279</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.997014</td>\n",
       "      <td>0.776243</td>\n",
       "      <td>2.918857</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.997014</td>\n",
       "      <td>0.776243</td>\n",
       "      <td>1.184831</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.772493</td>\n",
       "      <td>4.067247</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997153</td>\n",
       "      <td>0.772493</td>\n",
       "      <td>2.048632</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.980972</td>\n",
       "      <td>0.769149</td>\n",
       "      <td>1.060998</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.980972</td>\n",
       "      <td>0.769149</td>\n",
       "      <td>1.538422</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.980903</td>\n",
       "      <td>0.767063</td>\n",
       "      <td>1.059678</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.980903</td>\n",
       "      <td>0.767063</td>\n",
       "      <td>1.540660</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.967222</td>\n",
       "      <td>0.762881</td>\n",
       "      <td>1.714781</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.967222</td>\n",
       "      <td>0.762881</td>\n",
       "      <td>1.142211</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.967222</td>\n",
       "      <td>0.762461</td>\n",
       "      <td>1.147987</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.967222</td>\n",
       "      <td>0.762461</td>\n",
       "      <td>1.720329</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.989237</td>\n",
       "      <td>0.743266</td>\n",
       "      <td>1.015814</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.997083</td>\n",
       "      <td>0.741211</td>\n",
       "      <td>1.848990</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.976044</td>\n",
       "      <td>0.733311</td>\n",
       "      <td>0.769571</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.986947</td>\n",
       "      <td>0.732803</td>\n",
       "      <td>0.952018</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.995279</td>\n",
       "      <td>0.731497</td>\n",
       "      <td>1.033679</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.973616</td>\n",
       "      <td>0.720755</td>\n",
       "      <td>0.712035</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.958406</td>\n",
       "      <td>0.717416</td>\n",
       "      <td>0.812570</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.957091</td>\n",
       "      <td>0.716991</td>\n",
       "      <td>0.763777</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.584215</td>\n",
       "      <td>3.377926</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.584215</td>\n",
       "      <td>1.808763</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.584215</td>\n",
       "      <td>3.088955</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560884</td>\n",
       "      <td>0.589049</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560884</td>\n",
       "      <td>0.927186</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.678749</td>\n",
       "      <td>0.560884</td>\n",
       "      <td>0.514002</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.621831</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.311277</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.589725</td>\n",
       "      <td>0.537128</td>\n",
       "      <td>0.423086</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.284236</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.757569</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.553336</td>\n",
       "      <td>0.522530</td>\n",
       "      <td>0.397119</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_count__min_df param_count__max_df param_count__ngram_range  \\\n",
       "28                   2                 0.5                   (1, 2)   \n",
       "16                   2                 0.1                   (1, 2)   \n",
       "27                   2                 0.5                   (1, 1)   \n",
       "15                   2                 0.1                   (1, 1)   \n",
       "24                   1                 0.5                   (1, 1)   \n",
       "12                   1                 0.1                   (1, 1)   \n",
       "25                   1                 0.5                   (1, 2)   \n",
       "13                   1                 0.1                   (1, 2)   \n",
       "31                   3                 0.5                   (1, 2)   \n",
       "19                   3                 0.1                   (1, 2)   \n",
       "30                   3                 0.5                   (1, 1)   \n",
       "18                   3                 0.1                   (1, 1)   \n",
       "22                   4                 0.1                   (1, 2)   \n",
       "34                   4                 0.5                   (1, 2)   \n",
       "33                   4                 0.5                   (1, 1)   \n",
       "21                   4                 0.1                   (1, 1)   \n",
       "4                    2                0.05                   (1, 2)   \n",
       "1                    1                0.05                   (1, 2)   \n",
       "7                    3                0.05                   (1, 2)   \n",
       "3                    2                0.05                   (1, 1)   \n",
       "0                    1                0.05                   (1, 1)   \n",
       "6                    3                0.05                   (1, 1)   \n",
       "10                   4                0.05                   (1, 2)   \n",
       "9                    4                0.05                   (1, 1)   \n",
       "14                   1                 0.1                   (2, 2)   \n",
       "2                    1                0.05                   (2, 2)   \n",
       "26                   1                 0.5                   (2, 2)   \n",
       "29                   2                 0.5                   (2, 2)   \n",
       "17                   2                 0.1                   (2, 2)   \n",
       "5                    2                0.05                   (2, 2)   \n",
       "20                   3                 0.1                   (2, 2)   \n",
       "8                    3                0.05                   (2, 2)   \n",
       "32                   3                 0.5                   (2, 2)   \n",
       "11                   4                0.05                   (2, 2)   \n",
       "23                   4                 0.1                   (2, 2)   \n",
       "35                   4                 0.5                   (2, 2)   \n",
       "\n",
       "    mean_train_score  mean_test_score  mean_fit_time  rank_test_score  \n",
       "28          0.992361         0.787487       1.303181                1  \n",
       "16          0.992361         0.787487       1.731245                1  \n",
       "27          0.992361         0.784983       1.483919                3  \n",
       "15          0.992361         0.784983       1.627279                3  \n",
       "24          0.997014         0.776243       2.918857                5  \n",
       "12          0.997014         0.776243       1.184831                5  \n",
       "25          0.997153         0.772493       4.067247                7  \n",
       "13          0.997153         0.772493       2.048632                7  \n",
       "31          0.980972         0.769149       1.060998                9  \n",
       "19          0.980972         0.769149       1.538422                9  \n",
       "30          0.980903         0.767063       1.059678               11  \n",
       "18          0.980903         0.767063       1.540660               11  \n",
       "22          0.967222         0.762881       1.714781               13  \n",
       "34          0.967222         0.762881       1.142211               13  \n",
       "33          0.967222         0.762461       1.147987               15  \n",
       "21          0.967222         0.762461       1.720329               15  \n",
       "4           0.989237         0.743266       1.015814               17  \n",
       "1           0.997083         0.741211       1.848990               18  \n",
       "7           0.976044         0.733311       0.769571               19  \n",
       "3           0.986947         0.732803       0.952018               20  \n",
       "0           0.995279         0.731497       1.033679               21  \n",
       "6           0.973616         0.720755       0.712035               22  \n",
       "10          0.958406         0.717416       0.812570               23  \n",
       "9           0.957091         0.716991       0.763777               24  \n",
       "14          0.979236         0.584215       3.377926               25  \n",
       "2           0.979236         0.584215       1.808763               25  \n",
       "26          0.979236         0.584215       3.088955               25  \n",
       "29          0.678749         0.560884       0.589049               28  \n",
       "17          0.678749         0.560884       0.927186               28  \n",
       "5           0.678749         0.560884       0.514002               28  \n",
       "20          0.589725         0.537128       0.621831               31  \n",
       "8           0.589725         0.537128       0.311277               31  \n",
       "32          0.589725         0.537128       0.423086               31  \n",
       "11          0.553336         0.522530       0.284236               34  \n",
       "23          0.553336         0.522530       0.757569               34  \n",
       "35          0.553336         0.522530       0.397119               34  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_gridsearch_results(count_grid_searcher, list(count_parameters.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2131"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_count_vectorizer = count_grid_searcher.best_estimator_[0]\n",
    "best_count_vectorizer.fit_transform(x_train_text)\n",
    "x_train_text_count_best = best_count_vectorizer.transform(x_train_text).toarray()\n",
    "len(best_count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2131"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_text_count_best[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf = sklearn.model_selection.StratifiedKFold(n_splits=5)\n",
    "# count_tf_scores = [[],[]]\n",
    "# count_tf_train_time = [[],[]]\n",
    "\n",
    "# for train_index, test_index in skf.split(x_train_text, y_train): \n",
    "#     ## Count\n",
    "#     #\n",
    "#     count_randforest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "#     # Time the training process\n",
    "#     start_time_sec = time.time()\n",
    "#     count_randforest.fit(x_train_text_count[train_index], y_train[train_index])\n",
    "#     elapsed_time_sec = time.time() - start_time_sec\n",
    "#     # Get accuracy scores for this split\n",
    "#     count_y_test_pred = count_randforest.predict(x_train_text_count[test_index])\n",
    "#     count_balanced_acc = sklearn.metrics.balanced_accuracy_score(\n",
    "#         y_true=y_train[test_index], \n",
    "#         y_pred=count_y_test_pred\n",
    "#     )\n",
    "#     print(\"Performance of the count_vectorized random forest\")\n",
    "#     print(count_balanced_acc)\n",
    "#     count_tf_scores[0].append(count_balanced_acc)\n",
    "#     count_tf_train_time[0].append(elapsed_time_sec)\n",
    "    \n",
    "#     # TFIDF\n",
    "#     # \n",
    "#     tf_randforest = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "#     # Time the training process\n",
    "#     start_time_sec = time.time()    \n",
    "#     tf_randforest.fit(x_train_text_tf[train_index], y_train[train_index])\n",
    "#     elapsed_time_sec = time.time() - start_time_sec\n",
    "#     # Get accuracy scores for this split\n",
    "#     tf_y_test_pred=tf_randforest.predict(x_train_text_tf[test_index])\n",
    "    \n",
    "#     tf_balanced_acc = sklearn.metrics.balanced_accuracy_score(\n",
    "#         y_true=y_train[test_index], \n",
    "#         y_pred=tf_y_test_pred\n",
    "#     )\n",
    "#     print(\"Performance of the tfidf_vectorized random forest\")    \n",
    "#     print(tf_balanced_acc)\n",
    "#     count_tf_scores[1].append(tf_balanced_acc)\n",
    "#     count_tf_train_time[1].append(elapsed_time_sec)\n",
    "    \n",
    "# print(\"Best overall\")\n",
    "# print(f\"type:  | score | time \")\n",
    "# print(f\"count: | %5.3f | %4.3f\" % (np.mean(count_tf_scores[0]), np.mean(count_tf_train_time[0])))\n",
    "# print(f\"tfidf: | %5.3f | %4.3f\" % (np.mean(count_tf_scores[1]), np.mean(count_tf_train_time[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
